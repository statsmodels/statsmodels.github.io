

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Optimization &#8212; statsmodels v0.10.0 documentation</title>
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="_static/statsmodels_hybi_favico.ico"/>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="statsmodels.base.optimizer.Optimizer" href="generated/statsmodels.base.optimizer.Optimizer.html" />
    <link rel="prev" title="statsmodels.base.distributed_estimation.DistributedResults.wald_test_terms" href="generated/statsmodels.base.distributed_estimation.DistributedResults.wald_test_terms.html" />
<link rel="stylesheet" href="_static/examples.css" type="text/css" />
<link rel="stylesheet" href="_static/facebox.css" type="text/css" />
<script type="text/javascript" src="_static/scripts.js">
</script>
<script type="text/javascript" src="_static/facebox.js">
</script>
<script type="text/javascript">
$.facebox.settings.closeImage = "_static/closelabel.png"
$.facebox.settings.loadingImage = "_static/loading.gif"
</script>

<script>
$(document).ready(function() {
  $.getJSON("../versions.json", function(versions) {
    var dropdown = document.createElement("div");
    dropdown.className = "dropdown";
    var button = document.createElement("button");
    button.className = "dropbtn";
    button.innerHTML = "Other Versions";
    var content = document.createElement("div");
    content.className = "dropdown-content";
    dropdown.appendChild(button);
    dropdown.appendChild(content);
    $(".header").prepend(dropdown);
    for (var i = 0; i < versions.length; i++) {
      if (versions[i].substring(0, 1) == "v") {
        versions[i] = [versions[i], versions[i].substring(1)];
      } else {
        versions[i] = [versions[i], versions[i]];
      };
    };
    for (var i = 0; i < versions.length; i++) {
      var a = document.createElement("a");
      a.innerHTML = versions[i][1];
      a.href = "../" + versions[i][0] + "/index.html";
      a.title = versions[i][1];
      $(".dropdown-content").append(a);
    };
  });
});
</script>


  </head><body>
<div class="headerwrap">
    <div class = "header">
        
        <a href = "index.html">
<img src="_static/statsmodels_hybi_banner.png" alt="Logo"
    style="padding-left: 15px"/></a>
        
    </div>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="generated/statsmodels.base.optimizer.Optimizer.html" title="statsmodels.base.optimizer.Optimizer"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="generated/statsmodels.base.distributed_estimation.DistributedResults.wald_test_terms.html" title="statsmodels.base.distributed_estimation.DistributedResults.wald_test_terms"
             accesskey="P">previous</a> |</li>
<li><a href ="install.html">Install</a></li> &nbsp;|&nbsp;
<li><a href="https://groups.google.com/forum/?hl=en#!forum/pystatsmodels">Support</a></li> &nbsp;|&nbsp;
<li><a href="https://github.com/statsmodels/statsmodels/issues">Bugs</a></li> &nbsp;|&nbsp;
<li><a href="dev/index.html">Develop</a></li> &nbsp;|&nbsp;
<li><a href="examples/index.html">Examples</a></li> &nbsp;|&nbsp;
<li><a href="faq.html">FAQ</a></li> &nbsp;|&nbsp;
 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            




  <span class="target" id="module-statsmodels.base.optimizer"></span><div class="section" id="optimization">
<h1>Optimization<a class="headerlink" href="#optimization" title="Permalink to this headline">¶</a></h1>
<p>statsmodels uses three types of algorithms for the estimation of the parameters
of a model.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Basic linear models such as <a class="reference internal" href="regression.html#regression"><span class="std std-ref">WLS and OLS</span></a> are directly
estimated using appropriate linear algebra.</p></li>
<li><p><a class="reference internal" href="rlm.html#rlm"><span class="std std-ref">RLM</span></a> and <a class="reference internal" href="glm.html#glm"><span class="std std-ref">GLM</span></a>, use iteratively re-weighted
least squares. However, you can optionally select one of the scipy
optimizers discussed below.</p></li>
<li><p>For all other models, we use
<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/optimize.html">optimizers</a>
from <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/index.html">scipy</a>.</p></li>
</ol>
</div></blockquote>
<p>Where practical, certain models allow for the optional selection of a
scipy optimizer. A particular scipy optimizer might be default or an option.
Depending on the model and the data, choosing an appropriate scipy optimizer
enables avoidance of a local minima, fitting models in less time, or fitting a
model with less memory.</p>
<p>statsmodels supports the following optimizers along with keyword arguments
associated with that specific optimizer:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">newton</span></code> - Newton-Raphson iteration. While not directly from scipy, we
consider it an optimizer because only the score and hessian are required.</p>
<blockquote>
<div><dl class="simple">
<dt>tol<span class="classifier">float</span></dt><dd><p>Relative error in params acceptable for convergence.</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">nm</span></code> - scipy’s <code class="docutils literal notranslate"><span class="pre">fmin_nm</span></code></p>
<blockquote>
<div><dl class="simple">
<dt>xtol<span class="classifier">float</span></dt><dd><p>Relative error in params acceptable for convergence</p>
</dd>
<dt>ftol<span class="classifier">float</span></dt><dd><p>Relative error in loglike(params) acceptable for
convergence</p>
</dd>
<dt>maxfun<span class="classifier">int</span></dt><dd><p>Maximum number of function evaluations to make.</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">bfgs</span></code> - Broyden–Fletcher–Goldfarb–Shanno optimization, scipy’s
<code class="docutils literal notranslate"><span class="pre">fmin_bfgs</span></code>.</p>
<blockquote>
<div><dl class="simple">
<dt>gtol<span class="classifier">float</span></dt><dd><p>Stop when norm of gradient is less than gtol.</p>
</dd>
<dt>norm<span class="classifier">float</span></dt><dd><p>Order of norm (np.Inf is max, -np.Inf is min)</p>
</dd>
<dt>epsilon</dt><dd><p>If fprime is approximated, use this value for the step
size. Only relevant if LikelihoodModel.score is None.</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">lbfgs</span></code> - A more memory-efficient (limited memory) implementation of
<code class="docutils literal notranslate"><span class="pre">bfgs</span></code>. Scipy’s <code class="docutils literal notranslate"><span class="pre">fmin_l_bfgs_b</span></code>.</p>
<blockquote>
<div><dl class="simple">
<dt>m<span class="classifier">int</span></dt><dd><p>The maximum number of variable metric corrections used to
define the limited memory matrix. (The limited memory BFGS
method does not store the full hessian but uses this many
terms in an approximation to it.)</p>
</dd>
<dt>pgtol<span class="classifier">float</span></dt><dd><p>The iteration will stop when
<code class="docutils literal notranslate"><span class="pre">max{|proj</span> <span class="pre">g_i</span> <span class="pre">|</span> <span class="pre">i</span> <span class="pre">=</span> <span class="pre">1,</span> <span class="pre">...,</span> <span class="pre">n}</span> <span class="pre">&lt;=</span> <span class="pre">pgtol</span></code> where pg_i is
the i-th component of the projected gradient.</p>
</dd>
<dt>factr<span class="classifier">float</span></dt><dd><p>The iteration stops when
<code class="docutils literal notranslate"><span class="pre">(f^k</span> <span class="pre">-</span> <span class="pre">f^{k+1})/max{|f^k|,|f^{k+1}|,1}</span> <span class="pre">&lt;=</span> <span class="pre">factr</span> <span class="pre">*</span> <span class="pre">eps</span></code>,
where eps is the machine precision, which is automatically
generated by the code. Typical values for factr are: 1e12
for low accuracy; 1e7 for moderate accuracy; 10.0 for
extremely high accuracy. See Notes for relationship to
ftol, which is exposed (instead of factr) by the
scipy.optimize.minimize interface to L-BFGS-B.</p>
</dd>
<dt>maxfun<span class="classifier">int</span></dt><dd><p>Maximum number of iterations.</p>
</dd>
<dt>epsilon<span class="classifier">float</span></dt><dd><p>Step size used when approx_grad is True, for numerically
calculating the gradient</p>
</dd>
<dt>approx_grad<span class="classifier">bool</span></dt><dd><p>Whether to approximate the gradient numerically (in which
case func returns only the function value).</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">cg</span></code> - Conjugate gradient optimization. Scipy’s <code class="docutils literal notranslate"><span class="pre">fmin_cg</span></code>.</p>
<blockquote>
<div><dl class="simple">
<dt>gtol<span class="classifier">float</span></dt><dd><p>Stop when norm of gradient is less than gtol.</p>
</dd>
<dt>norm<span class="classifier">float</span></dt><dd><p>Order of norm (np.Inf is max, -np.Inf is min)</p>
</dd>
<dt>epsilon<span class="classifier">float</span></dt><dd><p>If fprime is approximated, use this value for the step
size. Can be scalar or vector.  Only relevant if
Likelihoodmodel.score is None.</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">ncg</span></code> - Newton conjugate gradient. Scipy’s <code class="docutils literal notranslate"><span class="pre">fmin_ncg</span></code>.</p>
<blockquote>
<div><dl class="simple">
<dt>fhess_p<span class="classifier">callable f’(x, \*args)</span></dt><dd><p>Function which computes the Hessian of f times an arbitrary
vector, p.  Should only be supplied if
LikelihoodModel.hessian is None.</p>
</dd>
<dt>avextol<span class="classifier">float</span></dt><dd><p>Stop when the average relative error in the minimizer
falls below this amount.</p>
</dd>
<dt>epsilon<span class="classifier">float or ndarray</span></dt><dd><p>If fhess is approximated, use this value for the step size.
Only relevant if Likelihoodmodel.hessian is None.</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">powell</span></code> - Powell’s method. Scipy’s <code class="docutils literal notranslate"><span class="pre">fmin_powell</span></code>.</p>
<blockquote>
<div><dl class="simple">
<dt>xtol<span class="classifier">float</span></dt><dd><p>Line-search error tolerance</p>
</dd>
<dt>ftol<span class="classifier">float</span></dt><dd><p>Relative error in loglike(params) for acceptable for
convergence.</p>
</dd>
<dt>maxfun<span class="classifier">int</span></dt><dd><p>Maximum number of function evaluations to make.</p>
</dd>
<dt>start_direc<span class="classifier">ndarray</span></dt><dd><p>Initial direction set.</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">basinhopping</span></code> - Basin hopping. This is part of scipy’s <code class="docutils literal notranslate"><span class="pre">basinhopping</span></code>
tools.</p>
<blockquote>
<div><dl class="simple">
<dt>niter<span class="classifier">integer</span></dt><dd><p>The number of basin hopping iterations.</p>
</dd>
<dt>niter_success<span class="classifier">integer</span></dt><dd><p>Stop the run if the global minimum candidate remains the
same for this number of iterations.</p>
</dd>
<dt>T<span class="classifier">float</span></dt><dd><p>The “temperature” parameter for the accept or reject
criterion. Higher “temperatures” mean that larger jumps
in function value will be accepted. For best results
<cite>T</cite> should be comparable to the separation (in function
value) between local minima.</p>
</dd>
<dt>stepsize<span class="classifier">float</span></dt><dd><p>Initial step size for use in the random displacement.</p>
</dd>
<dt>interval<span class="classifier">integer</span></dt><dd><p>The interval for how often to update the <cite>stepsize</cite>.</p>
</dd>
<dt>minimizer<span class="classifier">dict</span></dt><dd><p>Extra keyword arguments to be passed to the minimizer
<cite>scipy.optimize.minimize()</cite>, for example ‘method’ - the
minimization method (e.g. ‘L-BFGS-B’), or ‘tol’ - the
tolerance for termination. Other arguments are mapped from
explicit argument of <cite>fit</cite>:
- <cite>args</cite> &lt;- <cite>fargs</cite>
- <cite>jac</cite> &lt;- <cite>score</cite>
- <cite>hess</cite> &lt;- <cite>hess</cite></p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">minimize</span></code> - Allows the use of any scipy optimizer.</p>
<dl class="simple">
<dt>min_method<span class="classifier">str, optional</span></dt><dd><p>Name of minimization method to use.
Any method specific arguments can be passed directly.
For a list of methods and their arguments, see
documentation of <cite>scipy.optimize.minimize</cite>.
If no method is specified, then BFGS is used.</p>
</dd>
</dl>
</li>
</ul>
<div class="section" id="model-class">
<h2>Model Class<a class="headerlink" href="#model-class" title="Permalink to this headline">¶</a></h2>
<p>Generally, there is no need for an end-user to directly call these functions
and classes. However, we provide the class because the different optimization
techniques have unique keyword arguments that may be useful to the user.</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/statsmodels.base.optimizer.Optimizer.html#statsmodels.base.optimizer.Optimizer" title="statsmodels.base.optimizer.Optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Optimizer</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/statsmodels.base.optimizer._fit_newton.html#statsmodels.base.optimizer._fit_newton" title="statsmodels.base.optimizer._fit_newton"><code class="xref py py-obj docutils literal notranslate"><span class="pre">_fit_newton</span></code></a>(f, score, start_params, fargs, …)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/statsmodels.base.optimizer._fit_bfgs.html#statsmodels.base.optimizer._fit_bfgs" title="statsmodels.base.optimizer._fit_bfgs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">_fit_bfgs</span></code></a>(f, score, start_params, fargs, kwargs)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/statsmodels.base.optimizer._fit_lbfgs.html#statsmodels.base.optimizer._fit_lbfgs" title="statsmodels.base.optimizer._fit_lbfgs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">_fit_lbfgs</span></code></a>(f, score, start_params, fargs, kwargs)</p></td>
<td><p>Fit model using L-BFGS algorithm</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/statsmodels.base.optimizer._fit_nm.html#statsmodels.base.optimizer._fit_nm" title="statsmodels.base.optimizer._fit_nm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">_fit_nm</span></code></a>(f, score, start_params, fargs, kwargs)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/statsmodels.base.optimizer._fit_cg.html#statsmodels.base.optimizer._fit_cg" title="statsmodels.base.optimizer._fit_cg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">_fit_cg</span></code></a>(f, score, start_params, fargs, kwargs)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/statsmodels.base.optimizer._fit_ncg.html#statsmodels.base.optimizer._fit_ncg" title="statsmodels.base.optimizer._fit_ncg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">_fit_ncg</span></code></a>(f, score, start_params, fargs, kwargs)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/statsmodels.base.optimizer._fit_powell.html#statsmodels.base.optimizer._fit_powell" title="statsmodels.base.optimizer._fit_powell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">_fit_powell</span></code></a>(f, score, start_params, fargs, …)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/statsmodels.base.optimizer._fit_basinhopping.html#statsmodels.base.optimizer._fit_basinhopping" title="statsmodels.base.optimizer._fit_basinhopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">_fit_basinhopping</span></code></a>(f, score, start_params, …)</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</div>





          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Optimization</a><ul>
<li><a class="reference internal" href="#model-class">Model Class</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="generated/statsmodels.base.distributed_estimation.DistributedResults.wald_test_terms.html"
                        title="previous chapter">statsmodels.base.distributed_estimation.DistributedResults.wald_test_terms</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="generated/statsmodels.base.optimizer.Optimizer.html"
                        title="next chapter">statsmodels.base.optimizer.Optimizer</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/optimization.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2009-2018, Josef Perktold, Skipper Seabold, Jonathan Taylor, statsmodels-developers.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.2.
    </div>
  </body>
</html>