

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>statsmodels.nonparametric.smoothers_lowess.lowess &#8212; statsmodels v0.10.2 documentation</title>
    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/statsmodels_hybi_favico.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="statsmodels.nonparametric.kde.KDEUnivariate" href="statsmodels.nonparametric.kde.KDEUnivariate.html" />
    <link rel="prev" title="Nonparametric Methods nonparametric" href="../nonparametric.html" />
<link rel="stylesheet" href="../_static/examples.css" type="text/css" />
<link rel="stylesheet" href="../_static/facebox.css" type="text/css" />
<script type="text/javascript" src="../_static/scripts.js">
</script>
<script type="text/javascript" src="../_static/facebox.js">
</script>
<script type="text/javascript">
$.facebox.settings.closeImage = "../_static/closelabel.png"
$.facebox.settings.loadingImage = "../_static/loading.gif"
</script>

<script>
$(document).ready(function() {
  $.getJSON("../../versions.json", function(versions) {
    var dropdown = document.createElement("div");
    dropdown.className = "dropdown";
    var button = document.createElement("button");
    button.className = "dropbtn";
    button.innerHTML = "Other Versions";
    var content = document.createElement("div");
    content.className = "dropdown-content";
    dropdown.appendChild(button);
    dropdown.appendChild(content);
    $(".header").prepend(dropdown);
    for (var i = 0; i < versions.length; i++) {
      if (versions[i].substring(0, 1) == "v") {
        versions[i] = [versions[i], versions[i].substring(1)];
      } else {
        versions[i] = [versions[i], versions[i]];
      };
    };
    for (var i = 0; i < versions.length; i++) {
      var a = document.createElement("a");
      a.innerHTML = versions[i][1];
      a.href = "../../" + versions[i][0] + "/index.html";
      a.title = versions[i][1];
      $(".dropdown-content").append(a);
    };
  });
});
</script>


  </head><body>
<div class="headerwrap">
    <div class = "header">
        
        <a href = "../index.html">
<img src="../_static/statsmodels_hybi_banner.png" alt="Logo"
    style="padding-left: 15px"/></a>
        
    </div>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="statsmodels.nonparametric.kde.KDEUnivariate.html" title="statsmodels.nonparametric.kde.KDEUnivariate"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../nonparametric.html" title="Nonparametric Methods nonparametric"
             accesskey="P">previous</a> |</li>
<li><a href ="../install.html">Install</a></li> &nbsp;|&nbsp;
<li><a href="https://groups.google.com/forum/?hl=en#!forum/pystatsmodels">Support</a></li> &nbsp;|&nbsp;
<li><a href="https://github.com/statsmodels/statsmodels/issues">Bugs</a></li> &nbsp;|&nbsp;
<li><a href="../dev/index.html">Develop</a></li> &nbsp;|&nbsp;
<li><a href="../examples/index.html">Examples</a></li> &nbsp;|&nbsp;
<li><a href="../faq.html">FAQ</a></li> &nbsp;|&nbsp;

          <li class="nav-item nav-item-1"><a href="../nonparametric.html" accesskey="U">Nonparametric Methods <code class="xref py py-mod docutils literal notranslate"><span class="pre">nonparametric</span></code></a> |</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            




  <div class="section" id="statsmodels-nonparametric-smoothers-lowess-lowess">
<h1>statsmodels.nonparametric.smoothers_lowess.lowess<a class="headerlink" href="#statsmodels-nonparametric-smoothers-lowess-lowess" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="statsmodels.nonparametric.smoothers_lowess.lowess">
<code class="sig-prename descclassname">statsmodels.nonparametric.smoothers_lowess.</code><code class="sig-name descname">lowess</code><span class="sig-paren">(</span><em class="sig-param">endog</em>, <em class="sig-param">exog</em>, <em class="sig-param">frac=0.6666666666666666</em>, <em class="sig-param">it=3</em>, <em class="sig-param">delta=0.0</em>, <em class="sig-param">is_sorted=False</em>, <em class="sig-param">missing='drop'</em>, <em class="sig-param">return_sorted=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/statsmodels/nonparametric/smoothers_lowess.html#lowess"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#statsmodels.nonparametric.smoothers_lowess.lowess" title="Permalink to this definition">¶</a></dt>
<dd><p>LOWESS (Locally Weighted Scatterplot Smoothing)</p>
<p>A lowess function that outs smoothed estimates of endog
at the given exog values from points (exog, endog)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>endog: 1-D numpy array</strong></dt><dd><p>The y-values of the observed points</p>
</dd>
<dt><strong>exog: 1-D numpy array</strong></dt><dd><p>The x-values of the observed points</p>
</dd>
<dt><strong>frac: float</strong></dt><dd><p>Between 0 and 1. The fraction of the data used
when estimating each y-value.</p>
</dd>
<dt><strong>it: int</strong></dt><dd><p>The number of residual-based reweightings
to perform.</p>
</dd>
<dt><strong>delta: float</strong></dt><dd><p>Distance within which to use linear-interpolation
instead of weighted regression.</p>
</dd>
<dt><strong>is_sorted</strong><span class="classifier">bool</span></dt><dd><p>If False (default), then the data will be sorted by exog before
calculating lowess. If True, then it is assumed that the data is
already sorted by exog.</p>
</dd>
<dt><strong>missing</strong><span class="classifier">str</span></dt><dd><p>Available options are ‘none’, ‘drop’, and ‘raise’. If ‘none’, no nan
checking is done. If ‘drop’, any observations with nans are dropped.
If ‘raise’, an error is raised. Default is ‘drop’.</p>
</dd>
<dt><strong>return_sorted</strong><span class="classifier">bool</span></dt><dd><p>If True (default), then the returned array is sorted by exog and has
missing (nan or infinite) observations removed.
If False, then the returned array is in the same length and the same
sequence of observations as the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>out: ndarray, float</strong></dt><dd><p>The returned array is two-dimensional if return_sorted is True, and
one dimensional if return_sorted is False.
If return_sorted is True, then a numpy array with two columns. The
first column contains the sorted x (exog) values and the second column
the associated estimated y (endog) values.
If return_sorted is False, then only the fitted values are returned,
and the observations will be in the same order as the input arrays.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This lowess function implements the algorithm given in the
reference below using local linear estimates.</p>
<p>Suppose the input data has N points. The algorithm works by
estimating the <cite>smooth</cite> y_i by taking the frac*N closest points
to (x_i,y_i) based on their x values and estimating y_i
using a weighted linear regression. The weight for (x_j,y_j)
is tricube function applied to abs(x_i-x_j).</p>
<p>If it &gt; 1, then further weighted local linear regressions
are performed, where the weights are the same as above
times the _lowess_bisquare function of the residuals. Each iteration
takes approximately the same amount of time as the original fit,
so these iterations are expensive. They are most useful when
the noise has extremely heavy tails, such as Cauchy noise.
Noise with less heavy-tails, such as t-distributions with df&gt;2,
are less problematic. The weights downgrade the influence of
points with large residuals. In the extreme case, points whose
residuals are larger than 6 times the median absolute residual
are given weight 0.</p>
<p><cite>delta</cite> can be used to save computations. For each <cite>x_i</cite>, regressions
are skipped for points closer than <cite>delta</cite>. The next regression is
fit for the farthest point within delta of <cite>x_i</cite> and all points in
between are estimated by linearly interpolating between the two
regression fits.</p>
<p>Judicious choice of delta can cut computation time considerably
for large data (N &gt; 5000). A good choice is <code class="docutils literal notranslate"><span class="pre">delta</span> <span class="pre">=</span> <span class="pre">0.01</span> <span class="pre">*</span> <span class="pre">range(exog)</span></code>.</p>
<p>Some experimentation is likely required to find a good
choice of <cite>frac</cite> and <cite>iter</cite> for a particular dataset.</p>
<p class="rubric">References</p>
<p>Cleveland, W.S. (1979) “Robust Locally Weighted Regression
and Smoothing Scatterplots”. Journal of the American Statistical
Association 74 (368): 829-836.</p>
<p class="rubric">Examples</p>
<p>The below allows a comparison between how different the fits from
lowess for different values of frac can be.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lowess</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">nonparametric</span><span class="o">.</span><span class="n">lowess</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span> <span class="o">=</span> <span class="n">lowess</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span> <span class="o">=</span> <span class="n">lowess</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">frac</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<p>This gives a similar comparison for when it is 0 vs not.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lowess</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">nonparametric</span><span class="o">.</span><span class="n">lowess</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">stats</span><span class="o">.</span><span class="n">cauchy</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span> <span class="o">=</span> <span class="n">lowess</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">frac</span><span class="o">=</span> <span class="mf">1.</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="n">it</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span> <span class="o">=</span> <span class="n">lowess</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">frac</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>





          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="../nonparametric.html"
                        title="previous chapter">Nonparametric Methods <code class="xref py py-mod docutils literal notranslate"><span class="pre">nonparametric</span></code></a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="statsmodels.nonparametric.kde.KDEUnivariate.html"
                        title="next chapter">statsmodels.nonparametric.kde.KDEUnivariate</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/generated/statsmodels.nonparametric.smoothers_lowess.lowess.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2009-2018, Josef Perktold, Skipper Seabold, Jonathan Taylor, statsmodels-developers.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.2.1.
    </div>
  </body>
</html>