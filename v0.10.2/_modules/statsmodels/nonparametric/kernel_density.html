

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>statsmodels.nonparametric.kernel_density &#8212; statsmodels v0.10.2 documentation</title>
    <link rel="stylesheet" href="../../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../../../_static/statsmodels_hybi_favico.ico"/>
    <link rel="author" title="About these documents" href="../../../about.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
<link rel="stylesheet" href="../../../_static/examples.css" type="text/css" />
<link rel="stylesheet" href="../../../_static/facebox.css" type="text/css" />
<script type="text/javascript" src="../../../_static/scripts.js">
</script>
<script type="text/javascript" src="../../../_static/facebox.js">
</script>
<script type="text/javascript">
$.facebox.settings.closeImage = "../../../_static/closelabel.png"
$.facebox.settings.loadingImage = "../../../_static/loading.gif"
</script>

<script>
$(document).ready(function() {
  $.getJSON("../../../../versions.json", function(versions) {
    var dropdown = document.createElement("div");
    dropdown.className = "dropdown";
    var button = document.createElement("button");
    button.className = "dropbtn";
    button.innerHTML = "Other Versions";
    var content = document.createElement("div");
    content.className = "dropdown-content";
    dropdown.appendChild(button);
    dropdown.appendChild(content);
    $(".header").prepend(dropdown);
    for (var i = 0; i < versions.length; i++) {
      if (versions[i].substring(0, 1) == "v") {
        versions[i] = [versions[i], versions[i].substring(1)];
      } else {
        versions[i] = [versions[i], versions[i]];
      };
    };
    for (var i = 0; i < versions.length; i++) {
      var a = document.createElement("a");
      a.innerHTML = versions[i][1];
      a.href = "../../../../" + versions[i][0] + "/index.html";
      a.title = versions[i][1];
      $(".dropdown-content").append(a);
    };
  });
});
</script>


  </head><body>
<div class="headerwrap">
    <div class = "header">
        
        <a href = "../../../index.html">
<img src="../../../_static/statsmodels_hybi_banner.png" alt="Logo"
    style="padding-left: 15px"/></a>
        
    </div>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
<li><a href ="../../../install.html">Install</a></li> &nbsp;|&nbsp;
<li><a href="https://groups.google.com/forum/?hl=en#!forum/pystatsmodels">Support</a></li> &nbsp;|&nbsp;
<li><a href="https://github.com/statsmodels/statsmodels/issues">Bugs</a></li> &nbsp;|&nbsp;
<li><a href="../../../dev/index.html">Develop</a></li> &nbsp;|&nbsp;
<li><a href="../../../examples/index.html">Examples</a></li> &nbsp;|&nbsp;
<li><a href="../../../faq.html">FAQ</a></li> &nbsp;|&nbsp;

          <li class="nav-item nav-item-1"><a href="../../index.html" accesskey="U">Module code</a> |</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            




  <h1>Source code for statsmodels.nonparametric.kernel_density</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Multivariate Conditional and Unconditional Kernel Density Estimation</span>
<span class="sd">with Mixed Data Types.</span>

<span class="sd">References</span>
<span class="sd">----------</span>
<span class="sd">[1] Racine, J., Li, Q. Nonparametric econometrics: theory and practice.</span>
<span class="sd">    Princeton University Press. (2007)</span>
<span class="sd">[2] Racine, Jeff. &quot;Nonparametric Econometrics: A Primer,&quot; Foundation</span>
<span class="sd">    and Trends in Econometrics: Vol 3: No 1, pp1-88. (2008)</span>
<span class="sd">    http://dx.doi.org/10.1561/0800000009</span>
<span class="sd">[3] Racine, J., Li, Q. &quot;Nonparametric Estimation of Distributions</span>
<span class="sd">    with Categorical and Continuous Data.&quot; Working Paper. (2000)</span>
<span class="sd">[4] Racine, J. Li, Q. &quot;Kernel Estimation of Multivariate Conditional</span>
<span class="sd">    Distributions Annals of Economics and Finance 5, 211-235 (2004)</span>
<span class="sd">[5] Liu, R., Yang, L. &quot;Kernel estimation of multivariate</span>
<span class="sd">    cumulative distribution function.&quot;</span>
<span class="sd">    Journal of Nonparametric Statistics (2008)</span>
<span class="sd">[6] Li, R., Ju, G. &quot;Nonparametric Estimation of Multivariate CDF</span>
<span class="sd">    with Categorical and Continuous Data.&quot; Working Paper</span>
<span class="sd">[7] Li, Q., Racine, J. &quot;Cross-validated local linear nonparametric</span>
<span class="sd">    regression&quot; Statistica Sinica 14(2004), pp. 485-512</span>
<span class="sd">[8] Racine, J.: &quot;Consistent Significance Testing for Nonparametric</span>
<span class="sd">        Regression&quot; Journal of Business &amp; Economics Statistics</span>
<span class="sd">[9] Racine, J., Hart, J., Li, Q., &quot;Testing the Significance of</span>
<span class="sd">        Categorical Predictor Variables in Nonparametric Regression</span>
<span class="sd">        Models&quot;, 2006, Econometric Reviews 25, 523-544</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="c1"># TODO: make default behavior efficient=True above a certain n_obs</span>

<span class="kn">from</span> <span class="nn">statsmodels.compat.python</span> <span class="k">import</span> <span class="nb">range</span><span class="p">,</span> <span class="nb">next</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">kernels</span>
<span class="kn">from</span> <span class="nn">._kernel_base</span> <span class="k">import</span> <span class="n">GenericKDE</span><span class="p">,</span> <span class="n">EstimatorSettings</span><span class="p">,</span> <span class="n">gpke</span><span class="p">,</span> \
    <span class="n">LeaveOneOut</span><span class="p">,</span> <span class="n">_adjust_shape</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;KDEMultivariate&#39;</span><span class="p">,</span> <span class="s1">&#39;KDEMultivariateConditional&#39;</span><span class="p">,</span> <span class="s1">&#39;EstimatorSettings&#39;</span><span class="p">]</span>


<div class="viewcode-block" id="KDEMultivariate"><a class="viewcode-back" href="../../../generated/statsmodels.nonparametric.kernel_density.KDEMultivariate.html#statsmodels.nonparametric.kernel_density.KDEMultivariate">[docs]</a><span class="k">class</span> <span class="nc">KDEMultivariate</span><span class="p">(</span><span class="n">GenericKDE</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Multivariate kernel density estimator.</span>

<span class="sd">    This density estimator can handle univariate as well as multivariate data,</span>
<span class="sd">    including mixed continuous / ordered discrete / unordered discrete data.</span>
<span class="sd">    It also provides cross-validated bandwidth selection methods (least</span>
<span class="sd">    squares, maximum likelihood).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data: list of ndarrays or 2-D ndarray</span>
<span class="sd">        The training data for the Kernel Density Estimation, used to determine</span>
<span class="sd">        the bandwidth(s).  If a 2-D array, should be of shape</span>
<span class="sd">        (num_observations, num_variables).  If a list, each list element is a</span>
<span class="sd">        separate observation.</span>
<span class="sd">    var_type: str</span>
<span class="sd">        The type of the variables:</span>

<span class="sd">            - c : continuous</span>
<span class="sd">            - u : unordered (discrete)</span>
<span class="sd">            - o : ordered (discrete)</span>

<span class="sd">        The string should contain a type specifier for each variable, so for</span>
<span class="sd">        example ``var_type=&#39;ccuo&#39;``.</span>
<span class="sd">    bw: array_like or str, optional</span>
<span class="sd">        If an array, it is a fixed user-specified bandwidth.  If a string,</span>
<span class="sd">        should be one of:</span>

<span class="sd">            - normal_reference: normal reference rule of thumb (default)</span>
<span class="sd">            - cv_ml: cross validation maximum likelihood</span>
<span class="sd">            - cv_ls: cross validation least squares</span>

<span class="sd">    defaults: EstimatorSettings instance, optional</span>
<span class="sd">        The default values for (efficient) bandwidth estimation.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    bw: array_like</span>
<span class="sd">        The bandwidth parameters.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    KDEMultivariateConditional</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import statsmodels.api as sm</span>
<span class="sd">    &gt;&gt;&gt; nobs = 300</span>
<span class="sd">    &gt;&gt;&gt; np.random.seed(1234)  # Seed random generator</span>
<span class="sd">    &gt;&gt;&gt; c1 = np.random.normal(size=(nobs,1))</span>
<span class="sd">    &gt;&gt;&gt; c2 = np.random.normal(2, 1, size=(nobs,1))</span>

<span class="sd">    Estimate a bivariate distribution and display the bandwidth found:</span>

<span class="sd">    &gt;&gt;&gt; dens_u = sm.nonparametric.KDEMultivariate(data=[c1,c2],</span>
<span class="sd">    ...     var_type=&#39;cc&#39;, bw=&#39;normal_reference&#39;)</span>
<span class="sd">    &gt;&gt;&gt; dens_u.bw</span>
<span class="sd">    array([ 0.39967419,  0.38423292])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">var_type</span><span class="p">,</span> <span class="n">bw</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">defaults</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span> <span class="o">=</span> <span class="n">var_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_vars</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">_adjust_shape</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_vars</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_type</span> <span class="o">=</span> <span class="n">var_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nobs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_vars</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nobs</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_vars</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The number of observations must be larger &quot;</span> \
                             <span class="s2">&quot;than the number of variables.&quot;</span><span class="p">)</span>
        <span class="n">defaults</span> <span class="o">=</span> <span class="n">EstimatorSettings</span><span class="p">()</span> <span class="k">if</span> <span class="n">defaults</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">defaults</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_defaults</span><span class="p">(</span><span class="n">defaults</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">efficient</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_bw</span><span class="p">(</span><span class="n">bw</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_efficient</span><span class="p">(</span><span class="n">bw</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Provide something sane to print.&quot;&quot;&quot;</span>
        <span class="n">rpr</span> <span class="o">=</span> <span class="s2">&quot;KDE instance</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">rpr</span> <span class="o">+=</span> <span class="s2">&quot;Number of variables: k_vars = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k_vars</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">rpr</span> <span class="o">+=</span> <span class="s2">&quot;Number of samples:   nobs = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nobs</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">rpr</span> <span class="o">+=</span> <span class="s2">&quot;Variable types:      &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">rpr</span> <span class="o">+=</span> <span class="s2">&quot;BW selection method: &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bw_method</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">return</span> <span class="n">rpr</span>

<div class="viewcode-block" id="KDEMultivariate.loo_likelihood"><a class="viewcode-back" href="../../../generated/statsmodels.nonparametric.kernel_density.KDEMultivariate.loo_likelihood.html#statsmodels.nonparametric.kernel_density.KDEMultivariate.loo_likelihood">[docs]</a>    <span class="k">def</span> <span class="nf">loo_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bw</span><span class="p">,</span> <span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the leave-one-out likelihood function.</span>

<span class="sd">        The leave-one-out likelihood function for the unconditional KDE.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        bw: array_like</span>
<span class="sd">            The value for the bandwidth parameter(s).</span>
<span class="sd">        func: callable, optional</span>
<span class="sd">            Function to transform the likelihood values (before summing); for</span>
<span class="sd">            the log likelihood, use ``func=np.log``.  Default is ``f(x) = x``.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The leave-one-out kernel estimator of :math:`f_{-i}` is:</span>

<span class="sd">        .. math:: f_{-i}(X_{i})=\frac{1}{(n-1)h}</span>
<span class="sd">                    \sum_{j=1,j\neq i}K_{h}(X_{i},X_{j})</span>

<span class="sd">        where :math:`K_{h}` represents the generalized product kernel</span>
<span class="sd">        estimator:</span>

<span class="sd">        .. math:: K_{h}(X_{i},X_{j}) =</span>
<span class="sd">            \prod_{s=1}^{q}h_{s}^{-1}k\left(\frac{X_{is}-X_{js}}{h_{s}}\right)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">LOO</span> <span class="o">=</span> <span class="n">LeaveOneOut</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="n">L</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">X_not_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">LOO</span><span class="p">):</span>
            <span class="n">f_i</span> <span class="o">=</span> <span class="n">gpke</span><span class="p">(</span><span class="n">bw</span><span class="p">,</span> <span class="n">data</span><span class="o">=-</span><span class="n">X_not_i</span><span class="p">,</span> <span class="n">data_predict</span><span class="o">=-</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span>
                       <span class="n">var_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)</span>
            <span class="n">L</span> <span class="o">+=</span> <span class="n">func</span><span class="p">(</span><span class="n">f_i</span><span class="p">)</span>

        <span class="k">return</span> <span class="o">-</span><span class="n">L</span></div>

<div class="viewcode-block" id="KDEMultivariate.pdf"><a class="viewcode-back" href="../../../generated/statsmodels.nonparametric.kernel_density.KDEMultivariate.pdf.html#statsmodels.nonparametric.kernel_density.KDEMultivariate.pdf">[docs]</a>    <span class="k">def</span> <span class="nf">pdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_predict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the probability density function.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data_predict: array_like, optional</span>
<span class="sd">            Points to evaluate at.  If unspecified, the training data is used.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        pdf_est: array_like</span>
<span class="sd">            Probability density function evaluated at `data_predict`.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The probability density is given by the generalized product kernel</span>
<span class="sd">        estimator:</span>

<span class="sd">        .. math:: K_{h}(X_{i},X_{j}) =</span>
<span class="sd">            \prod_{s=1}^{q}h_{s}^{-1}k\left(\frac{X_{is}-X_{js}}{h_{s}}\right)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">data_predict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">data_predict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">data_predict</span> <span class="o">=</span> <span class="n">_adjust_shape</span><span class="p">(</span><span class="n">data_predict</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_vars</span><span class="p">)</span>

        <span class="n">pdf_est</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">data_predict</span><span class="p">)[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">pdf_est</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gpke</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bw</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
                                <span class="n">data_predict</span><span class="o">=</span><span class="n">data_predict</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span>
                                <span class="n">var_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nobs</span><span class="p">)</span>

        <span class="n">pdf_est</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">pdf_est</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pdf_est</span></div>

<div class="viewcode-block" id="KDEMultivariate.cdf"><a class="viewcode-back" href="../../../generated/statsmodels.nonparametric.kernel_density.KDEMultivariate.cdf.html#statsmodels.nonparametric.kernel_density.KDEMultivariate.cdf">[docs]</a>    <span class="k">def</span> <span class="nf">cdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_predict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the cumulative distribution function.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data_predict: array_like, optional</span>
<span class="sd">            Points to evaluate at.  If unspecified, the training data is used.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        cdf_est: array_like</span>
<span class="sd">            The estimate of the cdf.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        See http://en.wikipedia.org/wiki/Cumulative_distribution_function</span>
<span class="sd">        For more details on the estimation see Ref. [5] in module docstring.</span>

<span class="sd">        The multivariate CDF for mixed data (continuous and ordered/unordered</span>
<span class="sd">        discrete) is estimated by:</span>

<span class="sd">        .. math::</span>

<span class="sd">            F(x^{c},x^{d})=n^{-1}\sum_{i=1}^{n}\left[G(\frac{x^{c}-X_{i}}{h})\sum_{u\leq x^{d}}L(X_{i}^{d},x_{i}^{d}, \lambda)\right]</span>

<span class="sd">        where G() is the product kernel CDF estimator for the continuous</span>
<span class="sd">        and L() for the discrete variables.</span>

<span class="sd">        Used bandwidth is ``self.bw``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">data_predict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">data_predict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">data_predict</span> <span class="o">=</span> <span class="n">_adjust_shape</span><span class="p">(</span><span class="n">data_predict</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_vars</span><span class="p">)</span>

        <span class="n">cdf_est</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">data_predict</span><span class="p">)[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">cdf_est</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gpke</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bw</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
                                <span class="n">data_predict</span><span class="o">=</span><span class="n">data_predict</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span>
                                <span class="n">var_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">,</span>
                                <span class="n">ckertype</span><span class="o">=</span><span class="s2">&quot;gaussian_cdf&quot;</span><span class="p">,</span>
                                <span class="n">ukertype</span><span class="o">=</span><span class="s2">&quot;aitchisonaitken_cdf&quot;</span><span class="p">,</span>
                                <span class="n">okertype</span><span class="o">=</span><span class="s1">&#39;wangryzin_cdf&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nobs</span><span class="p">)</span>

        <span class="n">cdf_est</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">cdf_est</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cdf_est</span></div>

<div class="viewcode-block" id="KDEMultivariate.imse"><a class="viewcode-back" href="../../../generated/statsmodels.nonparametric.kernel_density.KDEMultivariate.imse.html#statsmodels.nonparametric.kernel_density.KDEMultivariate.imse">[docs]</a>    <span class="k">def</span> <span class="nf">imse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bw</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the Integrated Mean Square Error for the unconditional KDE.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        bw: array_like</span>
<span class="sd">            The bandwidth parameter(s).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        CV: float</span>
<span class="sd">            The cross-validation objective function.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        See p. 27 in [1]_ for details on how to handle the multivariate</span>
<span class="sd">        estimation with mixed data types see p.6 in [2]_.</span>

<span class="sd">        The formula for the cross-validation objective function is:</span>

<span class="sd">        .. math:: CV=\frac{1}{n^{2}}\sum_{i=1}^{n}\sum_{j=1}^{N}</span>
<span class="sd">            \bar{K}_{h}(X_{i},X_{j})-\frac{2}{n(n-1)}\sum_{i=1}^{n}</span>
<span class="sd">            \sum_{j=1,j\neq i}^{N}K_{h}(X_{i},X_{j})</span>

<span class="sd">        Where :math:`\bar{K}_{h}` is the multivariate product convolution</span>
<span class="sd">        kernel (consult [2]_ for mixed data types).</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        .. [1] Racine, J., Li, Q. Nonparametric econometrics: theory and</span>
<span class="sd">                practice. Princeton University Press. (2007)</span>
<span class="sd">        .. [2] Racine, J., Li, Q. &quot;Nonparametric Estimation of Distributions</span>
<span class="sd">                with Categorical and Continuous Data.&quot; Working Paper. (2000)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">#F = 0</span>
        <span class="c1">#for i in range(self.nobs):</span>
        <span class="c1">#    k_bar_sum = gpke(bw, data=-self.data,</span>
        <span class="c1">#                     data_predict=-self.data[i, :],</span>
        <span class="c1">#                     var_type=self.var_type,</span>
        <span class="c1">#                     ckertype=&#39;gauss_convolution&#39;,</span>
        <span class="c1">#                     okertype=&#39;wangryzin_convolution&#39;,</span>
        <span class="c1">#                     ukertype=&#39;aitchisonaitken_convolution&#39;)</span>
        <span class="c1">#    F += k_bar_sum</span>
        <span class="c1">## there is a + because loo_likelihood returns the negative</span>
        <span class="c1">#return (F / self.nobs**2 + self.loo_likelihood(bw) * \</span>
        <span class="c1">#        2 / ((self.nobs) * (self.nobs - 1)))</span>

        <span class="c1"># The code below is equivalent to the commented-out code above.  It&#39;s</span>
        <span class="c1"># about 20% faster due to some code being moved outside the for-loops</span>
        <span class="c1"># and shared by gpke() and loo_likelihood().</span>
        <span class="n">F</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">kertypes</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="n">kernels</span><span class="o">.</span><span class="n">gaussian_convolution</span><span class="p">,</span>
                        <span class="n">o</span><span class="o">=</span><span class="n">kernels</span><span class="o">.</span><span class="n">wang_ryzin_convolution</span><span class="p">,</span>
                        <span class="n">u</span><span class="o">=</span><span class="n">kernels</span><span class="o">.</span><span class="n">aitchison_aitken_convolution</span><span class="p">)</span>
        <span class="n">nobs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nobs</span>
        <span class="n">data</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span>
        <span class="n">var_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span>
        <span class="n">ix_cont</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">c</span> <span class="o">==</span> <span class="s1">&#39;c&#39;</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">var_type</span><span class="p">])</span>
        <span class="n">_bw_cont_product</span> <span class="o">=</span> <span class="n">bw</span><span class="p">[</span><span class="n">ix_cont</span><span class="p">]</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>
        <span class="n">Kval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nobs</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">vtype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">var_type</span><span class="p">):</span>
                <span class="n">Kval</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">kertypes</span><span class="p">[</span><span class="n">vtype</span><span class="p">](</span><span class="n">bw</span><span class="p">[</span><span class="n">ii</span><span class="p">],</span>
                                              <span class="n">data</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">],</span>
                                              <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">ii</span><span class="p">])</span>

            <span class="n">dens</span> <span class="o">=</span> <span class="n">Kval</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">_bw_cont_product</span>
            <span class="n">k_bar_sum</span> <span class="o">=</span> <span class="n">dens</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">F</span> <span class="o">+=</span> <span class="n">k_bar_sum</span>  <span class="c1"># sum of prod kernel over nobs</span>

        <span class="n">kertypes</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="n">kernels</span><span class="o">.</span><span class="n">gaussian</span><span class="p">,</span>
                        <span class="n">o</span><span class="o">=</span><span class="n">kernels</span><span class="o">.</span><span class="n">wang_ryzin</span><span class="p">,</span>
                        <span class="n">u</span><span class="o">=</span><span class="n">kernels</span><span class="o">.</span><span class="n">aitchison_aitken</span><span class="p">)</span>
        <span class="n">LOO</span> <span class="o">=</span> <span class="n">LeaveOneOut</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="n">L</span> <span class="o">=</span> <span class="mi">0</span>   <span class="c1"># leave-one-out likelihood</span>
        <span class="n">Kval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">X_not_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">LOO</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">vtype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">var_type</span><span class="p">):</span>
                <span class="n">Kval</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">kertypes</span><span class="p">[</span><span class="n">vtype</span><span class="p">](</span><span class="n">bw</span><span class="p">[</span><span class="n">ii</span><span class="p">],</span>
                                              <span class="o">-</span><span class="n">X_not_i</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">],</span>
                                              <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">ii</span><span class="p">])</span>
            <span class="n">dens</span> <span class="o">=</span> <span class="n">Kval</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">_bw_cont_product</span>
            <span class="n">L</span> <span class="o">+=</span> <span class="n">dens</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># CV objective function, eq. (2.4) of Ref. [3]</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">F</span> <span class="o">/</span> <span class="n">nobs</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">L</span> <span class="o">/</span> <span class="p">(</span><span class="n">nobs</span> <span class="o">*</span> <span class="p">(</span><span class="n">nobs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)))</span></div>

    <span class="k">def</span> <span class="nf">_get_class_vars_type</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Helper method to be able to pass needed vars to _compute_subset.&quot;&quot;&quot;</span>
        <span class="n">class_type</span> <span class="o">=</span> <span class="s1">&#39;KDEMultivariate&#39;</span>
        <span class="n">class_vars</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">,</span> <span class="p">)</span>
        <span class="k">return</span> <span class="n">class_type</span><span class="p">,</span> <span class="n">class_vars</span></div>


<div class="viewcode-block" id="KDEMultivariateConditional"><a class="viewcode-back" href="../../../generated/statsmodels.nonparametric.kernel_density.KDEMultivariateConditional.html#statsmodels.nonparametric.kernel_density.KDEMultivariateConditional">[docs]</a><span class="k">class</span> <span class="nc">KDEMultivariateConditional</span><span class="p">(</span><span class="n">GenericKDE</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Conditional multivariate kernel density estimator.</span>

<span class="sd">    Calculates ``P(Y_1,Y_2,...Y_n | X_1,X_2...X_m) =</span>
<span class="sd">    P(X_1, X_2,...X_n, Y_1, Y_2,..., Y_m)/P(X_1, X_2,..., X_m)``.</span>
<span class="sd">    The conditional density is by definition the ratio of the two densities,</span>
<span class="sd">    see [1]_.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    endog: list of ndarrays or 2-D ndarray</span>
<span class="sd">        The training data for the dependent variables, used to determine</span>
<span class="sd">        the bandwidth(s).  If a 2-D array, should be of shape</span>
<span class="sd">        (num_observations, num_variables).  If a list, each list element is a</span>
<span class="sd">        separate observation.</span>
<span class="sd">    exog: list of ndarrays or 2-D ndarray</span>
<span class="sd">        The training data for the independent variable; same shape as `endog`.</span>
<span class="sd">    dep_type: str</span>
<span class="sd">        The type of the dependent variables:</span>

<span class="sd">            c : Continuous</span>
<span class="sd">            u : Unordered (Discrete)</span>
<span class="sd">            o : Ordered (Discrete)</span>

<span class="sd">        The string should contain a type specifier for each variable, so for</span>
<span class="sd">        example ``dep_type=&#39;ccuo&#39;``.</span>
<span class="sd">    indep_type: str</span>
<span class="sd">        The type of the independent variables; specifed like `dep_type`.</span>
<span class="sd">    bw: array_like or str, optional</span>
<span class="sd">        If an array, it is a fixed user-specified bandwidth.  If a string,</span>
<span class="sd">        should be one of:</span>

<span class="sd">            - normal_reference: normal reference rule of thumb (default)</span>
<span class="sd">            - cv_ml: cross validation maximum likelihood</span>
<span class="sd">            - cv_ls: cross validation least squares</span>

<span class="sd">    defaults: Instance of class EstimatorSettings</span>
<span class="sd">        The default values for the efficient bandwidth estimation</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    bw: array_like</span>
<span class="sd">        The bandwidth parameters</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    KDEMultivariate</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] http://en.wikipedia.org/wiki/Conditional_probability_distribution</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import statsmodels.api as sm</span>
<span class="sd">    &gt;&gt;&gt; nobs = 300</span>
<span class="sd">    &gt;&gt;&gt; c1 = np.random.normal(size=(nobs,1))</span>
<span class="sd">    &gt;&gt;&gt; c2 = np.random.normal(2,1,size=(nobs,1))</span>

<span class="sd">    &gt;&gt;&gt; dens_c = sm.nonparametric.KDEMultivariateConditional(endog=[c1],</span>
<span class="sd">    ...     exog=[c2], dep_type=&#39;c&#39;, indep_type=&#39;c&#39;, bw=&#39;normal_reference&#39;)</span>
<span class="sd">    &gt;&gt;&gt; dens_c.bw   # show computed bandwidth</span>
<span class="sd">    array([ 0.41223484,  0.40976931])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="n">dep_type</span><span class="p">,</span> <span class="n">indep_type</span><span class="p">,</span> <span class="n">bw</span><span class="p">,</span>
                 <span class="n">defaults</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dep_type</span> <span class="o">=</span> <span class="n">dep_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">indep_type</span> <span class="o">=</span> <span class="n">indep_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_type</span> <span class="o">=</span> <span class="n">dep_type</span> <span class="o">+</span> <span class="n">indep_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dep_type</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_indep</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">indep_type</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">endog</span> <span class="o">=</span> <span class="n">_adjust_shape</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exog</span> <span class="o">=</span> <span class="n">_adjust_shape</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_indep</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nobs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">endog</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_vars</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">defaults</span> <span class="o">=</span> <span class="n">EstimatorSettings</span><span class="p">()</span> <span class="k">if</span> <span class="n">defaults</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">defaults</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_defaults</span><span class="p">(</span><span class="n">defaults</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">efficient</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_bw</span><span class="p">(</span><span class="n">bw</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_efficient</span><span class="p">(</span><span class="n">bw</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Provide something sane to print.&quot;&quot;&quot;</span>
        <span class="n">rpr</span> <span class="o">=</span> <span class="s2">&quot;KDEMultivariateConditional instance</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">rpr</span> <span class="o">+=</span> <span class="s2">&quot;Number of independent variables: k_indep = &quot;</span> <span class="o">+</span> \
               <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k_indep</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">rpr</span> <span class="o">+=</span> <span class="s2">&quot;Number of dependent variables: k_dep = &quot;</span> <span class="o">+</span> \
               <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">rpr</span> <span class="o">+=</span> <span class="s2">&quot;Number of observations: nobs = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nobs</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">rpr</span> <span class="o">+=</span> <span class="s2">&quot;Independent variable types:      &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">indep_type</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">rpr</span> <span class="o">+=</span> <span class="s2">&quot;Dependent variable types:      &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dep_type</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">rpr</span> <span class="o">+=</span> <span class="s2">&quot;BW selection method: &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bw_method</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">return</span> <span class="n">rpr</span>

<div class="viewcode-block" id="KDEMultivariateConditional.loo_likelihood"><a class="viewcode-back" href="../../../generated/statsmodels.nonparametric.kernel_density.KDEMultivariateConditional.loo_likelihood.html#statsmodels.nonparametric.kernel_density.KDEMultivariateConditional.loo_likelihood">[docs]</a>    <span class="k">def</span> <span class="nf">loo_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bw</span><span class="p">,</span> <span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the leave-one-out conditional likelihood of the data.</span>

<span class="sd">        If `func` is not equal to the default, what&#39;s calculated is a function</span>
<span class="sd">        of the leave-one-out conditional likelihood.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        bw: array_like</span>
<span class="sd">            The bandwidth parameter(s).</span>
<span class="sd">        func: callable, optional</span>
<span class="sd">            Function to transform the likelihood values (before summing); for</span>
<span class="sd">            the log likelihood, use ``func=np.log``.  Default is ``f(x) = x``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        L: float</span>
<span class="sd">            The value of the leave-one-out function for the data.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Similar to ``KDE.loo_likelihood`, but substitute ``f(y|x)=f(x,y)/f(x)``</span>
<span class="sd">        for ``f(x)``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">yLOO</span> <span class="o">=</span> <span class="n">LeaveOneOut</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="n">xLOO</span> <span class="o">=</span> <span class="n">LeaveOneOut</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="p">)</span><span class="o">.</span><span class="fm">__iter__</span><span class="p">()</span>
        <span class="n">L</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">Y_j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">yLOO</span><span class="p">):</span>
            <span class="n">X_not_i</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">xLOO</span><span class="p">)</span>
            <span class="n">f_yx</span> <span class="o">=</span> <span class="n">gpke</span><span class="p">(</span><span class="n">bw</span><span class="p">,</span> <span class="n">data</span><span class="o">=-</span><span class="n">Y_j</span><span class="p">,</span> <span class="n">data_predict</span><span class="o">=-</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span>
                        <span class="n">var_type</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dep_type</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">indep_type</span><span class="p">))</span>
            <span class="n">f_x</span> <span class="o">=</span> <span class="n">gpke</span><span class="p">(</span><span class="n">bw</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span><span class="p">:],</span> <span class="n">data</span><span class="o">=-</span><span class="n">X_not_i</span><span class="p">,</span>
                       <span class="n">data_predict</span><span class="o">=-</span><span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span>
                       <span class="n">var_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">indep_type</span><span class="p">)</span>
            <span class="n">f_i</span> <span class="o">=</span> <span class="n">f_yx</span> <span class="o">/</span> <span class="n">f_x</span>
            <span class="n">L</span> <span class="o">+=</span> <span class="n">func</span><span class="p">(</span><span class="n">f_i</span><span class="p">)</span>

        <span class="k">return</span> <span class="o">-</span><span class="n">L</span></div>

<div class="viewcode-block" id="KDEMultivariateConditional.pdf"><a class="viewcode-back" href="../../../generated/statsmodels.nonparametric.kernel_density.KDEMultivariateConditional.pdf.html#statsmodels.nonparametric.kernel_density.KDEMultivariateConditional.pdf">[docs]</a>    <span class="k">def</span> <span class="nf">pdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">endog_predict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exog_predict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the probability density function.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        endog_predict: array_like, optional</span>
<span class="sd">            Evaluation data for the dependent variables.  If unspecified, the</span>
<span class="sd">            training data is used.</span>
<span class="sd">        exog_predict: array_like, optional</span>
<span class="sd">            Evaluation data for the independent variables.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        pdf: array_like</span>
<span class="sd">            The value of the probability density at `endog_predict` and `exog_predict`.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The formula for the conditional probability density is:</span>

<span class="sd">        .. math:: f(y|x)=\frac{f(x,y)}{f(x)}</span>

<span class="sd">        with</span>

<span class="sd">        .. math:: f(x)=\prod_{s=1}^{q}h_{s}^{-1}k</span>
<span class="sd">                            \left(\frac{x_{is}-x_{js}}{h_{s}}\right)</span>

<span class="sd">        where :math:`k` is the appropriate kernel for each variable.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">endog_predict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">endog_predict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">endog</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">endog_predict</span> <span class="o">=</span> <span class="n">_adjust_shape</span><span class="p">(</span><span class="n">endog_predict</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">exog_predict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">exog_predict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">exog_predict</span> <span class="o">=</span> <span class="n">_adjust_shape</span><span class="p">(</span><span class="n">exog_predict</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_indep</span><span class="p">)</span>

        <span class="n">pdf_est</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">data_predict</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">endog_predict</span><span class="p">,</span> <span class="n">exog_predict</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">data_predict</span><span class="p">)[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">f_yx</span> <span class="o">=</span> <span class="n">gpke</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bw</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
                        <span class="n">data_predict</span><span class="o">=</span><span class="n">data_predict</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span>
                        <span class="n">var_type</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dep_type</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">indep_type</span><span class="p">))</span>
            <span class="n">f_x</span> <span class="o">=</span> <span class="n">gpke</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bw</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span><span class="p">:],</span> <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="p">,</span>
                       <span class="n">data_predict</span><span class="o">=</span><span class="n">exog_predict</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span>
                       <span class="n">var_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">indep_type</span><span class="p">)</span>
            <span class="n">pdf_est</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f_yx</span> <span class="o">/</span> <span class="n">f_x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">pdf_est</span><span class="p">)</span></div>

<div class="viewcode-block" id="KDEMultivariateConditional.cdf"><a class="viewcode-back" href="../../../generated/statsmodels.nonparametric.kernel_density.KDEMultivariateConditional.cdf.html#statsmodels.nonparametric.kernel_density.KDEMultivariateConditional.cdf">[docs]</a>    <span class="k">def</span> <span class="nf">cdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">endog_predict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exog_predict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Cumulative distribution function for the conditional density.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        endog_predict: array_like, optional</span>
<span class="sd">            The evaluation dependent variables at which the cdf is estimated.</span>
<span class="sd">            If not specified the training dependent variables are used.</span>
<span class="sd">        exog_predict: array_like, optional</span>
<span class="sd">            The evaluation independent variables at which the cdf is estimated.</span>
<span class="sd">            If not specified the training independent variables are used.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        cdf_est: array_like</span>
<span class="sd">            The estimate of the cdf.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        For more details on the estimation see [2]_, and p.181 in [1]_.</span>

<span class="sd">        The multivariate conditional CDF for mixed data (continuous and</span>
<span class="sd">        ordered/unordered discrete) is estimated by:</span>

<span class="sd">        .. math::</span>

<span class="sd">            F(y|x)=\frac{n^{-1}\sum_{i=1}^{n}G(\frac{y-Y_{i}}{h_{0}}) W_{h}(X_{i},x)}{\widehat{\mu}(x)}</span>

<span class="sd">        where G() is the product kernel CDF estimator for the dependent (y)</span>
<span class="sd">        variable(s) and W() is the product kernel CDF estimator for the</span>
<span class="sd">        independent variable(s).</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        .. [1] Racine, J., Li, Q. Nonparametric econometrics: theory and</span>
<span class="sd">                practice. Princeton University Press. (2007)</span>
<span class="sd">        .. [2] Liu, R., Yang, L. &quot;Kernel estimation of multivariate cumulative</span>
<span class="sd">                    distribution function.&quot; Journal of Nonparametric</span>
<span class="sd">                    Statistics (2008)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">endog_predict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">endog_predict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">endog</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">endog_predict</span> <span class="o">=</span> <span class="n">_adjust_shape</span><span class="p">(</span><span class="n">endog_predict</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">exog_predict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">exog_predict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">exog_predict</span> <span class="o">=</span> <span class="n">_adjust_shape</span><span class="p">(</span><span class="n">exog_predict</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_indep</span><span class="p">)</span>

        <span class="n">N_data_predict</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">exog_predict</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">cdf_est</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">N_data_predict</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_data_predict</span><span class="p">):</span>
            <span class="n">mu_x</span> <span class="o">=</span> <span class="n">gpke</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bw</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span><span class="p">:],</span> <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="p">,</span>
                        <span class="n">data_predict</span><span class="o">=</span><span class="n">exog_predict</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span>
                        <span class="n">var_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">indep_type</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nobs</span>
            <span class="n">mu_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">mu_x</span><span class="p">)</span>
            <span class="n">cdf_endog</span> <span class="o">=</span> <span class="n">gpke</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bw</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span>
                             <span class="n">data_predict</span><span class="o">=</span><span class="n">endog_predict</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span>
                             <span class="n">var_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dep_type</span><span class="p">,</span>
                             <span class="n">ckertype</span><span class="o">=</span><span class="s2">&quot;gaussian_cdf&quot;</span><span class="p">,</span>
                             <span class="n">ukertype</span><span class="o">=</span><span class="s2">&quot;aitchisonaitken_cdf&quot;</span><span class="p">,</span>
                             <span class="n">okertype</span><span class="o">=</span><span class="s1">&#39;wangryzin_cdf&#39;</span><span class="p">,</span> <span class="n">tosum</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">cdf_exog</span> <span class="o">=</span> <span class="n">gpke</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bw</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span><span class="p">:],</span> <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="p">,</span>
                            <span class="n">data_predict</span><span class="o">=</span><span class="n">exog_predict</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span>
                            <span class="n">var_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">indep_type</span><span class="p">,</span> <span class="n">tosum</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">S</span> <span class="o">=</span> <span class="p">(</span><span class="n">cdf_endog</span> <span class="o">*</span> <span class="n">cdf_exog</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">cdf_est</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">S</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nobs</span> <span class="o">*</span> <span class="n">mu_x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">cdf_est</span></div>

<div class="viewcode-block" id="KDEMultivariateConditional.imse"><a class="viewcode-back" href="../../../generated/statsmodels.nonparametric.kernel_density.KDEMultivariateConditional.imse.html#statsmodels.nonparametric.kernel_density.KDEMultivariateConditional.imse">[docs]</a>    <span class="k">def</span> <span class="nf">imse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bw</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The integrated mean square error for the conditional KDE.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        bw: array_like</span>
<span class="sd">            The bandwidth parameter(s).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        CV: float</span>
<span class="sd">            The cross-validation objective function.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        For more details see pp. 156-166 in [1]_. For details on how to</span>
<span class="sd">        handle the mixed variable types see [2]_.</span>

<span class="sd">        The formula for the cross-validation objective function for mixed</span>
<span class="sd">        variable types is:</span>

<span class="sd">        .. math:: CV(h,\lambda)=\frac{1}{n}\sum_{l=1}^{n}</span>
<span class="sd">            \frac{G_{-l}(X_{l})}{\left[\mu_{-l}(X_{l})\right]^{2}}-</span>
<span class="sd">            \frac{2}{n}\sum_{l=1}^{n}\frac{f_{-l}(X_{l},Y_{l})}{\mu_{-l}(X_{l})}</span>

<span class="sd">        where</span>

<span class="sd">        .. math:: G_{-l}(X_{l}) = n^{-2}\sum_{i\neq l}\sum_{j\neq l}</span>
<span class="sd">                        K_{X_{i},X_{l}} K_{X_{j},X_{l}}K_{Y_{i},Y_{j}}^{(2)}</span>

<span class="sd">        where :math:`K_{X_{i},X_{l}}` is the multivariate product kernel and</span>
<span class="sd">        :math:`\mu_{-l}(X_{l})` is the leave-one-out estimator of the pdf.</span>

<span class="sd">        :math:`K_{Y_{i},Y_{j}}^{(2)}` is the convolution kernel.</span>

<span class="sd">        The value of the function is minimized by the ``_cv_ls`` method of the</span>
<span class="sd">        `GenericKDE` class to return the bw estimates that minimize the</span>
<span class="sd">        distance between the estimated and &quot;true&quot; probability density.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        .. [1] Racine, J., Li, Q. Nonparametric econometrics: theory and</span>
<span class="sd">                practice. Princeton University Press. (2007)</span>
<span class="sd">        .. [2] Racine, J., Li, Q. &quot;Nonparametric Estimation of Distributions</span>
<span class="sd">                with Categorical and Continuous Data.&quot; Working Paper. (2000)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">zLOO</span> <span class="o">=</span> <span class="n">LeaveOneOut</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="n">CV</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">nobs</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nobs</span><span class="p">)</span>
        <span class="n">expander</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">nobs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">Z</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">zLOO</span><span class="p">):</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">Z</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span><span class="p">:]</span>
            <span class="n">Y</span> <span class="o">=</span> <span class="n">Z</span><span class="p">[:,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span><span class="p">]</span>
            <span class="n">Ye_L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">expander</span><span class="p">)</span>
            <span class="n">Ye_R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">expander</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
            <span class="n">Xe_L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">expander</span><span class="p">)</span>
            <span class="n">Xe_R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">expander</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
            <span class="n">K_Xi_Xl</span> <span class="o">=</span> <span class="n">gpke</span><span class="p">(</span><span class="n">bw</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span><span class="p">:],</span> <span class="n">data</span><span class="o">=</span><span class="n">Xe_L</span><span class="p">,</span>
                           <span class="n">data_predict</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:],</span>
                           <span class="n">var_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">indep_type</span><span class="p">,</span> <span class="n">tosum</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">K_Xj_Xl</span> <span class="o">=</span> <span class="n">gpke</span><span class="p">(</span><span class="n">bw</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span><span class="p">:],</span> <span class="n">data</span><span class="o">=</span><span class="n">Xe_R</span><span class="p">,</span>
                           <span class="n">data_predict</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:],</span>
                           <span class="n">var_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">indep_type</span><span class="p">,</span> <span class="n">tosum</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">K2_Yi_Yj</span> <span class="o">=</span> <span class="n">gpke</span><span class="p">(</span><span class="n">bw</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">Ye_L</span><span class="p">,</span>
                            <span class="n">data_predict</span><span class="o">=</span><span class="n">Ye_R</span><span class="p">,</span> <span class="n">var_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dep_type</span><span class="p">,</span>
                            <span class="n">ckertype</span><span class="o">=</span><span class="s1">&#39;gauss_convolution&#39;</span><span class="p">,</span>
                            <span class="n">okertype</span><span class="o">=</span><span class="s1">&#39;wangryzin_convolution&#39;</span><span class="p">,</span>
                            <span class="n">ukertype</span><span class="o">=</span><span class="s1">&#39;aitchisonaitken_convolution&#39;</span><span class="p">,</span>
                            <span class="n">tosum</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">G</span> <span class="o">=</span> <span class="p">(</span><span class="n">K_Xi_Xl</span> <span class="o">*</span> <span class="n">K_Xj_Xl</span> <span class="o">*</span> <span class="n">K2_Yi_Yj</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">nobs</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">f_X_Y</span> <span class="o">=</span> <span class="n">gpke</span><span class="p">(</span><span class="n">bw</span><span class="p">,</span> <span class="n">data</span><span class="o">=-</span><span class="n">Z</span><span class="p">,</span> <span class="n">data_predict</span><span class="o">=-</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:],</span>
                         <span class="n">var_type</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dep_type</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">indep_type</span><span class="p">))</span> <span class="o">/</span> <span class="n">nobs</span>
            <span class="n">m_x</span> <span class="o">=</span> <span class="n">gpke</span><span class="p">(</span><span class="n">bw</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span><span class="p">:],</span> <span class="n">data</span><span class="o">=-</span><span class="n">X</span><span class="p">,</span>
                       <span class="n">data_predict</span><span class="o">=-</span><span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:],</span>
                       <span class="n">var_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">indep_type</span><span class="p">)</span> <span class="o">/</span> <span class="n">nobs</span>
            <span class="n">CV</span> <span class="o">+=</span> <span class="p">(</span><span class="n">G</span> <span class="o">/</span> <span class="n">m_x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">f_X_Y</span> <span class="o">/</span> <span class="n">m_x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">CV</span> <span class="o">/</span> <span class="n">nobs</span></div>

    <span class="k">def</span> <span class="nf">_get_class_vars_type</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Helper method to be able to pass needed vars to _compute_subset.&quot;&quot;&quot;</span>
        <span class="n">class_type</span> <span class="o">=</span> <span class="s1">&#39;KDEMultivariateConditional&#39;</span>
        <span class="n">class_vars</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k_dep</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dep_type</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">indep_type</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">class_type</span><span class="p">,</span> <span class="n">class_vars</span></div>
</pre></div>




          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2009-2018, Josef Perktold, Skipper Seabold, Jonathan Taylor, statsmodels-developers.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.2.1.
    </div>
  </body>
</html>