



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../_static/favicon.ico">
    
    
  
      
        <title>statsmodels.gam.generalized_additive_model - statsmodels 0.15.0 (+640)</title>
      
    
  <link rel="icon" type="image/png" sizes="32x32" href="../../../_static/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="../../../_static/icons/favicon-16x16.png">
  <link rel="manifest" href="../../../_static/icons/site.webmanifest">
  <link rel="mask-icon" href="../../../_static/icons/safari-pinned-tab.svg" color="#919191">
  <meta name="msapplication-TileColor" content="#2b5797">
  <meta name="msapplication-config" content="../../../_static/icons/browserconfig.xml">
  <link rel="stylesheet" href="../../../_static/stylesheets/examples.css">
  <link rel="stylesheet" href="../../../_static/stylesheets/deprecation.css">
    
      
        
      
      


    
    
      
    
    
      
        
        
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
        <link rel="stylesheet" type="text/css" href="../../../_static/sphinx_immaterial_theme.96fe8683ff2bd71e9.min.css?v=13adf062" />
        <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=fd3f3429" />
        <link rel="stylesheet" type="text/css" href="../../../_static/plot_directive.css" />
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../index.html" title="statsmodels 0.15.0 (+640)" class="md-header__button md-logo" aria-label="statsmodels 0.15.0 (+640)" data-md-component="logo">
      <img src="../../../_static/statsmodels-logo-v2-bw.svg" alt="logo">
    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            statsmodels 0.15.0 (+640)
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              statsmodels.gam.generalized_additive_model
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/statsmodels/statsmodels/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    statsmodels
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../index.html" title="statsmodels 0.15.0 (+640)" class="md-nav__button md-logo" aria-label="statsmodels 0.15.0 (+640)" data-md-component="logo">
      <img src="../../../_static/statsmodels-logo-v2-bw.svg" alt="logo">
    </a>
    statsmodels 0.15.0 (+640)
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/statsmodels/statsmodels/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    statsmodels
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../install.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/install.rst (reference label)">Installing statsmodels</span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../gettingstarted.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/gettingstarted.rst (reference label)">Getting started</span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/user-guide.rst (reference label)">User Guide</span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/examples/index.rst (reference label)">Examples</span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../api.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/api.rst (reference label)">API Reference</span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../about.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/about.rst (reference label)">About statsmodels</span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dev/index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/dev/index.rst (reference label)">Developer Page</span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../release/index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/release/index.rst (reference label)">Release Notes</span>
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  

<nav class="md-nav md-nav--secondary">
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset" role="main">
                
                
                  


<h1>Source code for statsmodels.gam.generalized_additive_model</h1><div class="highlight"><pre>
<span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Generalized Additive Models</span>

<span class="sd">Author: Luca Puggini</span>
<span class="sd">Author: Josef Perktold</span>

<span class="sd">created on 08/07/2015</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Iterable</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">copy</span>  <span class="c1"># check if needed when dropping python 2.7</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">optimize</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.base._penalized</span><span class="w"> </span><span class="kn">import</span> <span class="n">PenalizedMixin</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.base.wrapper</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">wrap</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.discrete.discrete_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Logit</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.formula._manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">FormulaManager</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.gam.gam_cross_validation.cross_validators</span><span class="w"> </span><span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.gam.gam_cross_validation.gam_cross_validation</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">MultivariateGAMCVPath</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.gam.gam_penalties</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultivariateGamPenalty</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.genmod.generalized_linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">GLM</span><span class="p">,</span>
    <span class="n">GLMResults</span><span class="p">,</span>
    <span class="n">GLMResultsWrapper</span><span class="p">,</span>
    <span class="n">_check_convergence</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.regression.linear_model</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">lm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.tools.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">_is_using_pandas</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.tools.decorators</span><span class="w"> </span><span class="kn">import</span> <span class="n">cache_readonly</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.tools.linalg</span><span class="w"> </span><span class="kn">import</span> <span class="n">matrix_sqrt</span>
<span class="c1"># import statsmodels.regression._tools as reg_tools  # TODO: use this for pirls</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.tools.sm_exceptions</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">PerfectSeparationError</span><span class="p">,</span>
    <span class="n">ValueWarning</span><span class="p">,</span>
<span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_transform_predict_exog</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="n">model_spec</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;transform exog for predict using the formula&#39;s model_spec</span>

<span class="sd">    Note: this is copied from base.model.Results.predict and converted to</span>
<span class="sd">    standalone function with additional options.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">is_pandas</span> <span class="o">=</span> <span class="n">_is_using_pandas</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="n">exog_index</span> <span class="o">=</span> <span class="n">exog</span><span class="o">.</span><span class="n">index</span> <span class="k">if</span> <span class="n">is_pandas</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">model_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">model_spec</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;model_spec&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">model_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="n">exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.formula._manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">FormulaManager</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
            <span class="c1"># we are guessing whether it should be column or row</span>
            <span class="k">if</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exog</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span>
                    <span class="n">exog</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">model_spec</span><span class="o">.</span><span class="n">describe</span><span class="p">()):</span>
                <span class="c1"># assume we need one column</span>
                <span class="n">exog</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># assume we need a row</span>
                <span class="n">exog</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="n">orig_exog_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span>
        <span class="n">is_dict</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>

        <span class="n">exog</span> <span class="o">=</span> <span class="n">FormulaManager</span><span class="p">()</span><span class="o">.</span><span class="n">get_matrices</span><span class="p">(</span><span class="n">model_spec</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="n">pandas</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">orig_exog_len</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_dict</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
            <span class="k">if</span> <span class="n">exog_index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;nan values have been dropped&#39;</span><span class="p">,</span> <span class="n">ValueWarning</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">exog</span> <span class="o">=</span> <span class="n">exog</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="n">exog_index</span><span class="p">)</span>
        <span class="n">exog_index</span> <span class="o">=</span> <span class="n">exog</span><span class="o">.</span><span class="n">index</span>

    <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">exog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">exog</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">exog</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span>
                               <span class="n">model</span><span class="o">.</span><span class="n">exog</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">exog</span> <span class="o">=</span> <span class="n">exog</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">exog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span>  <span class="c1"># needed in count model shape[1]</span>

    <span class="k">return</span> <span class="n">exog</span><span class="p">,</span> <span class="n">exog_index</span>


<div class="viewcode-block" id="GLMGamResults">
<a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGamResults.html#statsmodels.gam.generalized_additive_model.GLMGamResults">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">GLMGamResults</span><span class="p">(</span><span class="n">GLMResults</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Results class for generalized additive models, GAM.</span>

<span class="sd">    This inherits from GLMResults.</span>

<span class="sd">    Warning: some inherited methods might not correctly take account of the</span>
<span class="sd">    penalization</span>

<span class="sd">    GLMGamResults inherits from GLMResults</span>
<span class="sd">    All methods related to the loglikelihood function return the penalized</span>
<span class="sd">    values.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>

<span class="sd">    edf</span>
<span class="sd">        list of effective degrees of freedom for each column of the design</span>
<span class="sd">        matrix.</span>
<span class="sd">    hat_matrix_diag</span>
<span class="sd">        diagonal of hat matrix</span>
<span class="sd">    gcv</span>
<span class="sd">        generalized cross-validation criterion computed as</span>
<span class="sd">        ``gcv = scale / (1. - hat_matrix_trace / self.nobs)**2``</span>
<span class="sd">    cv</span>
<span class="sd">        cross-validation criterion computed as</span>
<span class="sd">        ``cv = ((resid_pearson / (1 - hat_matrix_diag))**2).sum() / nobs``</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    status: experimental</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">normalized_cov_params</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">):</span>

        <span class="c1"># this is a messy way to compute edf and update scale</span>
        <span class="c1"># need several attributes to compute edf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized_cov_params</span> <span class="o">=</span> <span class="n">normalized_cov_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="n">edf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edf</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_model</span> <span class="o">=</span> <span class="n">edf</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># assume constant</span>
        <span class="c1"># need to use nobs or wnobs attribute</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_resid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">endog</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">edf</span>

        <span class="c1"># we are setting the model df for the case when super is using it</span>
        <span class="c1"># df in model will be incorrect state when alpha/pen_weight changes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">df_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">df_resid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_resid</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fittedvalues</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">estimate_scale</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">normalized_cov_params</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_tranform_predict_exog</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exog_smooth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                               <span class="n">transform</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transform original explanatory variables for prediction</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        exog : array_like, optional</span>
<span class="sd">            The values for the linear explanatory variables.</span>
<span class="sd">        exog_smooth : array_like</span>
<span class="sd">            values for the variables in the smooth terms</span>
<span class="sd">        transform : bool, optional</span>
<span class="sd">            If transform is False, then ``exog`` is returned unchanged and</span>
<span class="sd">            ``x`` is ignored. It is assumed that exog contains the full</span>
<span class="sd">            design matrix for the predict observations.</span>
<span class="sd">            If transform is True, then the basis representation of the smooth</span>
<span class="sd">            term will be constructed from the provided ``x``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        exog_transformed : ndarray</span>
<span class="sd">            design matrix for the prediction</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">exog_smooth</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">exog_smooth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">exog_smooth</span><span class="p">)</span>
        <span class="n">exog_index</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">transform</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="c1"># the following allows that either or both exog are not None</span>
            <span class="k">if</span> <span class="n">exog_smooth</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># exog could be None or array</span>
                <span class="n">ex</span> <span class="o">=</span> <span class="n">exog</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">ex</span> <span class="o">=</span> <span class="n">exog_smooth</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">ex</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">exog</span><span class="p">,</span> <span class="n">exog_smooth</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># transform exog_linear if needed</span>
            <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;model_spec_linear&#39;</span><span class="p">):</span>
                <span class="n">exog</span><span class="p">,</span> <span class="n">exog_index</span> <span class="o">=</span> <span class="n">_transform_predict_exog</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_spec_linear</span><span class="p">)</span>

            <span class="c1"># create smooth basis</span>
            <span class="k">if</span> <span class="n">exog_smooth</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ex_smooth</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">smoother</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">exog_smooth</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">ex</span> <span class="o">=</span> <span class="n">ex_smooth</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># TODO: there might be problems is exog_smooth is 1-D</span>
                    <span class="n">ex</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">exog</span><span class="p">,</span> <span class="n">ex_smooth</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">ex</span> <span class="o">=</span> <span class="n">exog</span>

        <span class="k">return</span> <span class="n">ex</span><span class="p">,</span> <span class="n">exog_index</span>

<div class="viewcode-block" id="GLMGamResults.predict">
<a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGamResults.predict.html#statsmodels.gam.generalized_additive_model.GLMGamResults.predict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exog_smooth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;&quot;</span>
<span class="sd">        compute prediction</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        exog : array_like, optional</span>
<span class="sd">            The values for the linear explanatory variables</span>
<span class="sd">        exog_smooth : array_like</span>
<span class="sd">            values for the variables in the smooth terms</span>
<span class="sd">        transform : bool, optional</span>
<span class="sd">            If transform is True, then the basis representation of the smooth</span>
<span class="sd">            term will be constructed from the provided ``exog``.</span>
<span class="sd">        kwargs :</span>
<span class="sd">            Some models can take additional arguments or keywords, see the</span>
<span class="sd">            predict method of the model for the details.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        prediction : ndarray, pandas.Series or pandas.DataFrame</span>
<span class="sd">            predicted values</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ex</span><span class="p">,</span> <span class="n">exog_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tranform_predict_exog</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">,</span>
                                                     <span class="n">exog_smooth</span><span class="o">=</span><span class="n">exog_smooth</span><span class="p">,</span>
                                                     <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
        <span class="n">predict_results</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">ex</span><span class="p">,</span>
                                          <span class="n">transform</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                          <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">exog_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="n">predict_results</span><span class="p">,</span> <span class="s1">&#39;predicted_values&#39;</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">predict_results</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">predict_results</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">exog_index</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">predict_results</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">exog_index</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">predict_results</span></div>


<div class="viewcode-block" id="GLMGamResults.get_prediction">
<a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGamResults.get_prediction.html#statsmodels.gam.generalized_additive_model.GLMGamResults.get_prediction">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exog_smooth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;compute prediction results</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        exog : array_like, optional</span>
<span class="sd">            The values for which you want to predict.</span>
<span class="sd">        exog_smooth : array_like</span>
<span class="sd">            values for the variables in the smooth terms</span>
<span class="sd">        transform : bool, optional</span>
<span class="sd">            If transform is True, then the basis representation of the smooth</span>
<span class="sd">            term will be constructed from the provided ``x``.</span>
<span class="sd">        kwargs :</span>
<span class="sd">            Some models can take additional arguments or keywords, see the</span>
<span class="sd">            predict method of the model for the details.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        prediction_results : generalized_linear_model.PredictionResults</span>
<span class="sd">            The prediction results instance contains prediction and prediction</span>
<span class="sd">            variance and can on demand calculate confidence intervals and</span>
<span class="sd">            summary tables for the prediction of the mean and of new</span>
<span class="sd">            observations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ex</span><span class="p">,</span> <span class="n">exog_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tranform_predict_exog</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">,</span>
                                                     <span class="n">exog_smooth</span><span class="o">=</span><span class="n">exog_smooth</span><span class="p">,</span>
                                                     <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_prediction</span><span class="p">(</span><span class="n">ex</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="GLMGamResults.partial_values">
<a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGamResults.partial_values.html#statsmodels.gam.generalized_additive_model.GLMGamResults.partial_values">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">partial_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smooth_index</span><span class="p">,</span> <span class="n">include_constant</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;contribution of a smooth term to the linear prediction</span>

<span class="sd">        Warning: This will be replaced by a predict method</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        smooth_index : int</span>
<span class="sd">            index of the smooth term within list of smooth terms</span>
<span class="sd">        include_constant : bool</span>
<span class="sd">            If true, then the estimated intercept is added to the prediction</span>
<span class="sd">            and its standard errors. This avoids that the confidence interval</span>
<span class="sd">            has zero width at the imposed identification constraint, e.g.</span>
<span class="sd">            either at a reference point or at the mean.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        predicted : nd_array</span>
<span class="sd">            predicted value of linear term.</span>
<span class="sd">            This is not the expected response if the link function is not</span>
<span class="sd">            linear.</span>
<span class="sd">        se_pred : nd_array</span>
<span class="sd">            standard error of linear prediction</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">variable</span> <span class="o">=</span> <span class="n">smooth_index</span>
        <span class="n">smoother</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">smoother</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">smoother</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span>

        <span class="n">start_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">k_exog_linear</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># smoother has only smooth parts, not exog_linear</span>
        <span class="n">exog_part</span> <span class="o">=</span> <span class="n">smoother</span><span class="o">.</span><span class="n">basis</span><span class="p">[:,</span> <span class="n">mask</span><span class="p">]</span>

        <span class="n">const_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">const_idx</span>
        <span class="k">if</span> <span class="n">include_constant</span> <span class="ow">and</span> <span class="n">const_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(([</span><span class="n">const_idx</span><span class="p">],</span> <span class="n">idx</span><span class="p">))</span>
            <span class="n">exog_part</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">exog</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">]</span>

        <span class="n">linpred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">exog_part</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="c1"># select the submatrix corresponding to a single variable</span>
        <span class="n">partial_cov_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_params</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="n">idx</span><span class="p">)</span>

        <span class="n">covb</span> <span class="o">=</span> <span class="n">partial_cov_params</span>
        <span class="n">var</span> <span class="o">=</span> <span class="p">(</span><span class="n">exog_part</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">covb</span><span class="p">,</span> <span class="n">exog_part</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">linpred</span><span class="p">,</span> <span class="n">se</span></div>


<div class="viewcode-block" id="GLMGamResults.plot_partial">
<a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGamResults.plot_partial.html#statsmodels.gam.generalized_additive_model.GLMGamResults.plot_partial">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">plot_partial</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smooth_index</span><span class="p">,</span> <span class="n">plot_se</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cpr</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                     <span class="n">include_constant</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;plot the contribution of a smooth term to the linear prediction</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        smooth_index : int</span>
<span class="sd">            index of the smooth term within list of smooth terms</span>
<span class="sd">        plot_se : bool</span>
<span class="sd">            If plot_se is true, then the confidence interval for the linear</span>
<span class="sd">            prediction will be added to the plot.</span>
<span class="sd">        cpr : bool</span>
<span class="sd">            If cpr (component plus residual) is true, then a scatter plot of</span>
<span class="sd">            the partial working residuals will be added to the plot.</span>
<span class="sd">        include_constant : bool</span>
<span class="sd">            If true, then the estimated intercept is added to the prediction</span>
<span class="sd">            and its standard errors. This avoids that the confidence interval</span>
<span class="sd">            has zero width at the imposed identification constraint, e.g.</span>
<span class="sd">            either at a reference point or at the mean.</span>
<span class="sd">        ax : None or matplotlib axis instance</span>
<span class="sd">           If ax is not None, then the plot will be added to it.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Figure</span>
<span class="sd">            If `ax` is None, the created figure. Otherwise, the Figure to which</span>
<span class="sd">            `ax` is connected.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.graphics.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_import_mpl</span><span class="p">,</span> <span class="n">create_mpl_ax</span>
        <span class="n">_import_mpl</span><span class="p">()</span>

        <span class="n">variable</span> <span class="o">=</span> <span class="n">smooth_index</span>
        <span class="n">y_est</span><span class="p">,</span> <span class="n">se</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">partial_values</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span>
                                        <span class="n">include_constant</span><span class="o">=</span><span class="n">include_constant</span><span class="p">)</span>
        <span class="n">smoother</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">smoother</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">smoother</span><span class="o">.</span><span class="n">smoothers</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span><span class="o">.</span><span class="n">x</span>
        <span class="n">sort_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">sort_index</span><span class="p">]</span>
        <span class="n">y_est</span> <span class="o">=</span> <span class="n">y_est</span><span class="p">[</span><span class="n">sort_index</span><span class="p">]</span>
        <span class="n">se</span> <span class="o">=</span> <span class="n">se</span><span class="p">[</span><span class="n">sort_index</span><span class="p">]</span>

        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">create_mpl_ax</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cpr</span><span class="p">:</span>
            <span class="c1"># TODO: resid_response does not make sense with nonlinear link</span>
            <span class="c1"># use resid_working ?</span>
            <span class="n">residual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resid_working</span><span class="p">[</span><span class="n">sort_index</span><span class="p">]</span>
            <span class="n">cpr_</span> <span class="o">=</span> <span class="n">y_est</span> <span class="o">+</span> <span class="n">residual</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">cpr_</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_est</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">plot_se</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_est</span> <span class="o">+</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">se</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_est</span> <span class="o">-</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">se</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">smoother</span><span class="o">.</span><span class="n">smoothers</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span><span class="o">.</span><span class="n">variable_name</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">fig</span></div>


<div class="viewcode-block" id="GLMGamResults.test_significance">
<a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGamResults.test_significance.html#statsmodels.gam.generalized_additive_model.GLMGamResults.test_significance">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">test_significance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smooth_index</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;hypothesis test that a smooth component is zero.</span>

<span class="sd">        This calls `wald_test` to compute the hypothesis test, but uses</span>
<span class="sd">        effective degrees of freedom.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        smooth_index : int</span>
<span class="sd">            index of the smooth term within list of smooth terms</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        wald_test : ContrastResults instance</span>
<span class="sd">            the results instance created by `wald_test`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">variable</span> <span class="o">=</span> <span class="n">smooth_index</span>
        <span class="n">smoother</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">smoother</span>
        <span class="n">start_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">k_exog_linear</span>

        <span class="n">k_params</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
        <span class="c1"># a bit messy, we need first index plus length of smooth term</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">smoother</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span>
        <span class="n">k_constraints</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">constraints</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">k_constraints</span><span class="p">,</span> <span class="n">k_params</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
        <span class="n">df_constraints</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edf</span><span class="p">[</span><span class="n">idx</span><span class="p">:</span> <span class="n">idx</span> <span class="o">+</span> <span class="n">k_constraints</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">wald_test</span><span class="p">(</span><span class="n">constraints</span><span class="p">,</span> <span class="n">df_constraints</span><span class="o">=</span><span class="n">df_constraints</span><span class="p">)</span></div>


<div class="viewcode-block" id="GLMGamResults.get_hat_matrix_diag">
<a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGamResults.get_hat_matrix_diag.html#statsmodels.gam.generalized_additive_model.GLMGamResults.get_hat_matrix_diag">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_hat_matrix_diag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">_axis</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the diagonal of the hat matrix</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        observed : bool</span>
<span class="sd">            If true, then observed hessian is used in the hat matrix</span>
<span class="sd">            computation. If false, then the expected hessian is used.</span>
<span class="sd">            In the case of a canonical link function both are the same.</span>
<span class="sd">            This is only relevant for models that implement both observed</span>
<span class="sd">            and expected Hessian, which is currently only GLM. Other</span>
<span class="sd">            models only use the observed Hessian.</span>
<span class="sd">        _axis : int</span>
<span class="sd">            This is mainly for internal use. By default it returns the usual</span>
<span class="sd">            diagonal of the hat matrix. If _axis is zero, then the result</span>
<span class="sd">            corresponds to the effective degrees of freedom, ``edf`` for each</span>
<span class="sd">            column of exog.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        hat_matrix_diag : ndarray</span>
<span class="sd">            The diagonal of the hat matrix computed from the observed</span>
<span class="sd">            or expected hessian.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">hessian_factor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span>
                                            <span class="n">observed</span><span class="o">=</span><span class="n">observed</span><span class="p">)</span>
        <span class="n">wexog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">weights</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">exog</span>

        <span class="c1"># we can use inverse hessian directly instead of computing it from</span>
        <span class="c1"># WLS/IRLS as in GLM</span>

        <span class="c1"># TODO: does `normalized_cov_params * scale` work in all cases?</span>
        <span class="c1"># this avoids recomputing hessian, check when used for other models.</span>
        <span class="n">hess_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized_cov_params</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
        <span class="c1"># this is in GLM equivalent to the more generic and direct</span>
        <span class="c1"># hess_inv = np.linalg.inv(-self.model.hessian(self.params))</span>
        <span class="n">hd</span> <span class="o">=</span> <span class="p">(</span><span class="n">wexog</span> <span class="o">*</span> <span class="n">hess_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wexog</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">_axis</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hd</span></div>


    <span class="nd">@cache_readonly</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">edf</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_hat_matrix_diag</span><span class="p">(</span><span class="n">_axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="nd">@cache_readonly</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">hat_matrix_trace</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">hat_matrix_diag</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="nd">@cache_readonly</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">hat_matrix_diag</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_hat_matrix_diag</span><span class="p">(</span><span class="n">observed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="nd">@cache_readonly</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">gcv</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">hat_matrix_trace</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nobs</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

    <span class="nd">@cache_readonly</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">cv</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">cv_</span> <span class="o">=</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">resid_pearson</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">hat_matrix_diag</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">cv_</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nobs</span>
        <span class="k">return</span> <span class="n">cv_</span></div>



<span class="k">class</span><span class="w"> </span><span class="nc">GLMGamResultsWrapper</span><span class="p">(</span><span class="n">GLMResultsWrapper</span><span class="p">):</span>
    <span class="k">pass</span>


<span class="n">wrap</span><span class="o">.</span><span class="n">populate_wrapper</span><span class="p">(</span><span class="n">GLMGamResultsWrapper</span><span class="p">,</span> <span class="n">GLMGamResults</span><span class="p">)</span>


<div class="viewcode-block" id="GLMGam">
<a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGam.html#statsmodels.gam.generalized_additive_model.GLMGam">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">GLMGam</span><span class="p">(</span><span class="n">PenalizedMixin</span><span class="p">,</span> <span class="n">GLM</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generalized Additive Models (GAM)</span>

<span class="sd">    This inherits from `GLM`.</span>

<span class="sd">    Warning: Not all inherited methods might take correctly account of the</span>
<span class="sd">    penalization. Not all options including offset and exposure have been</span>
<span class="sd">    verified yet.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    endog : array_like</span>
<span class="sd">        The response variable.</span>
<span class="sd">    exog : array_like or None</span>
<span class="sd">        This explanatory variables are treated as linear. The model in this</span>
<span class="sd">        case is a partial linear model.</span>
<span class="sd">    smoother : instance of additive smoother class</span>
<span class="sd">        Examples of smoother instances include Bsplines or CyclicCubicSplines.</span>
<span class="sd">    alpha : float or list of floats</span>
<span class="sd">        Penalization weights for smooth terms. The length of the list needs</span>
<span class="sd">        to be the same as the number of smooth terms in the ``smoother``.</span>
<span class="sd">    family : instance of GLM family</span>
<span class="sd">        See GLM.</span>
<span class="sd">    offset : None or array_like</span>
<span class="sd">        See GLM.</span>
<span class="sd">    exposure : None or array_like</span>
<span class="sd">        See GLM.</span>
<span class="sd">    missing : &#39;none&#39;</span>
<span class="sd">        Missing value handling is not supported in this class.</span>
<span class="sd">    **kwargs</span>
<span class="sd">        Extra keywords are used in call to the super classes.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Status: experimental. This has full unit test coverage for the core</span>
<span class="sd">    results with Gaussian and Poisson (without offset and exposure). Other</span>
<span class="sd">    options and additional results might not be correctly supported yet.</span>
<span class="sd">    (Binomial with counts, i.e. with n_trials, is most likely wrong in pirls.</span>
<span class="sd">    User specified var or freq weights are most likely also not correct for</span>
<span class="sd">    all results.)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_results_class</span> <span class="o">=</span> <span class="n">GLMGamResults</span>
    <span class="n">_results_class_wrapper</span> <span class="o">=</span> <span class="n">GLMGamResultsWrapper</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">smoother</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">offset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exposure</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">missing</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="c1"># TODO: check usage of hasconst</span>
        <span class="n">hasconst</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;hasconst&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">xnames_linear</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">mgr</span> <span class="o">=</span> <span class="n">FormulaManager</span><span class="p">()</span>
        <span class="n">model_spec</span> <span class="o">=</span> <span class="n">mgr</span><span class="o">.</span><span class="n">get_model_spec</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">model_spec</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_spec_linear</span> <span class="o">=</span> <span class="n">model_spec</span>
            <span class="n">xnames_linear</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_spec_linear</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>

        <span class="n">is_pandas</span> <span class="o">=</span> <span class="n">_is_using_pandas</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># TODO: handle data is experimental, see #5469</span>
        <span class="c1"># This is a bit wasteful because we need to `handle_data twice`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_linear</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_handle_data</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="n">missing</span><span class="p">,</span> <span class="n">hasconst</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">xnames_linear</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">xnames_linear</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_linear</span><span class="o">.</span><span class="n">xnames</span>
        <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">exog_linear</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_linear</span><span class="o">.</span><span class="n">exog</span>
            <span class="n">k_exog_linear</span> <span class="o">=</span> <span class="n">exog_linear</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">exog_linear</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">k_exog_linear</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_exog_linear</span> <span class="o">=</span> <span class="n">k_exog_linear</span>
        <span class="c1"># We need exog_linear for k-fold cross validation</span>
        <span class="c1"># TODO: alternative is to take columns from combined exog</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exog_linear</span> <span class="o">=</span> <span class="n">exog_linear</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">smoother</span> <span class="o">=</span> <span class="n">smoother</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_smooths</span> <span class="o">=</span> <span class="n">smoother</span><span class="o">.</span><span class="n">k_variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_alpha</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
        <span class="n">penal</span> <span class="o">=</span> <span class="n">MultivariateGamPenalty</span><span class="p">(</span><span class="n">smoother</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
                                       <span class="n">start_idx</span><span class="o">=</span><span class="n">k_exog_linear</span><span class="p">)</span>
        <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;penal&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">exog_linear</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">exog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">exog_linear</span><span class="p">,</span> <span class="n">smoother</span><span class="o">.</span><span class="n">basis</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">exog</span> <span class="o">=</span> <span class="n">smoother</span><span class="o">.</span><span class="n">basis</span>

        <span class="c1"># TODO: check: xnames_linear will be None instead of empty list</span>
        <span class="c1">#       if no exog_linear</span>
        <span class="c1"># can smoother be empty ? I guess not allowed.</span>
        <span class="k">if</span> <span class="n">xnames_linear</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">xnames_linear</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">xnames</span> <span class="o">=</span> <span class="n">xnames_linear</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">smoother</span><span class="o">.</span><span class="n">col_names</span>

        <span class="k">if</span> <span class="n">is_pandas</span> <span class="ow">and</span> <span class="n">exog_linear</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># we a dataframe so we can get a PandasData instance for wrapping</span>
            <span class="n">exog</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data_linear</span><span class="o">.</span><span class="n">row_labels</span><span class="p">,</span>
                                <span class="n">columns</span><span class="o">=</span><span class="n">xnames</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">family</span><span class="p">,</span>
                         <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span> <span class="n">exposure</span><span class="o">=</span><span class="n">exposure</span><span class="p">,</span>
                         <span class="n">penal</span><span class="o">=</span><span class="n">penal</span><span class="p">,</span> <span class="n">missing</span><span class="o">=</span><span class="n">missing</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_pandas</span><span class="p">:</span>
            <span class="c1"># set exog nanmes if not given by pandas DataFrame</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">exog_names</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">xnames</span>

        <span class="c1"># TODO: the generic data handling might attach the model_spec from the</span>
        <span class="c1">#       linear part, but this is incorrect for the full model and</span>
        <span class="c1">#       causes problems in wald_test_terms</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;model_spec&#39;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">model_spec</span>
        <span class="c1"># formula also might be attached which causes problems in predict</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;formula&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">formula_linear</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">formula</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">formula</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">formula</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_check_alpha</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;check and convert alpha to required list format</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        alpha : scalar, list or array_like</span>
<span class="sd">            penalization weight</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        alpha : list</span>
<span class="sd">            penalization weight, list with length equal to the number of</span>
<span class="sd">            smooth terms</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">):</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="p">[</span><span class="n">alpha</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">smoother</span><span class="o">.</span><span class="n">smoothers</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="c1"># we want alpha to be a list</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">alpha</span>

<div class="viewcode-block" id="GLMGam.fit">
<a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGam.fit.html#statsmodels.gam.generalized_additive_model.GLMGam.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;pirls&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
            <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cov_type</span><span class="o">=</span><span class="s1">&#39;nonrobust&#39;</span><span class="p">,</span> <span class="n">cov_kwds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_t</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">full_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_start_irls</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;estimate parameters and create instance of GLMGamResults class</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        most parameters are the same as for GLM</span>
<span class="sd">        method : optimization method</span>
<span class="sd">            The special optimization method is &quot;pirls&quot; which uses a penalized</span>
<span class="sd">            version of IRLS. Other methods are gradient optimizers as used in</span>
<span class="sd">            base.model.LikelihoodModel.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        res : instance of wrapped GLMGamResults</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: temporary hack to remove attribute</span>
        <span class="c1"># formula also might be attached which in inherited from_formula</span>
        <span class="c1"># causes problems in predict</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;formula&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">formula_linear</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">formula</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">formula</span>

        <span class="c1"># TODO: alpha not allowed yet, but is in `_fit_pirls`</span>
        <span class="c1"># alpha = self._check_alpha()</span>

        <span class="k">if</span> <span class="n">method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;pirls&#39;</span><span class="p">,</span> <span class="s1">&#39;irls&#39;</span><span class="p">]:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_pirls</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">start_params</span><span class="o">=</span><span class="n">start_params</span><span class="p">,</span>
                                  <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span>
                                  <span class="n">cov_type</span><span class="o">=</span><span class="n">cov_type</span><span class="p">,</span> <span class="n">cov_kwds</span><span class="o">=</span><span class="n">cov_kwds</span><span class="p">,</span>
                                  <span class="n">use_t</span><span class="o">=</span><span class="n">use_t</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">max_start_irls</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">start_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
                <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_pirls</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">start_params</span><span class="o">=</span><span class="n">start_params</span><span class="p">,</span>
                                      <span class="n">maxiter</span><span class="o">=</span><span class="n">max_start_irls</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
                                      <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span>
                                      <span class="n">cov_type</span><span class="o">=</span><span class="n">cov_type</span><span class="p">,</span> <span class="n">cov_kwds</span><span class="o">=</span><span class="n">cov_kwds</span><span class="p">,</span>
                                      <span class="n">use_t</span><span class="o">=</span><span class="n">use_t</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="n">start_params</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">params</span>
                <span class="k">del</span> <span class="n">res</span>
            <span class="n">res</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">start_params</span><span class="o">=</span><span class="n">start_params</span><span class="p">,</span>
                              <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
                              <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span>
                              <span class="n">cov_type</span><span class="o">=</span><span class="n">cov_type</span><span class="p">,</span> <span class="n">cov_kwds</span><span class="o">=</span><span class="n">cov_kwds</span><span class="p">,</span>
                              <span class="n">use_t</span><span class="o">=</span><span class="n">use_t</span><span class="p">,</span>
                              <span class="n">full_output</span><span class="o">=</span><span class="n">full_output</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="n">disp</span><span class="p">,</span>
                              <span class="n">max_start_irls</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                              <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>


    <span class="c1"># pag 165 4.3 # pag 136 PIRLS</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_fit_pirls</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">start_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
                   <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cov_type</span><span class="o">=</span><span class="s1">&#39;nonrobust&#39;</span><span class="p">,</span> <span class="n">cov_kwds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_t</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;fit model with penalized reweighted least squares</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: this currently modifies several attributes</span>
        <span class="c1"># self.scale, self.scaletype, self.mu, self.weights</span>
        <span class="c1"># self.data_weights,</span>
        <span class="c1"># and possibly self._offset_exposure</span>
        <span class="c1"># several of those might not be necessary, e.g. mu and weights</span>

        <span class="c1"># alpha = alpha * len(y) * self.scale / 100</span>
        <span class="c1"># TODO: we need to rescale alpha</span>
        <span class="n">endog</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">endog</span>
        <span class="n">wlsexog</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog</span>  <span class="c1"># smoother.basis</span>
        <span class="n">spl_s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">penal</span><span class="o">.</span><span class="n">penalty_matrix</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

        <span class="n">nobs</span><span class="p">,</span> <span class="n">n_columns</span> <span class="o">=</span> <span class="n">wlsexog</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># TODO what are these values?</span>
        <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">]</span> <span class="o">*</span> <span class="n">nobs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_weights</span> <span class="o">=</span> <span class="n">weights</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_offset_exposure&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_offset_exposure</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">scaletype</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="c1"># TODO: check default scale types</span>
        <span class="c1"># self.scaletype = &#39;dev&#39;</span>
        <span class="c1"># during iteration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">start_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">family</span><span class="o">.</span><span class="n">starting_mu</span><span class="p">(</span><span class="n">endog</span><span class="p">)</span>
            <span class="n">lin_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">family</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lin_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wlsexog</span><span class="p">,</span> <span class="n">start_params</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offset_exposure</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">family</span><span class="o">.</span><span class="n">fitted</span><span class="p">(</span><span class="n">lin_pred</span><span class="p">)</span>
        <span class="n">dev</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">family</span><span class="o">.</span><span class="n">deviance</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>

        <span class="n">history</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">start_params</span><span class="p">],</span> <span class="n">deviance</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">dev</span><span class="p">])</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">history</span><span class="p">[</span><span class="s1">&#39;deviance&#39;</span><span class="p">]</span>
        <span class="c1"># This special case is used to get the likelihood for a specific</span>
        <span class="c1"># params vector.</span>
        <span class="k">if</span> <span class="n">maxiter</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">family</span><span class="o">.</span><span class="n">fitted</span><span class="p">(</span><span class="n">lin_pred</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_scale</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
            <span class="n">wls_results</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">RegressionResults</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">maxiter</span><span class="p">):</span>

            <span class="c1"># TODO: is this equivalent to point 1 of page 136:</span>
            <span class="c1"># w = 1 / (V(mu) * g&#39;(mu))  ?</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_weights</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">family</span><span class="o">.</span><span class="n">weights</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>

            <span class="c1"># TODO: is this equivalent to point 1 of page 136:</span>
            <span class="c1"># z = g(mu)(y - mu) + X beta  ?</span>
            <span class="n">wlsendog</span> <span class="o">=</span> <span class="p">(</span><span class="n">lin_pred</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">family</span><span class="o">.</span><span class="n">link</span><span class="o">.</span><span class="n">deriv</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">endog</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span>
                        <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offset_exposure</span><span class="p">)</span>

            <span class="c1"># this defines the augmented matrix point 2a on page 136</span>
            <span class="n">wls_results</span> <span class="o">=</span> <span class="n">penalized_wls</span><span class="p">(</span><span class="n">wlsendog</span><span class="p">,</span> <span class="n">wlsexog</span><span class="p">,</span> <span class="n">spl_s</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
            <span class="n">lin_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wlsexog</span><span class="p">,</span> <span class="n">wls_results</span><span class="o">.</span><span class="n">params</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
            <span class="n">lin_pred</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offset_exposure</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">family</span><span class="o">.</span><span class="n">fitted</span><span class="p">(</span><span class="n">lin_pred</span><span class="p">)</span>

            <span class="c1"># We do not need to update scale in GLM/LEF models</span>
            <span class="c1"># We might need it in dispersion models.</span>
            <span class="c1"># self.scale = self.estimate_scale(mu)</span>
            <span class="n">history</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_history</span><span class="p">(</span><span class="n">wls_results</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">history</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">endog</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">mu</span> <span class="o">-</span> <span class="n">endog</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Perfect separation detected, results not available&quot;</span>
                <span class="k">raise</span> <span class="n">PerfectSeparationError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

            <span class="c1"># TODO need atol, rtol</span>
            <span class="c1"># args of _check_convergence: (criterion, iteration, atol, rtol)</span>
            <span class="n">converged</span> <span class="o">=</span> <span class="n">_check_convergence</span><span class="p">(</span><span class="n">criterion</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">converged</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_scale</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
        <span class="n">glm_results</span> <span class="o">=</span> <span class="n">GLMGamResults</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wls_results</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
                                    <span class="n">wls_results</span><span class="o">.</span><span class="n">normalized_cov_params</span><span class="p">,</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span>
                                    <span class="n">cov_type</span><span class="o">=</span><span class="n">cov_type</span><span class="p">,</span> <span class="n">cov_kwds</span><span class="o">=</span><span class="n">cov_kwds</span><span class="p">,</span>
                                    <span class="n">use_t</span><span class="o">=</span><span class="n">use_t</span><span class="p">)</span>

        <span class="n">glm_results</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;PIRLS&quot;</span>
        <span class="n">history</span><span class="p">[</span><span class="s1">&#39;iteration&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">iteration</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">glm_results</span><span class="o">.</span><span class="n">fit_history</span> <span class="o">=</span> <span class="n">history</span>
        <span class="n">glm_results</span><span class="o">.</span><span class="n">converged</span> <span class="o">=</span> <span class="n">converged</span>

        <span class="k">return</span> <span class="n">GLMGamResultsWrapper</span><span class="p">(</span><span class="n">glm_results</span><span class="p">)</span>

<div class="viewcode-block" id="GLMGam.select_penweight">
<a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGam.select_penweight.html#statsmodels.gam.generalized_additive_model.GLMGam.select_penweight">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">select_penweight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;aic&#39;</span><span class="p">,</span> <span class="n">start_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">start_model_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">method</span><span class="o">=</span><span class="s1">&#39;basinhopping&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_kwds</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;find alpha by minimizing results criterion</span>

<span class="sd">        The objective for the minimization can be results attributes like</span>
<span class="sd">        ``gcv``, ``aic`` or ``bic`` where the latter are based on effective</span>
<span class="sd">        degrees of freedom.</span>

<span class="sd">        Warning: In many case the optimization might converge to a local</span>
<span class="sd">        optimum or near optimum. Different start_params or using a global</span>
<span class="sd">        optimizer is recommended, default is basinhopping.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        criterion=&#39;aic&#39;</span>
<span class="sd">            name of results attribute to be minimized.</span>
<span class="sd">            Default is &#39;aic&#39;, other options are &#39;gcv&#39;, &#39;cv&#39; or &#39;bic&#39;.</span>
<span class="sd">        start_params : None or array</span>
<span class="sd">            starting parameters for alpha in the penalization weight</span>
<span class="sd">            minimization. The parameters are internally exponentiated and</span>
<span class="sd">            the minimization is with respect to ``exp(alpha)``</span>
<span class="sd">        start_model_params : None or array</span>
<span class="sd">            starting parameter for the ``model._fit_pirls``.</span>
<span class="sd">        method : &#39;basinhopping&#39;, &#39;nm&#39; or &#39;minimize&#39;</span>
<span class="sd">            &#39;basinhopping&#39; and &#39;nm&#39; directly use the underlying scipy.optimize</span>
<span class="sd">            functions `basinhopping` and `fmin`. &#39;minimize&#39; provides access</span>
<span class="sd">            to the high level interface, `scipy.optimize.minimize`.</span>
<span class="sd">        fit_kwds : keyword arguments</span>
<span class="sd">            additional keyword arguments will be used in the call to the</span>
<span class="sd">            scipy optimizer. Which keywords are supported depends on the</span>
<span class="sd">            scipy optimization function.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        alpha : ndarray</span>
<span class="sd">            penalization parameter found by minimizing the criterion.</span>
<span class="sd">            Note that this can be only a local (near) optimum.</span>
<span class="sd">        fit_res : tuple</span>
<span class="sd">            results returned by the scipy optimization routine. The</span>
<span class="sd">            parameters in the optimization problem are `log(alpha)`</span>
<span class="sd">        history : dict</span>
<span class="sd">            history of calls to pirls and contains alpha, the fit</span>
<span class="sd">            criterion and the parameters to which pirls converged to for the</span>
<span class="sd">            given alpha.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        In the test cases Nelder-Mead and bfgs often converge to local optima,</span>
<span class="sd">        see also https://github.com/statsmodels/statsmodels/issues/5381.</span>

<span class="sd">        This does not use any analytical derivatives for the criterion</span>
<span class="sd">        minimization.</span>

<span class="sd">        Status: experimental, It is possible that defaults change if there</span>
<span class="sd">        is a better way to find a global optimum. API (e.g. type of return)</span>
<span class="sd">        might also change.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># copy attributes that are changed, so we can reset them</span>
        <span class="n">scale_keep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
        <span class="n">scaletype_keep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaletype</span>
        <span class="c1"># TODO: use .copy() method when available for all types</span>
        <span class="n">alpha_keep</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">start_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">start_params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k_smooths</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">start_params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1e-20</span> <span class="o">+</span> <span class="n">start_params</span><span class="p">)</span>

        <span class="n">history</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">history</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">history</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">start_model_params</span><span class="p">]</span>
        <span class="n">history</span><span class="p">[</span><span class="s1">&#39;criterion&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">fun</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            <span class="n">res_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_pirls</span><span class="p">(</span><span class="n">start_params</span><span class="o">=</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                   <span class="n">alpha</span><span class="o">=</span><span class="n">a</span><span class="p">)</span>
            <span class="n">history</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
            <span class="n">history</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">res_</span><span class="o">.</span><span class="n">params</span><span class="p">))</span>
            <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">res_</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;nm&#39;</span><span class="p">:</span>
            <span class="n">kwds</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">full_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">maxfun</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
            <span class="n">kwds</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">fit_kwds</span><span class="p">)</span>
            <span class="n">fit_res</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">fmin</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
            <span class="n">opt</span> <span class="o">=</span> <span class="n">fit_res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;basinhopping&#39;</span><span class="p">:</span>
            <span class="n">kwds</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">minimizer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;method&#39;</span><span class="p">:</span> <span class="s1">&#39;Nelder-Mead&#39;</span><span class="p">,</span>
                        <span class="s1">&#39;options&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;maxiter&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span> <span class="s1">&#39;maxfev&#39;</span><span class="p">:</span> <span class="mi">500</span><span class="p">}},</span>
                        <span class="n">niter</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
            <span class="n">kwds</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">fit_kwds</span><span class="p">)</span>
            <span class="n">fit_res</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">basinhopping</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
            <span class="n">opt</span> <span class="o">=</span> <span class="n">fit_res</span><span class="o">.</span><span class="n">x</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;minimize&#39;</span><span class="p">:</span>
            <span class="n">fit_res</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_kwds</span><span class="p">)</span>
            <span class="n">opt</span> <span class="o">=</span> <span class="n">fit_res</span><span class="o">.</span><span class="n">x</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;method not recognized&#39;</span><span class="p">)</span>

        <span class="k">del</span> <span class="n">history</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># remove the model start_params</span>

        <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">opt</span><span class="p">)</span>

        <span class="c1"># reset attributes that have or might have changed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale_keep</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaletype</span> <span class="o">=</span> <span class="n">scaletype_keep</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha_keep</span>

        <span class="k">return</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">fit_res</span><span class="p">,</span> <span class="n">history</span></div>


<div class="viewcode-block" id="GLMGam.select_penweight_kfold">
<a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGam.select_penweight_kfold.html#statsmodels.gam.generalized_additive_model.GLMGam.select_penweight_kfold">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">select_penweight_kfold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cv_iterator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cost</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                               <span class="n">k_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">k_grid</span><span class="o">=</span><span class="mi">11</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;find alphas by k-fold cross-validation</span>

<span class="sd">        Warning: This estimates ``k_folds`` models for each point in the</span>
<span class="sd">            grid of alphas.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        alphas : None or list of arrays</span>
<span class="sd">        cv_iterator : instance</span>
<span class="sd">            instance of a cross-validation iterator, by default this is a</span>
<span class="sd">            KFold instance</span>
<span class="sd">        cost : function</span>
<span class="sd">            default is mean squared error. The cost function to evaluate the</span>
<span class="sd">            prediction error for the left out sample. This should take two</span>
<span class="sd">            arrays as argument and return one float.</span>
<span class="sd">        k_folds : int</span>
<span class="sd">            number of folds if default Kfold iterator is used.</span>
<span class="sd">            This is ignored if ``cv_iterator`` is not None.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        alpha_cv : list of float</span>
<span class="sd">            Best alpha in grid according to cross-validation</span>
<span class="sd">        res_cv : instance of MultivariateGAMCVPath</span>
<span class="sd">            The instance was used for cross-validation and holds the results</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The default alphas are defined as</span>
<span class="sd">        ``alphas = [np.logspace(0, 7, k_grid) for _ in range(k_smooths)]``</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">cost</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">cost</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x1</span> <span class="o">-</span> <span class="n">x2</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">alphas</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">k_grid</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k_smooths</span><span class="p">)]</span>

        <span class="k">if</span> <span class="n">cv_iterator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cv_iterator</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">k_folds</span><span class="o">=</span><span class="n">k_folds</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">gam_cv</span> <span class="o">=</span> <span class="n">MultivariateGAMCVPath</span><span class="p">(</span><span class="n">smoother</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">smoother</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span>
                                       <span class="n">gam</span><span class="o">=</span><span class="n">GLMGam</span><span class="p">,</span> <span class="n">cost</span><span class="o">=</span><span class="n">cost</span><span class="p">,</span> <span class="n">endog</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span>
                                       <span class="n">exog</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">exog_linear</span><span class="p">,</span>
                                       <span class="n">cv_iterator</span><span class="o">=</span><span class="n">cv_iterator</span><span class="p">)</span>
        <span class="n">gam_cv_res</span> <span class="o">=</span> <span class="n">gam_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">gam_cv_res</span><span class="o">.</span><span class="n">alpha_cv</span><span class="p">,</span> <span class="n">gam_cv_res</span></div>
</div>



<div class="viewcode-block" id="LogitGam">
<a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.LogitGam.html#statsmodels.gam.generalized_additive_model.LogitGam">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LogitGam</span><span class="p">(</span><span class="n">PenalizedMixin</span><span class="p">,</span> <span class="n">Logit</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generalized Additive model for discrete Logit</span>

<span class="sd">    This subclasses discrete_model Logit.</span>

<span class="sd">    Warning: not all inherited methods might take correctly account of the</span>
<span class="sd">    penalization</span>

<span class="sd">    not verified yet.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">endog</span><span class="p">,</span> <span class="n">smoother</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">):</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">alpha</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">smoother</span><span class="o">.</span><span class="n">smoothers</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">smoother</span> <span class="o">=</span> <span class="n">smoother</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pen_weight</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># TODO: pen weight should not be defined here!!</span>
        <span class="n">penal</span> <span class="o">=</span> <span class="n">MultivariateGamPenalty</span><span class="p">(</span><span class="n">smoother</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">smoother</span><span class="o">.</span><span class="n">basis</span><span class="p">,</span> <span class="n">penal</span><span class="o">=</span><span class="n">penal</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>



<span class="k">def</span><span class="w"> </span><span class="nf">penalized_wls</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="n">penalty_matrix</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;weighted least squares with quadratic penalty</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    endog : ndarray</span>
<span class="sd">        response or endogenous variable</span>
<span class="sd">    exog : ndarray</span>
<span class="sd">        design matrix, matrix of exogenous or explanatory variables</span>
<span class="sd">    penalty_matrix : ndarray, 2-Dim square</span>
<span class="sd">        penality matrix for quadratic penalization. Note, the penalty_matrix</span>
<span class="sd">        is multiplied by two to match non-pirls fitting methods.</span>
<span class="sd">    weights : ndarray</span>
<span class="sd">        weights for WLS</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    results : Results instance of WLS</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="n">penalty_matrix</span>
    <span class="c1"># TODO: I do not understand why I need 2 * s</span>
    <span class="n">aug_y</span><span class="p">,</span> <span class="n">aug_x</span><span class="p">,</span> <span class="n">aug_weights</span> <span class="o">=</span> <span class="n">make_augmented_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">s</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="n">wls_results</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">WLS</span><span class="p">(</span><span class="n">aug_y</span><span class="p">,</span> <span class="n">aug_x</span><span class="p">,</span> <span class="n">aug_weights</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
    <span class="c1"># TODO: use MinimalWLS during iterations, less overhead</span>
    <span class="c1"># However, MinimalWLS does not return normalized_cov_params</span>
    <span class="c1">#   which we need at the end of the iterations</span>
    <span class="c1"># call would be</span>
    <span class="c1"># wls_results = reg_tools._MinimalWLS(aug_y, aug_x, aug_weights).fit()</span>
    <span class="n">wls_results</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">wls_results</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">wls_results</span>


<span class="k">def</span><span class="w"> </span><span class="nf">make_augmented_matrix</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="n">penalty_matrix</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;augment endog, exog and weights with stochastic restriction matrix</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    endog : ndarray</span>
<span class="sd">        response or endogenous variable</span>
<span class="sd">    exog : ndarray</span>
<span class="sd">        design matrix, matrix of exogenous or explanatory variables</span>
<span class="sd">    penalty_matrix : ndarray, 2-Dim square</span>
<span class="sd">        penality matrix for quadratic penalization</span>
<span class="sd">    weights : ndarray</span>
<span class="sd">        weights for WLS</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    endog_aug : ndarray</span>
<span class="sd">        augmented response variable</span>
<span class="sd">    exog_aug : ndarray</span>
<span class="sd">        augmented design matrix</span>
<span class="sd">    weights_aug : ndarray</span>
<span class="sd">        augmented weights for WLS</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="o">=</span> <span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="n">penalty_matrix</span>
    <span class="n">nobs</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># TODO: needs full because of broadcasting with weights</span>
    <span class="c1"># check what weights should be doing</span>
    <span class="n">rs</span> <span class="o">=</span> <span class="n">matrix_sqrt</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">rs</span><span class="p">])</span>  <span class="c1"># augmented x</span>
    <span class="n">n_samp1es_x1</span> <span class="o">=</span> <span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">y1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_samp1es_x1</span><span class="p">)</span>  <span class="c1"># augmented y</span>
    <span class="n">y1</span><span class="p">[:</span><span class="n">nobs</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>

    <span class="n">id1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">]</span> <span class="o">*</span> <span class="n">rs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">w1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">weights</span><span class="p">,</span> <span class="n">id1</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">w1</span>
</code></pre></div>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    Apr 01, 2025
  </span>

    
    
    
    
  </aside>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  
  
  <div class="md-footer-meta md-typeset">
    
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-footer-copyright__highlight">
        &#169; Copyright 2009-2025, Josef Perktold, Skipper Seabold, Jonathan Taylor, statsmodels-developers.
        
    </div>
  
    Created using
    <a href="https://www.sphinx-doc.org/" target="_blank" rel="noopener">Sphinx</a>
    7.3.7.
     and
    <a href="https://github.com/jbms/sphinx-immaterial/" target="_blank" rel="noopener">Sphinx-Immaterial</a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/statsmodels/statsmodels/" target="_blank" rel="noopener" title="Source on github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://pypi.org/project/statsmodels/" target="_blank" rel="noopener" title="pypi.org" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://doi.org/10.5281/zenodo.593847" target="_blank" rel="noopener" title="doi.org" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 216C0 149.7 53.7 96 120 96h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V216m256 0c0-66.3 53.7-120 120-120h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64h-64c-35.3 0-64-28.7-64-64V216"/></svg>
    </a>
  
</div>
      
    </div>
    
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike", "staticVersions": null, "versionPath": "../versions-v3.json"}}</script>
    
      
        <script src="../../../_static/sphinx_immaterial_theme.32136f45f91ae6956.min.js?v=a7a9472a"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
  </body>
</html>