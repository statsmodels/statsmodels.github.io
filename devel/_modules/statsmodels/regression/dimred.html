



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../_static/favicon.ico">
    
    
  
      
        <title>statsmodels.regression.dimred - statsmodels 0.15.0 (+624)</title>
      
    
  <link rel="icon" type="image/png" sizes="32x32" href="../../../_static/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="../../../_static/icons/favicon-16x16.png">
  <link rel="manifest" href="../../../_static/icons/site.webmanifest">
  <link rel="mask-icon" href="../../../_static/icons/safari-pinned-tab.svg" color="#919191">
  <meta name="msapplication-TileColor" content="#2b5797">
  <meta name="msapplication-config" content="../../../_static/icons/browserconfig.xml">
  <link rel="stylesheet" href="../../../_static/stylesheets/examples.css">
  <link rel="stylesheet" href="../../../_static/stylesheets/deprecation.css">
    
      
        
      
      


    
    
      
    
    
      
        
        
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
        <link rel="stylesheet" type="text/css" href="../../../_static/sphinx_immaterial_theme.96fe8683ff2bd71e9.min.css?v=13adf062" />
        <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=fd3f3429" />
        <link rel="stylesheet" type="text/css" href="../../../_static/plot_directive.css" />
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../index.html" title="statsmodels 0.15.0 (+624)" class="md-header__button md-logo" aria-label="statsmodels 0.15.0 (+624)" data-md-component="logo">
      <img src="../../../_static/statsmodels-logo-v2-bw.svg" alt="logo">
    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            statsmodels 0.15.0 (+624)
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              statsmodels.regression.dimred
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/statsmodels/statsmodels/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    statsmodels
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../index.html" title="statsmodels 0.15.0 (+624)" class="md-nav__button md-logo" aria-label="statsmodels 0.15.0 (+624)" data-md-component="logo">
      <img src="../../../_static/statsmodels-logo-v2-bw.svg" alt="logo">
    </a>
    statsmodels 0.15.0 (+624)
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/statsmodels/statsmodels/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    statsmodels
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../install.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/install.rst (reference label)">Installing statsmodels</span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../gettingstarted.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/gettingstarted.rst (reference label)">Getting started</span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/user-guide.rst (reference label)">User Guide</span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/examples/index.rst (reference label)">Examples</span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../api.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/api.rst (reference label)">API Reference</span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../about.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/about.rst (reference label)">About statsmodels</span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dev/index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/dev/index.rst (reference label)">Developer Page</span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../release/index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/release/index.rst (reference label)">Release Notes</span>
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  

<nav class="md-nav md-nav--secondary">
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset" role="main">
                
                
                  


<h1>Source code for statsmodels.regression.dimred</h1><div class="highlight"><pre>
<span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">model</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.base.wrapper</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">wrap</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.tools.sm_exceptions</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConvergenceWarning</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_DimReductionRegression</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A base class for dimension reduction regression methods.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_prep</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_slice</span><span class="p">):</span>

        <span class="c1"># Sort the data by endog</span>
        <span class="n">ii</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">endog</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:]</span>

        <span class="c1"># Whiten the data</span>
        <span class="n">x</span> <span class="o">-=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">covx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">covxr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">covx</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">covxr</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wexog</span> <span class="o">=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_covxr</span> <span class="o">=</span> <span class="n">covxr</span>

        <span class="c1"># Split the data into slices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_split_wexog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_slice</span><span class="p">)</span>


<div class="viewcode-block" id="SlicedInverseReg">
<a class="viewcode-back" href="../../../generated/statsmodels.regression.dimred.SlicedInverseReg.html#statsmodels.regression.dimred.SlicedInverseReg">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SlicedInverseReg</span><span class="p">(</span><span class="n">_DimReductionRegression</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sliced Inverse Regression (SIR)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    endog : array_like (1d)</span>
<span class="sd">        The dependent variable</span>
<span class="sd">    exog : array_like (2d)</span>
<span class="sd">        The covariates</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    KC Li (1991).  Sliced inverse regression for dimension reduction.</span>
<span class="sd">    JASA 86, 316-342.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="SlicedInverseReg.fit">
<a class="viewcode-back" href="../../../generated/statsmodels.regression.dimred.SlicedInverseReg.fit.html#statsmodels.regression.dimred.SlicedInverseReg.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">slice_n</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Estimate the EDR space using Sliced Inverse Regression.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        slice_n : int, optional</span>
<span class="sd">            Target number of observations per slice</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Sample size per slice</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;SIR.fit does not take any extra keyword arguments&quot;</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="c1"># Number of slices</span>
        <span class="n">n_slice</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">slice_n</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_prep</span><span class="p">(</span><span class="n">n_slice</span><span class="p">)</span>

        <span class="n">mn</span> <span class="o">=</span> <span class="p">[</span><span class="n">z</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_wexog</span><span class="p">]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="p">[</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_wexog</span><span class="p">]</span>
        <span class="n">mn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">mn</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

        <span class="c1"># Estimate Cov E[X | Y=y]</span>
        <span class="n">mnc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">mn</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">n</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">mn</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

        <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">mnc</span><span class="p">)</span>
        <span class="n">jj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="o">-</span><span class="n">a</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">jj</span><span class="p">]</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">[:,</span> <span class="n">jj</span><span class="p">]</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_covxr</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">DimReductionResults</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">eigs</span><span class="o">=</span><span class="n">a</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">DimReductionResultsWrapper</span><span class="p">(</span><span class="n">results</span><span class="p">)</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_regularized_objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">A</span><span class="p">):</span>
        <span class="c1"># The objective function for regularized SIR</span>

        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_vars</span>
        <span class="n">covx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_covx</span>
        <span class="n">mn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_means</span>
        <span class="n">ph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_props</span>
        <span class="n">v</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>

        <span class="c1"># The penalty</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pen_mat</span><span class="p">,</span> <span class="n">A</span><span class="p">[:,</span> <span class="n">k</span><span class="p">])</span>
            <span class="n">v</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">u</span> <span class="o">*</span> <span class="n">u</span><span class="p">)</span>

        <span class="c1"># The SIR objective function</span>
        <span class="n">covxa</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">covx</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">covxa</span><span class="p">)</span>
        <span class="n">qd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">mn</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
        <span class="n">qu</span> <span class="o">=</span> <span class="n">mn</span><span class="o">.</span><span class="n">T</span> <span class="o">-</span> <span class="n">qd</span>
        <span class="n">v</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ph</span><span class="p">,</span> <span class="p">(</span><span class="n">qu</span> <span class="o">*</span> <span class="n">qu</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">v</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_regularized_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">A</span><span class="p">):</span>
        <span class="c1"># The gradient of the objective function for regularized SIR</span>

        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_vars</span>
        <span class="n">ndim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span>
        <span class="n">covx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_covx</span>
        <span class="n">n_slice</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_slice</span>
        <span class="n">mn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_means</span>
        <span class="n">ph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_props</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">ndim</span><span class="p">))</span>

        <span class="c1"># Penalty gradient</span>
        <span class="n">gr</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pen_mat</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pen_mat</span><span class="p">,</span> <span class="n">A</span><span class="p">))</span>

        <span class="n">A</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">ndim</span><span class="p">))</span>
        <span class="n">covxa</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">covx</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
        <span class="n">covx2a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">covx</span><span class="p">,</span> <span class="n">covxa</span><span class="p">)</span>
        <span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">covxa</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">covxa</span><span class="p">)</span>
        <span class="n">Qi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
        <span class="n">jm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">ndim</span><span class="p">))</span>
        <span class="n">qcv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">covxa</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="n">ft</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">p</span> <span class="o">*</span> <span class="n">ndim</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndim</span><span class="p">):</span>
                <span class="n">jm</span> <span class="o">*=</span> <span class="mi">0</span>
                <span class="n">jm</span><span class="p">[</span><span class="n">q</span><span class="p">,</span> <span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="n">umat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">covx2a</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">jm</span><span class="p">)</span>
                <span class="n">umat</span> <span class="o">+=</span> <span class="n">umat</span><span class="o">.</span><span class="n">T</span>
                <span class="n">umat</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Qi</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">umat</span><span class="p">,</span> <span class="n">Qi</span><span class="p">))</span>
                <span class="n">fmat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">covx</span><span class="p">,</span> <span class="n">jm</span><span class="p">),</span> <span class="n">qcv</span><span class="p">)</span>
                <span class="n">fmat</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">covxa</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">umat</span><span class="p">,</span> <span class="n">covxa</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
                <span class="n">fmat</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">covxa</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">jm</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">covx</span><span class="p">)))</span>
                <span class="n">ft</span><span class="p">[</span><span class="n">q</span><span class="o">*</span><span class="n">ndim</span> <span class="o">+</span> <span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">fmat</span>

        <span class="n">ch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">covxa</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">mn</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
        <span class="n">cu</span> <span class="o">=</span> <span class="n">mn</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">covxa</span><span class="p">,</span> <span class="n">ch</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_slice</span><span class="p">):</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">cu</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">mn</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span>
            <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndim</span><span class="p">):</span>
                    <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ft</span><span class="p">[</span><span class="n">q</span><span class="o">*</span><span class="n">ndim</span> <span class="o">+</span> <span class="n">r</span><span class="p">],</span> <span class="n">v</span><span class="p">))</span>
                    <span class="n">gr</span><span class="p">[</span><span class="n">q</span><span class="p">,</span> <span class="n">r</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">ph</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">f</span>

        <span class="k">return</span> <span class="n">gr</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

<div class="viewcode-block" id="SlicedInverseReg.fit_regularized">
<a class="viewcode-back" href="../../../generated/statsmodels.regression.dimred.SlicedInverseReg.fit_regularized.html#statsmodels.regression.dimred.SlicedInverseReg.fit_regularized">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_regularized</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">pen_mat</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">slice_n</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                        <span class="n">gtol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Estimate the EDR space using regularized SIR.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ndim : int</span>
<span class="sd">            The number of EDR directions to estimate</span>
<span class="sd">        pen_mat : array_like</span>
<span class="sd">            A 2d array such that the squared Frobenius norm of</span>
<span class="sd">            `dot(pen_mat, dirs)`` is added to the objective function,</span>
<span class="sd">            where `dirs` is an orthogonal array whose columns span</span>
<span class="sd">            the estimated EDR space.</span>
<span class="sd">        slice_n : int, optional</span>
<span class="sd">            Target number of observations per slice</span>
<span class="sd">        maxiter :int</span>
<span class="sd">            The maximum number of iterations for estimating the EDR</span>
<span class="sd">            space.</span>
<span class="sd">        gtol : float</span>
<span class="sd">            If the norm of the gradient of the objective function</span>
<span class="sd">            falls below this value, the algorithm has converged.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        A results class instance.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If each row of `exog` can be viewed as containing the values of a</span>
<span class="sd">        function evaluated at equally-spaced locations, then setting the</span>
<span class="sd">        rows of `pen_mat` to [[1, -2, 1, ...], [0, 1, -2, 1, ..], ...]</span>
<span class="sd">        will give smooth EDR coefficients.  This is a form of &quot;functional</span>
<span class="sd">        SIR&quot; using the squared second derivative as a penalty.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        L. Ferre, A.F. Yao (2003).  Functional sliced inverse regression</span>
<span class="sd">        analysis.  Statistics: a journal of theoretical and applied</span>
<span class="sd">        statistics 37(6) 475-488.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;SIR.fit_regularized does not take keyword arguments&quot;</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">pen_mat</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;pen_mat is a required argument&quot;</span><span class="p">)</span>

        <span class="n">start_params</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;start_params&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Sample size per slice</span>
        <span class="n">slice_n</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;slice_n&quot;</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

        <span class="c1"># Number of slices</span>
        <span class="n">n_slice</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">slice_n</span>

        <span class="c1"># Sort the data by endog</span>
        <span class="n">ii</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">endog</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">x</span> <span class="o">-=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">covx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="c1"># Split the data into slices</span>
        <span class="n">split_exog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_slice</span><span class="p">)</span>

        <span class="n">mn</span> <span class="o">=</span> <span class="p">[</span><span class="n">z</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">split_exog</span><span class="p">]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="p">[</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">split_exog</span><span class="p">]</span>
        <span class="n">mn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">mn</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_slice_props</span> <span class="o">=</span> <span class="n">n</span> <span class="o">/</span> <span class="n">n</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="n">ndim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_vars</span> <span class="o">=</span> <span class="n">covx</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pen_mat</span> <span class="o">=</span> <span class="n">pen_mat</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_covx</span> <span class="o">=</span> <span class="n">covx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_slice</span> <span class="o">=</span> <span class="n">n_slice</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_slice_means</span> <span class="o">=</span> <span class="n">mn</span>

        <span class="k">if</span> <span class="n">start_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">k_vars</span><span class="p">,</span> <span class="n">ndim</span><span class="p">))</span>
            <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">ndim</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="n">ndim</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">ndim</span><span class="p">)</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">start_params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">ndim</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Shape of start_params is not compatible with ndim&quot;</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">start_params</span>

        <span class="n">params</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">cnvrg</span> <span class="o">=</span> <span class="n">_grass_opt</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_regularized_objective</span><span class="p">,</span>
                                      <span class="bp">self</span><span class="o">.</span><span class="n">_regularized_grad</span><span class="p">,</span> <span class="n">maxiter</span><span class="p">,</span> <span class="n">gtol</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">cnvrg</span><span class="p">:</span>
            <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_regularized_grad</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
            <span class="n">gn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">g</span><span class="p">))</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;SIR.fit_regularized did not converge, |g|=</span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">gn</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">DimReductionResults</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">eigs</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">DimReductionResultsWrapper</span><span class="p">(</span><span class="n">results</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="PrincipalHessianDirections">
<a class="viewcode-back" href="../../../generated/statsmodels.regression.dimred.PrincipalHessianDirections.html#statsmodels.regression.dimred.PrincipalHessianDirections">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">PrincipalHessianDirections</span><span class="p">(</span><span class="n">_DimReductionRegression</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Principal Hessian Directions (PHD)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    endog : array_like (1d)</span>
<span class="sd">        The dependent variable</span>
<span class="sd">    exog : array_like (2d)</span>
<span class="sd">        The covariates</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    A model instance.  Call `fit` to obtain a results instance,</span>
<span class="sd">    from which the estimated parameters can be obtained.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    KC Li (1992).  On Principal Hessian Directions for Data</span>
<span class="sd">    Visualization and Dimension Reduction: Another application</span>
<span class="sd">    of Stein&#39;s lemma. JASA 87:420.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="PrincipalHessianDirections.fit">
<a class="viewcode-back" href="../../../generated/statsmodels.regression.dimred.PrincipalHessianDirections.fit.html#statsmodels.regression.dimred.PrincipalHessianDirections.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Estimate the EDR space using PHD.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        resid : bool, optional</span>
<span class="sd">            If True, use least squares regression to remove the</span>
<span class="sd">            linear relationship between each covariate and the</span>
<span class="sd">            response, before conducting PHD.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        A results instance which can be used to access the estimated</span>
<span class="sd">        parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">resid</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;resid&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">endog</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">endog</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">resid</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.regression.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">OLS</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">resid</span>

        <span class="n">cm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;i,ij,ik-&gt;jk&#39;</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">cm</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="n">cx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">cb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">cx</span><span class="p">,</span> <span class="n">cm</span><span class="p">)</span>

        <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">cb</span><span class="p">)</span>
        <span class="n">jj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">jj</span><span class="p">]</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">b</span><span class="p">[:,</span> <span class="n">jj</span><span class="p">]</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">DimReductionResults</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">eigs</span><span class="o">=</span><span class="n">a</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">DimReductionResultsWrapper</span><span class="p">(</span><span class="n">results</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="SlicedAverageVarianceEstimation">
<a class="viewcode-back" href="../../../generated/statsmodels.regression.dimred.SlicedAverageVarianceEstimation.html#statsmodels.regression.dimred.SlicedAverageVarianceEstimation">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SlicedAverageVarianceEstimation</span><span class="p">(</span><span class="n">_DimReductionRegression</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sliced Average Variance Estimation (SAVE)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    endog : array_like (1d)</span>
<span class="sd">        The dependent variable</span>
<span class="sd">    exog : array_like (2d)</span>
<span class="sd">        The covariates</span>
<span class="sd">    bc : bool, optional</span>
<span class="sd">        If True, use the bias-corrected CSAVE method of Li and Zhu.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    RD Cook.  SAVE: A method for dimension reduction and graphics</span>
<span class="sd">    in regression.</span>
<span class="sd">    http://www.stat.umn.edu/RegGraph/RecentDev/save.pdf</span>

<span class="sd">    Y Li, L-X Zhu (2007). Asymptotics for sliced average</span>
<span class="sd">    variance estimation.  The Annals of Statistics.</span>
<span class="sd">    https://arxiv.org/pdf/0708.0462.pdf</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SAVE</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">bc</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="s2">&quot;bc&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">and</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;bc&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bc</span> <span class="o">=</span> <span class="kc">True</span>

<div class="viewcode-block" id="SlicedAverageVarianceEstimation.fit">
<a class="viewcode-back" href="../../../generated/statsmodels.regression.dimred.SlicedAverageVarianceEstimation.fit.html#statsmodels.regression.dimred.SlicedAverageVarianceEstimation.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Estimate the EDR space.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        slice_n : int</span>
<span class="sd">            Number of observations per slice</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Sample size per slice</span>
        <span class="n">slice_n</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;slice_n&quot;</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>

        <span class="c1"># Number of slices</span>
        <span class="n">n_slice</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">slice_n</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_prep</span><span class="p">(</span><span class="n">n_slice</span><span class="p">)</span>

        <span class="n">cv</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_wexog</span><span class="p">]</span>
        <span class="n">ns</span> <span class="o">=</span> <span class="p">[</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_wexog</span><span class="p">]</span>

        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wexog</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">bc</span><span class="p">:</span>
            <span class="c1"># Cook&#39;s original approach</span>
            <span class="n">vm</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">cvx</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ns</span><span class="p">,</span> <span class="n">cv</span><span class="p">):</span>
                <span class="n">icv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">-</span> <span class="n">cvx</span>
                <span class="n">vm</span> <span class="o">+=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">icv</span><span class="p">,</span> <span class="n">icv</span><span class="p">)</span>
            <span class="n">vm</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># The bias-corrected approach of Li and Zhu</span>

            <span class="c1"># \Lambda_n in Li, Zhu</span>
            <span class="n">av</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">cv</span><span class="p">:</span>
                <span class="n">av</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
            <span class="n">av</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>

            <span class="c1"># V_n in Li, Zhu</span>
            <span class="n">vn</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_wexog</span><span class="p">:</span>
                <span class="n">r</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                    <span class="n">u</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span>
                    <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">u</span><span class="p">)</span>
                    <span class="n">vn</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
            <span class="n">vn</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span>
            <span class="n">k1</span> <span class="o">=</span> <span class="n">c</span> <span class="o">*</span> <span class="p">(</span><span class="n">c</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">((</span><span class="n">c</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">k2</span> <span class="o">=</span> <span class="p">(</span><span class="n">c</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">((</span><span class="n">c</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">av2</span> <span class="o">=</span> <span class="n">k1</span> <span class="o">*</span> <span class="n">av</span> <span class="o">-</span> <span class="n">k2</span> <span class="o">*</span> <span class="n">vn</span>

            <span class="n">vm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span> <span class="o">+</span> <span class="n">av2</span>

        <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">vm</span><span class="p">)</span>
        <span class="n">jj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="o">-</span><span class="n">a</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">jj</span><span class="p">]</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">[:,</span> <span class="n">jj</span><span class="p">]</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_covxr</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">DimReductionResults</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">eigs</span><span class="o">=</span><span class="n">a</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">DimReductionResultsWrapper</span><span class="p">(</span><span class="n">results</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="DimReductionResults">
<a class="viewcode-back" href="../../../generated/statsmodels.regression.dimred.DimReductionResults.html#statsmodels.regression.dimred.DimReductionResults">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">DimReductionResults</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">Results</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Results class for a dimension reduction regression.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The `params` attribute is a matrix whose columns span</span>
<span class="sd">    the effective dimension reduction (EDR) space.  Some</span>
<span class="sd">    methods produce a corresponding set of eigenvalues</span>
<span class="sd">    (`eigs`) that indicate how much information is contained</span>
<span class="sd">    in each basis direction.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">eigs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
              <span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eigs</span> <span class="o">=</span> <span class="n">eigs</span></div>



<span class="k">class</span><span class="w"> </span><span class="nc">DimReductionResultsWrapper</span><span class="p">(</span><span class="n">wrap</span><span class="o">.</span><span class="n">ResultsWrapper</span><span class="p">):</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="s1">&#39;columns&#39;</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">_wrap_attrs</span> <span class="o">=</span> <span class="n">_attrs</span>

<span class="n">wrap</span><span class="o">.</span><span class="n">populate_wrapper</span><span class="p">(</span><span class="n">DimReductionResultsWrapper</span><span class="p">,</span>  <span class="c1"># noqa:E305</span>
                      <span class="n">DimReductionResults</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_grass_opt</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">fun</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">maxiter</span><span class="p">,</span> <span class="n">gtol</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Minimize a function on a Grassmann manifold.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    params : array_like</span>
<span class="sd">        Starting value for the optimization.</span>
<span class="sd">    fun : function</span>
<span class="sd">        The function to be minimized.</span>
<span class="sd">    grad : function</span>
<span class="sd">        The gradient of fun.</span>
<span class="sd">    maxiter : int</span>
<span class="sd">        The maximum number of iterations.</span>
<span class="sd">    gtol : float</span>
<span class="sd">        Convergence occurs when the gradient norm falls below this value.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    params : array_like</span>
<span class="sd">        The minimizing value for the objective function.</span>
<span class="sd">    fval : float</span>
<span class="sd">        The smallest achieved value of the objective function.</span>
<span class="sd">    cnvrg : bool</span>
<span class="sd">        True if the algorithm converged to a limit point.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    `params` is 2-d, but `fun` and `grad` should take 1-d arrays</span>
<span class="sd">    `params.ravel()` as arguments.</span>

<span class="sd">    Reference</span>
<span class="sd">    ---------</span>
<span class="sd">    A Edelman, TA Arias, ST Smith (1998).  The geometry of algorithms with</span>
<span class="sd">    orthogonality constraints. SIAM J Matrix Anal Appl.</span>
<span class="sd">    http://math.mit.edu/~edelman/publications/geometry_of_algorithms.pdf</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">p</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="n">f0</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">cnvrg</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">maxiter</span><span class="p">):</span>

        <span class="c1"># Project the gradient to the tangent space</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="n">g</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span> <span class="o">*</span> <span class="n">params</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">g</span> <span class="o">*</span> <span class="n">g</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">gtol</span><span class="p">:</span>
            <span class="n">cnvrg</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">break</span>

        <span class="n">gm</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
        <span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">vt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">gm</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="n">paramsm</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
        <span class="n">pa0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">paramsm</span><span class="p">,</span> <span class="n">vt</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">geo</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
            <span class="c1"># Parameterize the geodesic path in the direction</span>
            <span class="c1"># of the gradient as a function of a real value t.</span>
            <span class="n">pa</span> <span class="o">=</span> <span class="n">pa0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">s</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span> <span class="o">+</span> <span class="n">u</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">s</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pa</span><span class="p">,</span> <span class="n">vt</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

        <span class="c1"># Try to find a downhill step along the geodesic path.</span>
        <span class="n">step</span> <span class="o">=</span> <span class="mf">2.</span>
        <span class="k">while</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="mf">1e-10</span><span class="p">:</span>
            <span class="n">pa</span> <span class="o">=</span> <span class="n">geo</span><span class="p">(</span><span class="o">-</span><span class="n">step</span><span class="p">)</span>
            <span class="n">f1</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">pa</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">f1</span> <span class="o">&lt;</span> <span class="n">f0</span><span class="p">:</span>
                <span class="n">params</span> <span class="o">=</span> <span class="n">pa</span>
                <span class="n">f0</span> <span class="o">=</span> <span class="n">f1</span>
                <span class="k">break</span>
            <span class="n">step</span> <span class="o">/=</span> <span class="mi">2</span>

    <span class="n">params</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">params</span><span class="p">,</span> <span class="n">f0</span><span class="p">,</span> <span class="n">cnvrg</span>


<span class="k">class</span><span class="w"> </span><span class="nc">CovarianceReduction</span><span class="p">(</span><span class="n">_DimReductionRegression</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Dimension reduction for covariance matrices (CORE).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    endog : array_like</span>
<span class="sd">        The dependent variable, treated as group labels</span>
<span class="sd">    exog : array_like</span>
<span class="sd">        The independent variables.</span>
<span class="sd">    dim : int</span>
<span class="sd">        The dimension of the subspace onto which the covariance</span>
<span class="sd">        matrices are projected.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    A model instance.  Call `fit` on the model instance to obtain</span>
<span class="sd">    a results instance, which contains the fitted model parameters.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This is a likelihood-based dimension reduction procedure based</span>
<span class="sd">    on Wishart models for sample covariance matrices.  The goal</span>
<span class="sd">    is to find a projection matrix P so that C_i | P&#39;C_iP and</span>
<span class="sd">    C_j | P&#39;C_jP are equal in distribution for all i, j, where</span>
<span class="sd">    the C_i are the within-group covariance matrices.</span>

<span class="sd">    The model and methodology are as described in Cook and Forzani.</span>
<span class="sd">    The optimization method follows Edelman et. al.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    DR Cook, L Forzani (2008).  Covariance reducing models: an alternative</span>
<span class="sd">    to spectral modeling of covariance matrices.  Biometrika 95:4.</span>

<span class="sd">    A Edelman, TA Arias, ST Smith (1998).  The geometry of algorithms with</span>
<span class="sd">    orthogonality constraints. SIAM J Matrix Anal Appl.</span>
<span class="sd">    http://math.mit.edu/~edelman/publications/geometry_of_algorithms.pdf</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">)</span>

        <span class="n">covs</span><span class="p">,</span> <span class="n">ns</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">exog</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endog</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">):</span>
            <span class="n">covs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">cov</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
            <span class="n">ns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nobs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">endog</span><span class="p">)</span>

        <span class="c1"># The marginal covariance</span>
        <span class="n">covm</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">covs</span><span class="p">):</span>
            <span class="n">covm</span> <span class="o">+=</span> <span class="n">covs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">ns</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">covm</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nobs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covm</span> <span class="o">=</span> <span class="n">covm</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">covs</span> <span class="o">=</span> <span class="n">covs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ns</span> <span class="o">=</span> <span class="n">ns</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">loglike</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the log-likelihood</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        params : array_like</span>
<span class="sd">            The projection matrix used to reduce the covariances, flattened</span>
<span class="sd">            to 1d.</span>

<span class="sd">        Returns the log-likelihood.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">proj</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">))</span>

        <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">proj</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">covm</span><span class="p">,</span> <span class="n">proj</span><span class="p">))</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">ldet</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">slogdet</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
        <span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nobs</span> <span class="o">*</span> <span class="n">ldet</span> <span class="o">/</span> <span class="mi">2</span>

        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">covs</span><span class="p">):</span>
            <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">proj</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">proj</span><span class="p">))</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">ldet</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">slogdet</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
            <span class="n">f</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ns</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">ldet</span> <span class="o">/</span> <span class="mi">2</span>

        <span class="k">return</span> <span class="n">f</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the score function.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        params : array_like</span>
<span class="sd">            The projection matrix used to reduce the covariances,</span>
<span class="sd">            flattened to 1d.</span>

<span class="sd">        Returns the score function evaluated at &#39;params&#39;.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">proj</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">))</span>

        <span class="n">c0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">proj</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">covm</span><span class="p">,</span> <span class="n">proj</span><span class="p">))</span>
        <span class="n">cP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">covm</span><span class="p">,</span> <span class="n">proj</span><span class="p">)</span>
        <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nobs</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">c0</span><span class="p">,</span> <span class="n">cP</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">covs</span><span class="p">):</span>
            <span class="n">c0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">proj</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">proj</span><span class="p">))</span>
            <span class="n">cP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">proj</span><span class="p">)</span>
            <span class="n">g</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ns</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">c0</span><span class="p">,</span> <span class="n">cP</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

        <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">gtol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the covariance reduction model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        start_params : array_like</span>
<span class="sd">            Starting value for the projection matrix. May be</span>
<span class="sd">            rectangular, or flattened.</span>
<span class="sd">        maxiter : int</span>
<span class="sd">            The maximum number of gradient steps to take.</span>
<span class="sd">        gtol : float</span>
<span class="sd">            Convergence criterion for the gradient norm.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        A results instance that can be used to access the</span>
<span class="sd">        fitted parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span>

        <span class="c1"># Starting value for params</span>
        <span class="k">if</span> <span class="n">start_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
            <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">d</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="n">d</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">start_params</span>

        <span class="c1"># _grass_opt is designed for minimization, we are doing maximization</span>
        <span class="c1"># here so everything needs to be flipped.</span>
        <span class="n">params</span><span class="p">,</span> <span class="n">llf</span><span class="p">,</span> <span class="n">cnvrg</span> <span class="o">=</span> <span class="n">_grass_opt</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">loglike</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
                                        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">maxiter</span><span class="p">,</span>
                                        <span class="n">gtol</span><span class="p">)</span>
        <span class="n">llf</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">cnvrg</span><span class="p">:</span>
            <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
            <span class="n">gn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">g</span> <span class="o">*</span> <span class="n">g</span><span class="p">))</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;CovReduce optimization did not converge, |g|=</span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">gn</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="n">ConvergenceWarning</span><span class="p">)</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">DimReductionResults</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">eigs</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">results</span><span class="o">.</span><span class="n">llf</span> <span class="o">=</span> <span class="n">llf</span>
        <span class="k">return</span> <span class="n">DimReductionResultsWrapper</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>


<span class="c1"># aliases for expert users</span>
<span class="n">SIR</span> <span class="o">=</span> <span class="n">SlicedInverseReg</span>
<span class="n">PHD</span> <span class="o">=</span> <span class="n">PrincipalHessianDirections</span>
<span class="n">SAVE</span> <span class="o">=</span> <span class="n">SlicedAverageVarianceEstimation</span>
<span class="n">CORE</span> <span class="o">=</span> <span class="n">CovarianceReduction</span>
</code></pre></div>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    Mar 24, 2025
  </span>

    
    
    
    
  </aside>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  
  
  <div class="md-footer-meta md-typeset">
    
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-footer-copyright__highlight">
        &#169; Copyright 2009-2025, Josef Perktold, Skipper Seabold, Jonathan Taylor, statsmodels-developers.
        
    </div>
  
    Created using
    <a href="https://www.sphinx-doc.org/" target="_blank" rel="noopener">Sphinx</a>
    7.3.7.
     and
    <a href="https://github.com/jbms/sphinx-immaterial/" target="_blank" rel="noopener">Sphinx-Immaterial</a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/statsmodels/statsmodels/" target="_blank" rel="noopener" title="Source on github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://pypi.org/project/statsmodels/" target="_blank" rel="noopener" title="pypi.org" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://doi.org/10.5281/zenodo.593847" target="_blank" rel="noopener" title="doi.org" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 216C0 149.7 53.7 96 120 96h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V216m256 0c0-66.3 53.7-120 120-120h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64h-64c-35.3 0-64-28.7-64-64V216"/></svg>
    </a>
  
</div>
      
    </div>
    
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike", "staticVersions": null, "versionPath": "../versions-v3.json"}}</script>
    
      
        <script src="../../../_static/sphinx_immaterial_theme.32136f45f91ae6956.min.js?v=a7a9472a"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
  </body>
</html>