

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../../../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../../../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../../../_static/javascripts/modernizr.js"></script>
  
  
  
    <title>statsmodels.gam.generalized_additive_model &#8212; statsmodels</title>
  <link rel="icon" type="image/png" sizes="32x32" href="../../../_static/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="../../../_static/icons/favicon-16x16.png">
  <link rel="manifest" href="../../../_static/icons/site.webmanifest">
  <link rel="mask-icon" href="../../../_static/icons/safari-pinned-tab.svg" color="#919191">
  <meta name="msapplication-TileColor" content="#2b5797">
  <meta name="msapplication-config" content="../../../_static/icons/browserconfig.xml">
  <link rel="stylesheet" href="../../../_static/stylesheets/examples.css">
    <link rel="stylesheet" href="../../../_static/material.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../../about.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  
   
  
  <script src="../../../_static/javascripts/version_dropdown.js"></script>
  <script>
    var json_loc = "../../../_static/versions.json",
        target_loc = "../../../../",
        text = "Versions";
    $( document ).ready( add_version_dropdown(json_loc, target_loc, text));
  </script>


  </head>
  <body dir=ltr
        data-md-color-primary=indigo data-md-color-accent=blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#_modules/statsmodels/gam/generalized_additive_model" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../../index.html" title="statsmodels"
           class="md-header-nav__button md-logo">
          
              <img src="../../../_static/statsmodels-logo-v2-bw.svg" height="26"
                   alt="statsmodels logo">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">statsmodels v0.11.1</span>
          <span class="md-header-nav__topic"> statsmodels.gam.generalized_additive_model </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../../../search.html" method="GET" name="search">
      <input type="text" class="md-search__input" name="q" placeholder="Search"
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/statsmodels/statsmodels" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    statsmodels
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
          <li class="md-tabs__item"><a href="../../index.html" class="md-tabs__link">Module code</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../../index.html" title="statsmodels" class="md-nav__button md-logo">
      
        <img src="../../../_static/statsmodels-logo-v2-bw.svg" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../../../index.html"
       title="statsmodels">statsmodels v0.11.1</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/statsmodels/statsmodels" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    statsmodels
  </div>
</a>
    </div>
  
  

  
  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
      <a href="../../../install.html" class="md-nav__link">Installing statsmodels</a>
      
    </li>
    <li class="md-nav__item">
    
      <a href="../../../gettingstarted.html" class="md-nav__link">Getting started</a>
      
    </li>
    <li class="md-nav__item">
    
      <a href="../../../user-guide.html" class="md-nav__link">User Guide</a>
      
    </li>
    <li class="md-nav__item">
    
      <a href="../../../examples/index.html" class="md-nav__link">Examples</a>
      
    </li>
    <li class="md-nav__item">
    
      <a href="../../../api.html" class="md-nav__link">API Reference</a>
      
    </li>
    <li class="md-nav__item">
    
      <a href="../../../about.html" class="md-nav__link">About statsmodels</a>
      
    </li>
    <li class="md-nav__item">
    
      <a href="../../../dev/index.html" class="md-nav__link">Developer Page</a>
      
    </li>
    <li class="md-nav__item">
    
      <a href="../../../release/index.html" class="md-nav__link">Release Notes</a>
      
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
  <ul class="md-nav__list" data-md-scrollfix="">
    

<li id="searchbox" class="md-nav__item"></li>

  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <h1 id="modules-statsmodels-gam-generalized-additive-model--page-root">Source code for statsmodels.gam.generalized_additive_model</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="sd">"""</span>
<span class="sd">Generalized Additive Models</span>

<span class="sd">Author: Luca Puggini</span>
<span class="sd">Author: Josef Perktold</span>

<span class="sd">created on 08/07/2015</span>
<span class="sd">"""</span>

<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Iterable</span>
<span class="kn">import</span> <span class="nn">copy</span>  <span class="c1"># check if needed when dropping python 2.7</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">optimize</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">statsmodels.base.wrapper</span> <span class="k">as</span> <span class="nn">wrap</span>

<span class="kn">from</span> <span class="nn">statsmodels.discrete.discrete_model</span> <span class="kn">import</span> <span class="n">Logit</span>
<span class="kn">from</span> <span class="nn">statsmodels.genmod.generalized_linear_model</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">GLM</span><span class="p">,</span> <span class="n">GLMResults</span><span class="p">,</span> <span class="n">GLMResultsWrapper</span><span class="p">,</span> <span class="n">_check_convergence</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">statsmodels.regression.linear_model</span> <span class="k">as</span> <span class="nn">lm</span>
<span class="c1"># import statsmodels.regression._tools as reg_tools  # TODO: use this for pirls</span>
<span class="kn">from</span> <span class="nn">statsmodels.tools.sm_exceptions</span> <span class="kn">import</span> <span class="p">(</span><span class="n">PerfectSeparationError</span><span class="p">,</span>
                                             <span class="n">ValueWarning</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">statsmodels.tools.decorators</span> <span class="kn">import</span> <span class="n">cache_readonly</span>
<span class="kn">from</span> <span class="nn">statsmodels.tools.data</span> <span class="kn">import</span> <span class="n">_is_using_pandas</span>
<span class="kn">from</span> <span class="nn">statsmodels.tools.linalg</span> <span class="kn">import</span> <span class="n">matrix_sqrt</span>

<span class="kn">from</span> <span class="nn">statsmodels.base._penalized</span> <span class="kn">import</span> <span class="n">PenalizedMixin</span>
<span class="kn">from</span> <span class="nn">statsmodels.gam.gam_penalties</span> <span class="kn">import</span> <span class="n">MultivariateGamPenalty</span>
<span class="kn">from</span> <span class="nn">statsmodels.gam.gam_cross_validation.gam_cross_validation</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">MultivariateGAMCVPath</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">statsmodels.gam.gam_cross_validation.cross_validators</span> <span class="kn">import</span> <span class="n">KFold</span>


<span class="k">def</span> <span class="nf">_transform_predict_exog</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="n">design_info</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""transform exog for predict using design_info</span>

<span class="sd">    Note: this is copied from base.model.Results.predict and converted to</span>
<span class="sd">    standalone function with additional options.</span>
<span class="sd">    """</span>

    <span class="n">is_pandas</span> <span class="o">=</span> <span class="n">_is_using_pandas</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="n">exog_index</span> <span class="o">=</span> <span class="n">exog</span><span class="o">.</span><span class="n">index</span> <span class="k">if</span> <span class="n">is_pandas</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">design_info</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">design_info</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="s1">'design_info'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">design_info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="n">exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">patsy</span> <span class="kn">import</span> <span class="n">dmatrix</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
            <span class="c1"># we are guessing whether it should be column or row</span>
            <span class="k">if</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="s1">'name'</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exog</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span>
                    <span class="n">exog</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">design_info</span><span class="o">.</span><span class="n">describe</span><span class="p">()):</span>
                <span class="c1"># assume we need one column</span>
                <span class="n">exog</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># assume we need a row</span>
                <span class="n">exog</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="n">orig_exog_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span>
        <span class="n">is_dict</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
        <span class="n">exog</span> <span class="o">=</span> <span class="n">dmatrix</span><span class="p">(</span><span class="n">design_info</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">"dataframe"</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">orig_exog_len</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_dict</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">warnings</span>
            <span class="k">if</span> <span class="n">exog_index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">'nan values have been dropped'</span><span class="p">,</span> <span class="n">ValueWarning</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">exog</span> <span class="o">=</span> <span class="n">exog</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="n">exog_index</span><span class="p">)</span>
        <span class="n">exog_index</span> <span class="o">=</span> <span class="n">exog</span><span class="o">.</span><span class="n">index</span>

    <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">exog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">exog</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">exog</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span>
                               <span class="n">model</span><span class="o">.</span><span class="n">exog</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">exog</span> <span class="o">=</span> <span class="n">exog</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">exog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span>  <span class="c1"># needed in count model shape[1]</span>

    <span class="k">return</span> <span class="n">exog</span><span class="p">,</span> <span class="n">exog_index</span>


<div class="viewcode-block" id="GLMGamResults"><a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGamResults.html#statsmodels.gam.generalized_additive_model.GLMGamResults">[docs]</a><span class="k">class</span> <span class="nc">GLMGamResults</span><span class="p">(</span><span class="n">GLMResults</span><span class="p">):</span>
    <span class="sd">"""Results class for generalized additive models, GAM.</span>

<span class="sd">    This inherits from GLMResults.</span>

<span class="sd">    Warning: some inherited methods might not correctly take account of the</span>
<span class="sd">    penalization</span>

<span class="sd">    GLMGamResults inherits from GLMResults</span>
<span class="sd">    All methods related to the loglikelihood function return the penalized</span>
<span class="sd">    values.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>

<span class="sd">    edf</span>
<span class="sd">        list of effective degrees of freedom for each column of the design</span>
<span class="sd">        matrix.</span>
<span class="sd">    hat_matrix_diag</span>
<span class="sd">        diagonal of hat matrix</span>
<span class="sd">    gcv</span>
<span class="sd">        generalized cross-validation criterion computed as</span>
<span class="sd">        ``gcv = scale / (1. - hat_matrix_trace / self.nobs)**2``</span>
<span class="sd">    cv</span>
<span class="sd">        cross-validation criterion computed as</span>
<span class="sd">        ``cv = ((resid_pearson / (1 - hat_matrix_diag))**2).sum() / nobs``</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    status: experimental</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">normalized_cov_params</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">):</span>

        <span class="c1"># this is a messy way to compute edf and update scale</span>
        <span class="c1"># need several attributes to compute edf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized_cov_params</span> <span class="o">=</span> <span class="n">normalized_cov_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="n">edf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edf</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_model</span> <span class="o">=</span> <span class="n">edf</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># assume constant</span>
        <span class="c1"># need to use nobs or wnobs attribute</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_resid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">endog</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">edf</span>

        <span class="c1"># we are setting the model df for the case when super is using it</span>
        <span class="c1"># df in model will be incorrect state when alpha/pen_weight changes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">df_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">df_resid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_resid</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fittedvalues</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">estimate_scale</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GLMGamResults</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span>
                                            <span class="n">normalized_cov_params</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span>
                                            <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_tranform_predict_exog</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exog_smooth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                               <span class="n">transform</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">"""Transform original explanatory variables for prediction</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        exog : array_like, optional</span>
<span class="sd">            The values for the linear explanatory variables.</span>
<span class="sd">        exog_smooth : array_like</span>
<span class="sd">            values for the variables in the smooth terms</span>
<span class="sd">        transform : bool, optional</span>
<span class="sd">            If transform is False, then ``exog`` is returned unchanged and</span>
<span class="sd">            ``x`` is ignored. It is assumed that exog contains the full</span>
<span class="sd">            design matrix for the predict observations.</span>
<span class="sd">            If transform is True, then the basis representation of the smooth</span>
<span class="sd">            term will be constructed from the provided ``x``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        exog_transformed : ndarray</span>
<span class="sd">            design matrix for the prediction</span>
<span class="sd">        """</span>
        <span class="n">exog_index</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">transform</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="c1"># the following allows that either or both exog are not None</span>
            <span class="k">if</span> <span class="n">exog_smooth</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># exog could be None or array</span>
                <span class="n">ex</span> <span class="o">=</span> <span class="n">exog</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">ex</span> <span class="o">=</span> <span class="n">exog_smooth</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">ex</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">exog</span><span class="p">,</span> <span class="n">exog_smooth</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># transform exog_linear if needed</span>
            <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">'design_info_linear'</span><span class="p">):</span>
                <span class="n">exog</span><span class="p">,</span> <span class="n">exog_index</span> <span class="o">=</span> <span class="n">_transform_predict_exog</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">design_info_linear</span><span class="p">)</span>

            <span class="c1"># create smooth basis</span>
            <span class="k">if</span> <span class="n">exog_smooth</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ex_smooth</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">smoother</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">exog_smooth</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">ex</span> <span class="o">=</span> <span class="n">ex_smooth</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># TODO: there might be problems is exog_smooth is 1-D</span>
                    <span class="n">ex</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">exog</span><span class="p">,</span> <span class="n">ex_smooth</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">ex</span> <span class="o">=</span> <span class="n">exog</span>

        <span class="k">return</span> <span class="n">ex</span><span class="p">,</span> <span class="n">exog_index</span>

<div class="viewcode-block" id="GLMGamResults.predict"><a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGamResults.predict.html#statsmodels.gam.generalized_additive_model.GLMGamResults.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exog_smooth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">""""</span>
<span class="sd">        compute prediction</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        exog : array_like, optional</span>
<span class="sd">            The values for the linear explanatory variables</span>
<span class="sd">        exog_smooth : array_like</span>
<span class="sd">            values for the variables in the smooth terms</span>
<span class="sd">        transform : bool, optional</span>
<span class="sd">            If transform is True, then the basis representation of the smooth</span>
<span class="sd">            term will be constructed from the provided ``exog``.</span>
<span class="sd">        kwargs :</span>
<span class="sd">            Some models can take additional arguments or keywords, see the</span>
<span class="sd">            predict method of the model for the details.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        prediction : ndarray, pandas.Series or pandas.DataFrame</span>
<span class="sd">            predicted values</span>
<span class="sd">        """</span>
        <span class="n">ex</span><span class="p">,</span> <span class="n">exog_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tranform_predict_exog</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">,</span>
                                                     <span class="n">exog_smooth</span><span class="o">=</span><span class="n">exog_smooth</span><span class="p">,</span>
                                                     <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
        <span class="n">predict_results</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">GLMGamResults</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">ex</span><span class="p">,</span>
                                                             <span class="n">transform</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                             <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">exog_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="n">predict_results</span><span class="p">,</span> <span class="s1">'predicted_values'</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">predict_results</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">predict_results</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">exog_index</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">predict_results</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">exog_index</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">predict_results</span></div>

<div class="viewcode-block" id="GLMGamResults.get_prediction"><a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGamResults.get_prediction.html#statsmodels.gam.generalized_additive_model.GLMGamResults.get_prediction">[docs]</a>    <span class="k">def</span> <span class="nf">get_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exog_smooth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">"""compute prediction results</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        exog : array_like, optional</span>
<span class="sd">            The values for which you want to predict.</span>
<span class="sd">        exog_smooth : array_like</span>
<span class="sd">            values for the variables in the smooth terms</span>
<span class="sd">        transform : bool, optional</span>
<span class="sd">            If transform is True, then the basis representation of the smooth</span>
<span class="sd">            term will be constructed from the provided ``x``.</span>
<span class="sd">        kwargs :</span>
<span class="sd">            Some models can take additional arguments or keywords, see the</span>
<span class="sd">            predict method of the model for the details.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        prediction_results : generalized_linear_model.PredictionResults</span>
<span class="sd">            The prediction results instance contains prediction and prediction</span>
<span class="sd">            variance and can on demand calculate confidence intervals and</span>
<span class="sd">            summary tables for the prediction of the mean and of new</span>
<span class="sd">            observations.</span>
<span class="sd">        """</span>
        <span class="n">ex</span><span class="p">,</span> <span class="n">exog_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tranform_predict_exog</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">,</span>
                                                     <span class="n">exog_smooth</span><span class="o">=</span><span class="n">exog_smooth</span><span class="p">,</span>
                                                     <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">GLMGamResults</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">get_prediction</span><span class="p">(</span><span class="n">ex</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                         <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="GLMGamResults.partial_values"><a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGamResults.partial_values.html#statsmodels.gam.generalized_additive_model.GLMGamResults.partial_values">[docs]</a>    <span class="k">def</span> <span class="nf">partial_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smooth_index</span><span class="p">,</span> <span class="n">include_constant</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">"""contribution of a smooth term to the linear prediction</span>

<span class="sd">        Warning: This will be replaced by a predict method</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        smooth_index : int</span>
<span class="sd">            index of the smooth term within list of smooth terms</span>
<span class="sd">        include_constant : bool</span>
<span class="sd">            If true, then the estimated intercept is added to the prediction</span>
<span class="sd">            and its standard errors. This avoids that the confidence interval</span>
<span class="sd">            has zero width at the imposed identification constraint, e.g.</span>
<span class="sd">            either at a reference point or at the mean.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        predicted : nd_array</span>
<span class="sd">            predicted value of linear term.</span>
<span class="sd">            This is not the expected response if the link function is not</span>
<span class="sd">            linear.</span>
<span class="sd">        se_pred : nd_array</span>
<span class="sd">            standard error of linear prediction</span>
<span class="sd">        """</span>
        <span class="n">variable</span> <span class="o">=</span> <span class="n">smooth_index</span>
        <span class="n">smoother</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">smoother</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">smoother</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span>

        <span class="n">start_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">k_exog_linear</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># smoother has only smooth parts, not exog_linear</span>
        <span class="n">exog_part</span> <span class="o">=</span> <span class="n">smoother</span><span class="o">.</span><span class="n">basis</span><span class="p">[:,</span> <span class="n">mask</span><span class="p">]</span>

        <span class="n">const_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">const_idx</span>
        <span class="k">if</span> <span class="n">include_constant</span> <span class="ow">and</span> <span class="n">const_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(([</span><span class="n">const_idx</span><span class="p">],</span> <span class="n">idx</span><span class="p">))</span>
            <span class="n">exog_part</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">exog</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">]</span>

        <span class="n">linpred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">exog_part</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="c1"># select the submatrix corresponding to a single variable</span>
        <span class="n">partial_cov_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_params</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="n">idx</span><span class="p">)</span>

        <span class="n">covb</span> <span class="o">=</span> <span class="n">partial_cov_params</span>
        <span class="n">var</span> <span class="o">=</span> <span class="p">(</span><span class="n">exog_part</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">covb</span><span class="p">,</span> <span class="n">exog_part</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">linpred</span><span class="p">,</span> <span class="n">se</span></div>

<div class="viewcode-block" id="GLMGamResults.plot_partial"><a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGamResults.plot_partial.html#statsmodels.gam.generalized_additive_model.GLMGamResults.plot_partial">[docs]</a>    <span class="k">def</span> <span class="nf">plot_partial</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smooth_index</span><span class="p">,</span> <span class="n">plot_se</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cpr</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                     <span class="n">include_constant</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">"""plot the contribution of a smooth term to the linear prediction</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        smooth_index : int</span>
<span class="sd">            index of the smooth term within list of smooth terms</span>
<span class="sd">        plot_se : book</span>
<span class="sd">            If plot_se is true, then the confidence interval for the linear</span>
<span class="sd">            prediction will be added to the plot.</span>
<span class="sd">        cpr : bool</span>
<span class="sd">            If cpr (component plus residual) is true, the a scatter plot of</span>
<span class="sd">            the partial working residuals will be added to the plot.</span>
<span class="sd">        include_constant : bool</span>
<span class="sd">            If true, then the estimated intercept is added to the prediction</span>
<span class="sd">            and its standard errors. This avoids that the confidence interval</span>
<span class="sd">            has zero width at the imposed identification constraint, e.g.</span>
<span class="sd">            either at a reference point or at the mean.</span>
<span class="sd">        ax : None or matplotlib axis instance</span>
<span class="sd">           If ax is not None, then the plot will be added to it.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Figure</span>
<span class="sd">            If `ax` is None, the created figure. Otherwise the Figure to which</span>
<span class="sd">            `ax` is connected.</span>
<span class="sd">        """</span>
        <span class="kn">from</span> <span class="nn">statsmodels.graphics.utils</span> <span class="kn">import</span> <span class="n">_import_mpl</span><span class="p">,</span> <span class="n">create_mpl_ax</span>
        <span class="n">_import_mpl</span><span class="p">()</span>

        <span class="n">variable</span> <span class="o">=</span> <span class="n">smooth_index</span>
        <span class="n">y_est</span><span class="p">,</span> <span class="n">se</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">partial_values</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span>
                                        <span class="n">include_constant</span><span class="o">=</span><span class="n">include_constant</span><span class="p">)</span>
        <span class="n">smoother</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">smoother</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">smoother</span><span class="o">.</span><span class="n">smoothers</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span><span class="o">.</span><span class="n">x</span>
        <span class="n">sort_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">sort_index</span><span class="p">]</span>
        <span class="n">y_est</span> <span class="o">=</span> <span class="n">y_est</span><span class="p">[</span><span class="n">sort_index</span><span class="p">]</span>
        <span class="n">se</span> <span class="o">=</span> <span class="n">se</span><span class="p">[</span><span class="n">sort_index</span><span class="p">]</span>

        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">create_mpl_ax</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_est</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">plot_se</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_est</span> <span class="o">+</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">se</span><span class="p">,</span> <span class="s1">'-'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_est</span> <span class="o">-</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">se</span><span class="p">,</span> <span class="s1">'-'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cpr</span><span class="p">:</span>
            <span class="c1"># TODO: resid_response does not make sense with nonlinear link</span>
            <span class="c1"># use resid_working ?</span>
            <span class="n">cpr_</span> <span class="o">=</span> <span class="n">y_est</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">resid_working</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">cpr_</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">smoother</span><span class="o">.</span><span class="n">smoothers</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span><span class="o">.</span><span class="n">variable_name</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">fig</span></div>

<div class="viewcode-block" id="GLMGamResults.test_significance"><a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGamResults.test_significance.html#statsmodels.gam.generalized_additive_model.GLMGamResults.test_significance">[docs]</a>    <span class="k">def</span> <span class="nf">test_significance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smooth_index</span><span class="p">):</span>
        <span class="sd">"""hypothesis test that a smooth component is zero.</span>

<span class="sd">        This calls `wald_test` to compute the hypothesis test, but uses</span>
<span class="sd">        effective degrees of freedom.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        smooth_index : int</span>
<span class="sd">            index of the smooth term within list of smooth terms</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        wald_test : ContrastResults instance</span>
<span class="sd">            the results instance created by `wald_test`</span>
<span class="sd">        """</span>

        <span class="n">variable</span> <span class="o">=</span> <span class="n">smooth_index</span>
        <span class="n">smoother</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">smoother</span>
        <span class="n">start_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">k_exog_linear</span>

        <span class="n">k_params</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
        <span class="c1"># a bit messy, we need first index plus length of smooth term</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">smoother</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span>
        <span class="n">k_constraints</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">constraints</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">k_constraints</span><span class="p">,</span> <span class="n">k_params</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
        <span class="n">df_constraints</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edf</span><span class="p">[</span><span class="n">idx</span><span class="p">:</span> <span class="n">idx</span> <span class="o">+</span> <span class="n">k_constraints</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">wald_test</span><span class="p">(</span><span class="n">constraints</span><span class="p">,</span> <span class="n">df_constraints</span><span class="o">=</span><span class="n">df_constraints</span><span class="p">)</span></div>

<div class="viewcode-block" id="GLMGamResults.get_hat_matrix_diag"><a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGamResults.get_hat_matrix_diag.html#statsmodels.gam.generalized_additive_model.GLMGamResults.get_hat_matrix_diag">[docs]</a>    <span class="k">def</span> <span class="nf">get_hat_matrix_diag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">_axis</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">"""</span>
<span class="sd">        Compute the diagonal of the hat matrix</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        observed : bool</span>
<span class="sd">            If true, then observed hessian is used in the hat matrix</span>
<span class="sd">            computation. If false, then the expected hessian is used.</span>
<span class="sd">            In the case of a canonical link function both are the same.</span>
<span class="sd">            This is only relevant for models that implement both observed</span>
<span class="sd">            and expected Hessian, which is currently only GLM. Other</span>
<span class="sd">            models only use the observed Hessian.</span>
<span class="sd">        _axis : int</span>
<span class="sd">            This is mainly for internal use. By default it returns the usual</span>
<span class="sd">            diagonal of the hat matrix. If _axis is zero, then the result</span>
<span class="sd">            corresponds to the effective degrees of freedom, ``edf`` for each</span>
<span class="sd">            column of exog.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        hat_matrix_diag : ndarray</span>
<span class="sd">            The diagonal of the hat matrix computed from the observed</span>
<span class="sd">            or expected hessian.</span>
<span class="sd">        """</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">hessian_factor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span>
                                            <span class="n">observed</span><span class="o">=</span><span class="n">observed</span><span class="p">)</span>
        <span class="n">wexog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">weights</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">exog</span>

        <span class="c1"># we can use inverse hessian directly instead of computing it from</span>
        <span class="c1"># WLS/IRLS as in GLM</span>

        <span class="c1"># TODO: does `normalized_cov_params * scale` work in all cases?</span>
        <span class="c1"># this avoids recomputing hessian, check when used for other models.</span>
        <span class="n">hess_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized_cov_params</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
        <span class="c1"># this is in GLM equivalent to the more generic and direct</span>
        <span class="c1"># hess_inv = np.linalg.inv(-self.model.hessian(self.params))</span>
        <span class="n">hd</span> <span class="o">=</span> <span class="p">(</span><span class="n">wexog</span> <span class="o">*</span> <span class="n">hess_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wexog</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">_axis</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hd</span></div>

    <span class="nd">@cache_readonly</span>
    <span class="k">def</span> <span class="nf">edf</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_hat_matrix_diag</span><span class="p">(</span><span class="n">_axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="nd">@cache_readonly</span>
    <span class="k">def</span> <span class="nf">hat_matrix_trace</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">hat_matrix_diag</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="nd">@cache_readonly</span>
    <span class="k">def</span> <span class="nf">hat_matrix_diag</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_hat_matrix_diag</span><span class="p">(</span><span class="n">observed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="nd">@cache_readonly</span>
    <span class="k">def</span> <span class="nf">gcv</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">hat_matrix_trace</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nobs</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

    <span class="nd">@cache_readonly</span>
    <span class="k">def</span> <span class="nf">cv</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">cv_</span> <span class="o">=</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">resid_pearson</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">hat_matrix_diag</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">cv_</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nobs</span>
        <span class="k">return</span> <span class="n">cv_</span></div>


<span class="k">class</span> <span class="nc">GLMGamResultsWrapper</span><span class="p">(</span><span class="n">GLMResultsWrapper</span><span class="p">):</span>
    <span class="k">pass</span>


<span class="n">wrap</span><span class="o">.</span><span class="n">populate_wrapper</span><span class="p">(</span><span class="n">GLMGamResultsWrapper</span><span class="p">,</span> <span class="n">GLMGamResults</span><span class="p">)</span>


<div class="viewcode-block" id="GLMGam"><a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGam.html#statsmodels.gam.generalized_additive_model.GLMGam">[docs]</a><span class="k">class</span> <span class="nc">GLMGam</span><span class="p">(</span><span class="n">PenalizedMixin</span><span class="p">,</span> <span class="n">GLM</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Generalized Additive Models (GAM)</span>

<span class="sd">    This inherits from `GLM`.</span>

<span class="sd">    Warning: Not all inherited methods might take correctly account of the</span>
<span class="sd">    penalization. Not all options including offset and exposure have been</span>
<span class="sd">    verified yet.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    endog : array_like</span>
<span class="sd">        The response variable.</span>
<span class="sd">    exog : array_like or None</span>
<span class="sd">        This explanatory variables are treated as linear. The model in this</span>
<span class="sd">        case is a partial linear model.</span>
<span class="sd">    smoother : instance of additive smoother class</span>
<span class="sd">        Examples of smoother instances include Bsplines or CyclicCubicSplines.</span>
<span class="sd">    alpha : float or list of floats</span>
<span class="sd">        Penalization weights for smooth terms. The length of the list needs</span>
<span class="sd">        to be the same as the number of smooth terms in the ``smoother``.</span>
<span class="sd">    family : instance of GLM family</span>
<span class="sd">        See GLM.</span>
<span class="sd">    offset : None or array_like</span>
<span class="sd">        See GLM.</span>
<span class="sd">    exposure : None or array_like</span>
<span class="sd">        See GLM.</span>
<span class="sd">    missing : 'none'</span>
<span class="sd">        Missing value handling is not supported in this class.</span>
<span class="sd">    **kwargs</span>
<span class="sd">        Extra keywords are used in call to the super classes.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Status: experimental. This has full unit test coverage for the core</span>
<span class="sd">    results with Gaussian and Poisson (without offset and exposure). Other</span>
<span class="sd">    options and additional results might not be correctly supported yet.</span>
<span class="sd">    (Binomial with counts, i.e. with n_trials, is most likely wrong in pirls.</span>
<span class="sd">    User specified var or freq weights are most likely also not correct for</span>
<span class="sd">    all results.)</span>
<span class="sd">    """</span>

    <span class="n">_results_class</span> <span class="o">=</span> <span class="n">GLMGamResults</span>
    <span class="n">_results_class_wrapper</span> <span class="o">=</span> <span class="n">GLMGamResultsWrapper</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">smoother</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">offset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exposure</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">missing</span><span class="o">=</span><span class="s1">'none'</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="c1"># TODO: check usage of hasconst</span>
        <span class="n">hasconst</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'hasconst'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">xnames_linear</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="s1">'design_info'</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">design_info_linear</span> <span class="o">=</span> <span class="n">exog</span><span class="o">.</span><span class="n">design_info</span>
            <span class="n">xnames_linear</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">design_info_linear</span><span class="o">.</span><span class="n">column_names</span>

        <span class="n">is_pandas</span> <span class="o">=</span> <span class="n">_is_using_pandas</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># TODO: handle data is experimental, see #5469</span>
        <span class="c1"># This is a bit wasteful because we need to `handle_data twice`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_linear</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_handle_data</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="n">missing</span><span class="p">,</span> <span class="n">hasconst</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">xnames_linear</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">xnames_linear</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_linear</span><span class="o">.</span><span class="n">xnames</span>
        <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">exog_linear</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_linear</span><span class="o">.</span><span class="n">exog</span>
            <span class="n">k_exog_linear</span> <span class="o">=</span> <span class="n">exog_linear</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">exog_linear</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">k_exog_linear</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_exog_linear</span> <span class="o">=</span> <span class="n">k_exog_linear</span>
        <span class="c1"># We need exog_linear for k-fold cross validation</span>
        <span class="c1"># TODO: alternative is to take columns from combined exog</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exog_linear</span> <span class="o">=</span> <span class="n">exog_linear</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">smoother</span> <span class="o">=</span> <span class="n">smoother</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_smooths</span> <span class="o">=</span> <span class="n">smoother</span><span class="o">.</span><span class="n">k_variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_alpha</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
        <span class="n">penal</span> <span class="o">=</span> <span class="n">MultivariateGamPenalty</span><span class="p">(</span><span class="n">smoother</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
                                       <span class="n">start_idx</span><span class="o">=</span><span class="n">k_exog_linear</span><span class="p">)</span>
        <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">'penal'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">exog_linear</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">exog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">exog_linear</span><span class="p">,</span> <span class="n">smoother</span><span class="o">.</span><span class="n">basis</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">exog</span> <span class="o">=</span> <span class="n">smoother</span><span class="o">.</span><span class="n">basis</span>

        <span class="c1"># TODO: check: xnames_linear will be None instead of empty list</span>
        <span class="c1">#       if no exog_linear</span>
        <span class="c1"># can smoother be empty ? I guess not allowed.</span>
        <span class="k">if</span> <span class="n">xnames_linear</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">xnames_linear</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">xnames</span> <span class="o">=</span> <span class="n">xnames_linear</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">smoother</span><span class="o">.</span><span class="n">col_names</span>

        <span class="k">if</span> <span class="n">is_pandas</span> <span class="ow">and</span> <span class="n">exog_linear</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># we a dataframe so we can get a PandasData instance for wrapping</span>
            <span class="n">exog</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data_linear</span><span class="o">.</span><span class="n">row_labels</span><span class="p">,</span>
                                <span class="n">columns</span><span class="o">=</span><span class="n">xnames</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">GLMGam</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">family</span><span class="p">,</span>
                                     <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span> <span class="n">exposure</span><span class="o">=</span><span class="n">exposure</span><span class="p">,</span>
                                     <span class="n">penal</span><span class="o">=</span><span class="n">penal</span><span class="p">,</span> <span class="n">missing</span><span class="o">=</span><span class="n">missing</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_pandas</span><span class="p">:</span>
            <span class="c1"># set exog nanmes if not given by pandas DataFrame</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">exog_names</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">xnames</span>

        <span class="c1"># TODO: the generic data handling might attach the design_info from the</span>
        <span class="c1">#       linear part, but this is incorrect for the full model and</span>
        <span class="c1">#       causes problems in wald_test_terms</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="s1">'design_info'</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">design_info</span>
        <span class="c1"># formula also might be attached which causes problems in predict</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">'formula'</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">formula_linear</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">formula</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">formula</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">formula</span>

    <span class="k">def</span> <span class="nf">_check_alpha</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
        <span class="sd">"""check and convert alpha to required list format</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        alpha : scalar, list or array_like</span>
<span class="sd">            penalization weight</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        alpha : list</span>
<span class="sd">            penalization weight, list with length equal to the number of</span>
<span class="sd">            smooth terms</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">):</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="p">[</span><span class="n">alpha</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">smoother</span><span class="o">.</span><span class="n">smoothers</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="c1"># we want alpha to be a list</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">alpha</span>

<div class="viewcode-block" id="GLMGam.fit"><a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGam.fit.html#statsmodels.gam.generalized_additive_model.GLMGam.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">'pirls'</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
            <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cov_type</span><span class="o">=</span><span class="s1">'nonrobust'</span><span class="p">,</span> <span class="n">cov_kwds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_t</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">full_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_start_irls</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">"""estimate parameters and create instance of GLMGamResults class</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        most parameters are the same as for GLM</span>
<span class="sd">        method : optimization method</span>
<span class="sd">            The special optimization method is "pirls" which uses a penalized</span>
<span class="sd">            version of IRLS. Other methods are gradient optimizers as used in</span>
<span class="sd">            base.model.LikelihoodModel.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        res : instance of wrapped GLMGamResults</span>
<span class="sd">        """</span>
        <span class="c1"># TODO: temporary hack to remove attribute</span>
        <span class="c1"># formula also might be attached which in inherited from_formula</span>
        <span class="c1"># causes problems in predict</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">'formula'</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">formula_linear</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">formula</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">formula</span>

        <span class="c1"># TODO: alpha not allowed yet, but is in `_fit_pirls`</span>
        <span class="c1"># alpha = self._check_alpha()</span>

        <span class="k">if</span> <span class="n">method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'pirls'</span><span class="p">,</span> <span class="s1">'irls'</span><span class="p">]:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_pirls</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">start_params</span><span class="o">=</span><span class="n">start_params</span><span class="p">,</span>
                                  <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span>
                                  <span class="n">cov_type</span><span class="o">=</span><span class="n">cov_type</span><span class="p">,</span> <span class="n">cov_kwds</span><span class="o">=</span><span class="n">cov_kwds</span><span class="p">,</span>
                                  <span class="n">use_t</span><span class="o">=</span><span class="n">use_t</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">max_start_irls</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">start_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
                <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_pirls</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">start_params</span><span class="o">=</span><span class="n">start_params</span><span class="p">,</span>
                                      <span class="n">maxiter</span><span class="o">=</span><span class="n">max_start_irls</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
                                      <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span>
                                      <span class="n">cov_type</span><span class="o">=</span><span class="n">cov_type</span><span class="p">,</span> <span class="n">cov_kwds</span><span class="o">=</span><span class="n">cov_kwds</span><span class="p">,</span>
                                      <span class="n">use_t</span><span class="o">=</span><span class="n">use_t</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="n">start_params</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">params</span>
                <span class="k">del</span> <span class="n">res</span>
            <span class="n">res</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">GLMGam</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">start_params</span><span class="o">=</span><span class="n">start_params</span><span class="p">,</span>
                                          <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
                                          <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span>
                                          <span class="n">cov_type</span><span class="o">=</span><span class="n">cov_type</span><span class="p">,</span> <span class="n">cov_kwds</span><span class="o">=</span><span class="n">cov_kwds</span><span class="p">,</span>
                                          <span class="n">use_t</span><span class="o">=</span><span class="n">use_t</span><span class="p">,</span>
                                          <span class="n">full_output</span><span class="o">=</span><span class="n">full_output</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="n">disp</span><span class="p">,</span>
                                          <span class="n">max_start_irls</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                          <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>

    <span class="c1"># pag 165 4.3 # pag 136 PIRLS</span>
    <span class="k">def</span> <span class="nf">_fit_pirls</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">start_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
                   <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cov_type</span><span class="o">=</span><span class="s1">'nonrobust'</span><span class="p">,</span> <span class="n">cov_kwds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_t</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">"""fit model with penalized reweighted least squares</span>
<span class="sd">        """</span>
        <span class="c1"># TODO: this currently modifies several attributes</span>
        <span class="c1"># self.scale, self.scaletype, self.mu, self.weights</span>
        <span class="c1"># self.data_weights,</span>
        <span class="c1"># and possibly self._offset_exposure</span>
        <span class="c1"># several of those might not be necessary, e.g. mu and weights</span>

        <span class="c1"># alpha = alpha * len(y) * self.scale / 100</span>
        <span class="c1"># TODO: we need to rescale alpha</span>
        <span class="n">endog</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">endog</span>
        <span class="n">wlsexog</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog</span>  <span class="c1"># smoother.basis</span>
        <span class="n">spl_s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">penal</span><span class="o">.</span><span class="n">penalty_matrix</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

        <span class="n">nobs</span><span class="p">,</span> <span class="n">n_columns</span> <span class="o">=</span> <span class="n">wlsexog</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># TODO what are these values?</span>
        <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">]</span> <span class="o">*</span> <span class="n">nobs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_weights</span> <span class="o">=</span> <span class="n">weights</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">'_offset_exposure'</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_offset_exposure</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">scaletype</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="c1"># TODO: check default scale types</span>
        <span class="c1"># self.scaletype = 'dev'</span>
        <span class="c1"># during iteration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">start_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">family</span><span class="o">.</span><span class="n">starting_mu</span><span class="p">(</span><span class="n">endog</span><span class="p">)</span>
            <span class="n">lin_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">family</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lin_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wlsexog</span><span class="p">,</span> <span class="n">start_params</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offset_exposure</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">family</span><span class="o">.</span><span class="n">fitted</span><span class="p">(</span><span class="n">lin_pred</span><span class="p">)</span>
        <span class="n">dev</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">family</span><span class="o">.</span><span class="n">deviance</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>

        <span class="n">history</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">start_params</span><span class="p">],</span> <span class="n">deviance</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">dev</span><span class="p">])</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">history</span><span class="p">[</span><span class="s1">'deviance'</span><span class="p">]</span>
        <span class="c1"># This special case is used to get the likelihood for a specific</span>
        <span class="c1"># params vector.</span>
        <span class="k">if</span> <span class="n">maxiter</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">family</span><span class="o">.</span><span class="n">fitted</span><span class="p">(</span><span class="n">lin_pred</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_scale</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
            <span class="n">wls_results</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">RegressionResults</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">maxiter</span><span class="p">):</span>

            <span class="c1"># TODO: is this equivalent to point 1 of page 136:</span>
            <span class="c1"># w = 1 / (V(mu) * g'(mu))  ?</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_weights</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">family</span><span class="o">.</span><span class="n">weights</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>

            <span class="c1"># TODO: is this equivalent to point 1 of page 136:</span>
            <span class="c1"># z = g(mu)(y - mu) + X beta  ?</span>
            <span class="n">wlsendog</span> <span class="o">=</span> <span class="p">(</span><span class="n">lin_pred</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">family</span><span class="o">.</span><span class="n">link</span><span class="o">.</span><span class="n">deriv</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">endog</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span>
                        <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offset_exposure</span><span class="p">)</span>

            <span class="c1"># this defines the augmented matrix point 2a on page 136</span>
            <span class="n">wls_results</span> <span class="o">=</span> <span class="n">penalized_wls</span><span class="p">(</span><span class="n">wlsendog</span><span class="p">,</span> <span class="n">wlsexog</span><span class="p">,</span> <span class="n">spl_s</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
            <span class="n">lin_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wlsexog</span><span class="p">,</span> <span class="n">wls_results</span><span class="o">.</span><span class="n">params</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
            <span class="n">lin_pred</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offset_exposure</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">family</span><span class="o">.</span><span class="n">fitted</span><span class="p">(</span><span class="n">lin_pred</span><span class="p">)</span>

            <span class="c1"># We do not need to update scale in GLM/LEF models</span>
            <span class="c1"># We might need it in dispersion models.</span>
            <span class="c1"># self.scale = self.estimate_scale(mu)</span>
            <span class="n">history</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_history</span><span class="p">(</span><span class="n">wls_results</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">history</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">endog</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">mu</span> <span class="o">-</span> <span class="n">endog</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">"Perfect separation detected, results not available"</span>
                <span class="k">raise</span> <span class="n">PerfectSeparationError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

            <span class="c1"># TODO need atol, rtol</span>
            <span class="c1"># args of _check_convergence: (criterion, iteration, atol, rtol)</span>
            <span class="n">converged</span> <span class="o">=</span> <span class="n">_check_convergence</span><span class="p">(</span><span class="n">criterion</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">converged</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_scale</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
        <span class="n">glm_results</span> <span class="o">=</span> <span class="n">GLMGamResults</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wls_results</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
                                    <span class="n">wls_results</span><span class="o">.</span><span class="n">normalized_cov_params</span><span class="p">,</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span>
                                    <span class="n">cov_type</span><span class="o">=</span><span class="n">cov_type</span><span class="p">,</span> <span class="n">cov_kwds</span><span class="o">=</span><span class="n">cov_kwds</span><span class="p">,</span>
                                    <span class="n">use_t</span><span class="o">=</span><span class="n">use_t</span><span class="p">)</span>

        <span class="n">glm_results</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="s2">"PIRLS"</span>
        <span class="n">history</span><span class="p">[</span><span class="s1">'iteration'</span><span class="p">]</span> <span class="o">=</span> <span class="n">iteration</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">glm_results</span><span class="o">.</span><span class="n">fit_history</span> <span class="o">=</span> <span class="n">history</span>
        <span class="n">glm_results</span><span class="o">.</span><span class="n">converged</span> <span class="o">=</span> <span class="n">converged</span>

        <span class="k">return</span> <span class="n">GLMGamResultsWrapper</span><span class="p">(</span><span class="n">glm_results</span><span class="p">)</span>

<div class="viewcode-block" id="GLMGam.select_penweight"><a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGam.select_penweight.html#statsmodels.gam.generalized_additive_model.GLMGam.select_penweight">[docs]</a>    <span class="k">def</span> <span class="nf">select_penweight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">'aic'</span><span class="p">,</span> <span class="n">start_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">start_model_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">method</span><span class="o">=</span><span class="s1">'basinhopping'</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_kwds</span><span class="p">):</span>
        <span class="sd">"""find alpha by minimizing results criterion</span>

<span class="sd">        The objective for the minimization can be results attributes like</span>
<span class="sd">        ``gcv``, ``aic`` or ``bic`` where the latter are based on effective</span>
<span class="sd">        degrees of freedom.</span>

<span class="sd">        Warning: In many case the optimization might converge to a local</span>
<span class="sd">        optimum or near optimum. Different start_params or using a global</span>
<span class="sd">        optimizer is recommended, default is basinhopping.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        criterion='aic'</span>
<span class="sd">            name of results attribute to be minimized.</span>
<span class="sd">            Default is 'aic', other options are 'gcv', 'cv' or 'bic'.</span>
<span class="sd">        start_params : None or array</span>
<span class="sd">            starting parameters for alpha in the penalization weight</span>
<span class="sd">            minimization. The parameters are internally exponentiated and</span>
<span class="sd">            the minimization is with respect to ``exp(alpha)``</span>
<span class="sd">        start_model_params : None or array</span>
<span class="sd">            starting parameter for the ``model._fit_pirls``.</span>
<span class="sd">        method : 'basinhopping', 'nm' or 'minimize'</span>
<span class="sd">            'basinhopping' and 'nm' directly use the underlying scipy.optimize</span>
<span class="sd">            functions `basinhopping` and `fmin`. 'minimize' provides access</span>
<span class="sd">            to the high level interface, `scipy.optimize.minimize`.</span>
<span class="sd">        fit_kwds : keyword arguments</span>
<span class="sd">            additional keyword arguments will be used in the call to the</span>
<span class="sd">            scipy optimizer. Which keywords are supported depends on the</span>
<span class="sd">            scipy optimization function.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        alpha : ndarray</span>
<span class="sd">            penalization parameter found by minimizing the criterion.</span>
<span class="sd">            Note that this can be only a local (near) optimum.</span>
<span class="sd">        fit_res : tuple</span>
<span class="sd">            results returned by the scipy optimization routine. The</span>
<span class="sd">            parameters in the optimization problem are `log(alpha)`</span>
<span class="sd">        history : dict</span>
<span class="sd">            history of calls to pirls and contains alpha, the fit</span>
<span class="sd">            criterion and the parameters to which pirls converged to for the</span>
<span class="sd">            given alpha.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        In the test cases Nelder-Mead and bfgs often converge to local optima,</span>
<span class="sd">        see also https://github.com/statsmodels/statsmodels/issues/5381.</span>

<span class="sd">        This does not use any analytical derivatives for the criterion</span>
<span class="sd">        minimization.</span>

<span class="sd">        Status: experimental, It is possible that defaults change if there</span>
<span class="sd">        is a better way to find a global optimum. API (e.g. type of return)</span>
<span class="sd">        might also change.</span>
<span class="sd">        """</span>
        <span class="c1"># copy attributes that are changed, so we can reset them</span>
        <span class="n">scale_keep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
        <span class="n">scaletype_keep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaletype</span>
        <span class="c1"># TODO: use .copy() method when available for all types</span>
        <span class="n">alpha_keep</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">start_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">start_params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k_smooths</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">start_params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1e-20</span> <span class="o">+</span> <span class="n">start_params</span><span class="p">)</span>

        <span class="n">history</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">history</span><span class="p">[</span><span class="s1">'alpha'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">history</span><span class="p">[</span><span class="s1">'params'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">start_model_params</span><span class="p">]</span>
        <span class="n">history</span><span class="p">[</span><span class="s1">'criterion'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">def</span> <span class="nf">fun</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            <span class="n">res_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_pirls</span><span class="p">(</span><span class="n">start_params</span><span class="o">=</span><span class="n">history</span><span class="p">[</span><span class="s1">'params'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                   <span class="n">alpha</span><span class="o">=</span><span class="n">a</span><span class="p">)</span>
            <span class="n">history</span><span class="p">[</span><span class="s1">'alpha'</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
            <span class="n">history</span><span class="p">[</span><span class="s1">'params'</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">res_</span><span class="o">.</span><span class="n">params</span><span class="p">))</span>
            <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">res_</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">'nm'</span><span class="p">:</span>
            <span class="n">kwds</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">full_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">maxfun</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
            <span class="n">kwds</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">fit_kwds</span><span class="p">)</span>
            <span class="n">fit_res</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">fmin</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
            <span class="n">opt</span> <span class="o">=</span> <span class="n">fit_res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">'basinhopping'</span><span class="p">:</span>
            <span class="n">kwds</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">minimizer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">'method'</span><span class="p">:</span> <span class="s1">'Nelder-Mead'</span><span class="p">,</span>
                        <span class="s1">'options'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'maxiter'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span> <span class="s1">'maxfev'</span><span class="p">:</span> <span class="mi">500</span><span class="p">}},</span>
                        <span class="n">niter</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
            <span class="n">kwds</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">fit_kwds</span><span class="p">)</span>
            <span class="n">fit_res</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">basinhopping</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
            <span class="n">opt</span> <span class="o">=</span> <span class="n">fit_res</span><span class="o">.</span><span class="n">x</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">'minimize'</span><span class="p">:</span>
            <span class="n">fit_res</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_kwds</span><span class="p">)</span>
            <span class="n">opt</span> <span class="o">=</span> <span class="n">fit_res</span><span class="o">.</span><span class="n">x</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'method not recognized'</span><span class="p">)</span>

        <span class="k">del</span> <span class="n">history</span><span class="p">[</span><span class="s1">'params'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># remove the model start_params</span>

        <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">opt</span><span class="p">)</span>

        <span class="c1"># reset attributes that have or might have changed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale_keep</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaletype</span> <span class="o">=</span> <span class="n">scaletype_keep</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha_keep</span>

        <span class="k">return</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">fit_res</span><span class="p">,</span> <span class="n">history</span></div>

<div class="viewcode-block" id="GLMGam.select_penweight_kfold"><a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.GLMGam.select_penweight_kfold.html#statsmodels.gam.generalized_additive_model.GLMGam.select_penweight_kfold">[docs]</a>    <span class="k">def</span> <span class="nf">select_penweight_kfold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cv_iterator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cost</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                               <span class="n">k_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">k_grid</span><span class="o">=</span><span class="mi">11</span><span class="p">):</span>
        <span class="sd">"""find alphas by k-fold cross-validation</span>

<span class="sd">        Warning: This estimates ``k_folds`` models for each point in the</span>
<span class="sd">            grid of alphas.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        alphas : None or list of arrays</span>
<span class="sd">        cv_iterator : instance</span>
<span class="sd">            instance of a cross-validation iterator, by default this is a</span>
<span class="sd">            KFold instance</span>
<span class="sd">        cost : function</span>
<span class="sd">            default is mean squared error. The cost function to evaluate the</span>
<span class="sd">            prediction error for the left out sample. This should take two</span>
<span class="sd">            arrays as argument and return one float.</span>
<span class="sd">        k_folds : int</span>
<span class="sd">            number of folds if default Kfold iterator is used.</span>
<span class="sd">            This is ignored if ``cv_iterator`` is not None.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        alpha_cv : list of float</span>
<span class="sd">            Best alpha in grid according to cross-validation</span>
<span class="sd">        res_cv : instance of MultivariateGAMCVPath</span>
<span class="sd">            The instance was used for cross-validation and holds the results</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The default alphas are defined as</span>
<span class="sd">        ``alphas = [np.logspace(0, 7, k_grid) for _ in range(k_smooths)]``</span>
<span class="sd">        """</span>

        <span class="k">if</span> <span class="n">cost</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">def</span> <span class="nf">cost</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x1</span> <span class="o">-</span> <span class="n">x2</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">alphas</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">k_grid</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k_smooths</span><span class="p">)]</span>

        <span class="k">if</span> <span class="n">cv_iterator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cv_iterator</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">k_folds</span><span class="o">=</span><span class="n">k_folds</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">gam_cv</span> <span class="o">=</span> <span class="n">MultivariateGAMCVPath</span><span class="p">(</span><span class="n">smoother</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">smoother</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span>
                                       <span class="n">gam</span><span class="o">=</span><span class="n">GLMGam</span><span class="p">,</span> <span class="n">cost</span><span class="o">=</span><span class="n">cost</span><span class="p">,</span> <span class="n">endog</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span>
                                       <span class="n">exog</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">exog_linear</span><span class="p">,</span>
                                       <span class="n">cv_iterator</span><span class="o">=</span><span class="n">cv_iterator</span><span class="p">)</span>
        <span class="n">gam_cv_res</span> <span class="o">=</span> <span class="n">gam_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">gam_cv_res</span><span class="o">.</span><span class="n">alpha_cv</span><span class="p">,</span> <span class="n">gam_cv_res</span></div></div>


<div class="viewcode-block" id="LogitGam"><a class="viewcode-back" href="../../../generated/statsmodels.gam.generalized_additive_model.LogitGam.html#statsmodels.gam.generalized_additive_model.LogitGam">[docs]</a><span class="k">class</span> <span class="nc">LogitGam</span><span class="p">(</span><span class="n">PenalizedMixin</span><span class="p">,</span> <span class="n">Logit</span><span class="p">):</span>
    <span class="sd">"""Generalized Additive model for discrete Logit</span>

<span class="sd">    This subclasses discrete_model Logit.</span>

<span class="sd">    Warning: not all inherited methods might take correctly account of the</span>
<span class="sd">    penalization</span>

<span class="sd">    not verified yet.</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">endog</span><span class="p">,</span> <span class="n">smoother</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">):</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">alpha</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">smoother</span><span class="o">.</span><span class="n">smoothers</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">smoother</span> <span class="o">=</span> <span class="n">smoother</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pen_weight</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># TODO: pen weight should not be defined here!!</span>
        <span class="n">penal</span> <span class="o">=</span> <span class="n">MultivariateGamPenalty</span><span class="p">(</span><span class="n">smoother</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">LogitGam</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">smoother</span><span class="o">.</span><span class="n">basis</span><span class="p">,</span> <span class="n">penal</span><span class="o">=</span><span class="n">penal</span><span class="p">,</span>
                                       <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">penalized_wls</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="n">penalty_matrix</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="sd">"""weighted least squares with quadratic penalty</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    endog : ndarray</span>
<span class="sd">        response or endogenous variable</span>
<span class="sd">    exog : ndarray</span>
<span class="sd">        design matrix, matrix of exogenous or explanatory variables</span>
<span class="sd">    penalty_matrix : ndarray, 2-Dim square</span>
<span class="sd">        penality matrix for quadratic penalization. Note, the penalty_matrix</span>
<span class="sd">        is multiplied by two to match non-pirls fitting methods.</span>
<span class="sd">    weights : ndarray</span>
<span class="sd">        weights for WLS</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    results : Results instance of WLS</span>
<span class="sd">    """</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="n">penalty_matrix</span>
    <span class="c1"># TODO: I do not understand why I need 2 * s</span>
    <span class="n">aug_y</span><span class="p">,</span> <span class="n">aug_x</span><span class="p">,</span> <span class="n">aug_weights</span> <span class="o">=</span> <span class="n">make_augmented_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">s</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="n">wls_results</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">WLS</span><span class="p">(</span><span class="n">aug_y</span><span class="p">,</span> <span class="n">aug_x</span><span class="p">,</span> <span class="n">aug_weights</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
    <span class="c1"># TODO: use MinimalWLS during iterations, less overhead</span>
    <span class="c1"># However, MinimalWLS does not return normalized_cov_params</span>
    <span class="c1">#   which we need at the end of the iterations</span>
    <span class="c1"># call would be</span>
    <span class="c1"># wls_results = reg_tools._MinimalWLS(aug_y, aug_x, aug_weights).fit()</span>
    <span class="n">wls_results</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">wls_results</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">wls_results</span>


<span class="k">def</span> <span class="nf">make_augmented_matrix</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="n">penalty_matrix</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="sd">"""augment endog, exog and weights with stochastic restriction matrix</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    endog : ndarray</span>
<span class="sd">        response or endogenous variable</span>
<span class="sd">    exog : ndarray</span>
<span class="sd">        design matrix, matrix of exogenous or explanatory variables</span>
<span class="sd">    penalty_matrix : ndarray, 2-Dim square</span>
<span class="sd">        penality matrix for quadratic penalization</span>
<span class="sd">    weights : ndarray</span>
<span class="sd">        weights for WLS</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    endog_aug : ndarray</span>
<span class="sd">        augmented response variable</span>
<span class="sd">    exog_aug : ndarray</span>
<span class="sd">        augmented design matrix</span>
<span class="sd">    weights_aug : ndarray</span>
<span class="sd">        augmented weights for WLS</span>
<span class="sd">    """</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="o">=</span> <span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">,</span> <span class="n">penalty_matrix</span>
    <span class="n">nobs</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># TODO: needs full because of broadcasting with weights</span>
    <span class="c1"># check what weights should be doing</span>
    <span class="n">rs</span> <span class="o">=</span> <span class="n">matrix_sqrt</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">rs</span><span class="p">])</span>  <span class="c1"># augmented x</span>
    <span class="n">n_samp1es_x1</span> <span class="o">=</span> <span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">y1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_samp1es_x1</span><span class="p">)</span>  <span class="c1"># augmented y</span>
    <span class="n">y1</span><span class="p">[:</span><span class="n">nobs</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>

    <span class="n">id1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">]</span> <span class="o">*</span> <span class="n">rs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">w1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">weights</span><span class="p">,</span> <span class="n">id1</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">w1</span>
</pre></div>

          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2009-2019, Josef Perktold, Skipper Seabold, Jonathan Taylor, statsmodels-developers.
              
          </div>
            Last updated on
              Feb 21, 2020.
            <br/>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 2.4.2.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../../../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>