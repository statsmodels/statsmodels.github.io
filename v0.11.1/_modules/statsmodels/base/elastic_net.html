

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../../../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../../../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../../../_static/javascripts/modernizr.js"></script>
  
  
  
    <title>statsmodels.base.elastic_net &#8212; statsmodels</title>
  <link rel="icon" type="image/png" sizes="32x32" href="../../../_static/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="../../../_static/icons/favicon-16x16.png">
  <link rel="manifest" href="../../../_static/icons/site.webmanifest">
  <link rel="mask-icon" href="../../../_static/icons/safari-pinned-tab.svg" color="#919191">
  <meta name="msapplication-TileColor" content="#2b5797">
  <meta name="msapplication-config" content="../../../_static/icons/browserconfig.xml">
  <link rel="stylesheet" href="../../../_static/stylesheets/examples.css">
    <link rel="stylesheet" href="../../../_static/material.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../../about.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  
   
  
  <script src="../../../_static/javascripts/version_dropdown.js"></script>
  <script>
    var json_loc = "../../../_static/versions.json",
        target_loc = "../../../../",
        text = "Versions";
    $( document ).ready( add_version_dropdown(json_loc, target_loc, text));
  </script>


  </head>
  <body dir=ltr
        data-md-color-primary=indigo data-md-color-accent=blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#_modules/statsmodels/base/elastic_net" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../../index.html" title="statsmodels"
           class="md-header-nav__button md-logo">
          
              <img src="../../../_static/statsmodels-logo-v2-bw.svg" height="26"
                   alt="statsmodels logo">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">statsmodels v0.11.1</span>
          <span class="md-header-nav__topic"> statsmodels.base.elastic_net </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../../../search.html" method="GET" name="search">
      <input type="text" class="md-search__input" name="q" placeholder="Search"
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/statsmodels/statsmodels" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    statsmodels
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
          <li class="md-tabs__item"><a href="../../index.html" class="md-tabs__link">Module code</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../../index.html" title="statsmodels" class="md-nav__button md-logo">
      
        <img src="../../../_static/statsmodels-logo-v2-bw.svg" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../../../index.html"
       title="statsmodels">statsmodels v0.11.1</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/statsmodels/statsmodels" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    statsmodels
  </div>
</a>
    </div>
  
  

  
  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
      <a href="../../../install.html" class="md-nav__link">Installing statsmodels</a>
      
    </li>
    <li class="md-nav__item">
    
      <a href="../../../gettingstarted.html" class="md-nav__link">Getting started</a>
      
    </li>
    <li class="md-nav__item">
    
      <a href="../../../user-guide.html" class="md-nav__link">User Guide</a>
      
    </li>
    <li class="md-nav__item">
    
      <a href="../../../examples/index.html" class="md-nav__link">Examples</a>
      
    </li>
    <li class="md-nav__item">
    
      <a href="../../../api.html" class="md-nav__link">API Reference</a>
      
    </li>
    <li class="md-nav__item">
    
      <a href="../../../about.html" class="md-nav__link">About statsmodels</a>
      
    </li>
    <li class="md-nav__item">
    
      <a href="../../../dev/index.html" class="md-nav__link">Developer Page</a>
      
    </li>
    <li class="md-nav__item">
    
      <a href="../../../release/index.html" class="md-nav__link">Release Notes</a>
      
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
  <ul class="md-nav__list" data-md-scrollfix="">
    

<li id="searchbox" class="md-nav__item"></li>

  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <h1 id="modules-statsmodels-base-elastic-net--page-root">Source code for statsmodels.base.elastic_net</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">statsmodels.base.model</span> <span class="kn">import</span> <span class="n">Results</span>
<span class="kn">import</span> <span class="nn">statsmodels.base.wrapper</span> <span class="k">as</span> <span class="nn">wrap</span>
<span class="kn">from</span> <span class="nn">statsmodels.tools.decorators</span> <span class="kn">import</span> <span class="n">cache_readonly</span>

<span class="sd">"""</span>
<span class="sd">Elastic net regularization.</span>

<span class="sd">Routines for fitting regression models using elastic net</span>
<span class="sd">regularization.  The elastic net minimizes the objective function</span>

<span class="sd">-llf / nobs + alpha((1 - L1_wt) * sum(params**2) / 2 +</span>
<span class="sd">    L1_wt * sum(abs(params)))</span>

<span class="sd">The algorithm implemented here closely follows the implementation in</span>
<span class="sd">the R glmnet package, documented here:</span>

<span class="sd">http://cran.r-project.org/web/packages/glmnet/index.html</span>

<span class="sd">and here:</span>

<span class="sd">http://www.jstatsoft.org/v33/i01/paper</span>

<span class="sd">This routine should work for any regression model that implements</span>
<span class="sd">loglike, score, and hess.</span>
<span class="sd">"""</span>


<span class="k">def</span> <span class="nf">_gen_npfuncs</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">L1_wt</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">loglike_kwds</span><span class="p">,</span> <span class="n">score_kwds</span><span class="p">,</span> <span class="n">hess_kwds</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Negative penalized log-likelihood functions.</span>

<span class="sd">    Returns the negative penalized log-likelihood, its derivative, and</span>
<span class="sd">    its Hessian.  The penalty only includes the smooth (L2) term.</span>

<span class="sd">    All three functions have argument signature (x, model), where</span>
<span class="sd">    ``x`` is a point in the parameter space and ``model`` is an</span>
<span class="sd">    arbitrary statsmodels regression model.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">nploglike</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="n">nobs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">nobs</span>
        <span class="n">pen_llf</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">L1_wt</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">params</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="n">llf</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">loglike</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">params</span><span class="p">],</span> <span class="o">**</span><span class="n">loglike_kwds</span><span class="p">)</span>
        <span class="k">return</span> <span class="o">-</span> <span class="n">llf</span> <span class="o">/</span> <span class="n">nobs</span> <span class="o">+</span> <span class="n">pen_llf</span>

    <span class="k">def</span> <span class="nf">npscore</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="n">nobs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">nobs</span>
        <span class="n">pen_grad</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">L1_wt</span><span class="p">)</span> <span class="o">*</span> <span class="n">params</span>
        <span class="n">gr</span> <span class="o">=</span> <span class="o">-</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">params</span><span class="p">],</span> <span class="o">**</span><span class="n">score_kwds</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">nobs</span>
        <span class="k">return</span> <span class="n">gr</span> <span class="o">+</span> <span class="n">pen_grad</span>

    <span class="k">def</span> <span class="nf">nphess</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="n">nobs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">nobs</span>
        <span class="n">pen_hess</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">L1_wt</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="o">-</span><span class="n">model</span><span class="o">.</span><span class="n">hessian</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">params</span><span class="p">],</span> <span class="o">**</span><span class="n">hess_kwds</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">nobs</span> <span class="o">+</span> <span class="n">pen_hess</span>
        <span class="k">return</span> <span class="n">h</span>

    <span class="k">return</span> <span class="n">nploglike</span><span class="p">,</span> <span class="n">npscore</span><span class="p">,</span> <span class="n">nphess</span>


<span class="k">def</span> <span class="nf">fit_elasticnet</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">"coord_descent"</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                   <span class="n">alpha</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">L1_wt</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">start_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cnvrg_tol</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
                   <span class="n">zero_tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_step</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">loglike_kwds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">score_kwds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hess_kwds</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Return an elastic net regularized fit to a regression model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : model object</span>
<span class="sd">        A statsmodels object implementing ``loglike``, ``score``, and</span>
<span class="sd">        ``hessian``.</span>
<span class="sd">    method : {'coord_descent'}</span>
<span class="sd">        Only the coordinate descent algorithm is implemented.</span>
<span class="sd">    maxiter : int</span>
<span class="sd">        The maximum number of iteration cycles (an iteration cycle</span>
<span class="sd">        involves running coordinate descent on all variables).</span>
<span class="sd">    alpha : scalar or array_like</span>
<span class="sd">        The penalty weight.  If a scalar, the same penalty weight</span>
<span class="sd">        applies to all variables in the model.  If a vector, it</span>
<span class="sd">        must have the same length as `params`, and contains a</span>
<span class="sd">        penalty weight for each coefficient.</span>
<span class="sd">    L1_wt : scalar</span>
<span class="sd">        The fraction of the penalty given to the L1 penalty term.</span>
<span class="sd">        Must be between 0 and 1 (inclusive).  If 0, the fit is</span>
<span class="sd">        a ridge fit, if 1 it is a lasso fit.</span>
<span class="sd">    start_params : array_like</span>
<span class="sd">        Starting values for `params`.</span>
<span class="sd">    cnvrg_tol : scalar</span>
<span class="sd">        If `params` changes by less than this amount (in sup-norm)</span>
<span class="sd">        in one iteration cycle, the algorithm terminates with</span>
<span class="sd">        convergence.</span>
<span class="sd">    zero_tol : scalar</span>
<span class="sd">        Any estimated coefficient smaller than this value is</span>
<span class="sd">        replaced with zero.</span>
<span class="sd">    refit : bool</span>
<span class="sd">        If True, the model is refit using only the variables that have</span>
<span class="sd">        non-zero coefficients in the regularized fit.  The refitted</span>
<span class="sd">        model is not regularized.</span>
<span class="sd">    check_step : bool</span>
<span class="sd">        If True, confirm that the first step is an improvement and search</span>
<span class="sd">        further if it is not.</span>
<span class="sd">    loglike_kwds : dict-like or None</span>
<span class="sd">        Keyword arguments for the log-likelihood function.</span>
<span class="sd">    score_kwds : dict-like or None</span>
<span class="sd">        Keyword arguments for the score function.</span>
<span class="sd">    hess_kwds : dict-like or None</span>
<span class="sd">        Keyword arguments for the Hessian function.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Results</span>
<span class="sd">        A results object.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The ``elastic net`` penalty is a combination of L1 and L2</span>
<span class="sd">    penalties.</span>

<span class="sd">    The function that is minimized is:</span>

<span class="sd">    -loglike/n + alpha*((1-L1_wt)*|params|_2^2/2 + L1_wt*|params|_1)</span>

<span class="sd">    where |*|_1 and |*|_2 are the L1 and L2 norms.</span>

<span class="sd">    The computational approach used here is to obtain a quadratic</span>
<span class="sd">    approximation to the smooth part of the target function:</span>

<span class="sd">    -loglike/n + alpha*(1-L1_wt)*|params|_2^2/2</span>

<span class="sd">    then repeatedly optimize the L1 penalized version of this function</span>
<span class="sd">    along coordinate axes.</span>
<span class="sd">    """</span>

    <span class="n">k_exog</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">exog</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">loglike_kwds</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">loglike_kwds</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">loglike_kwds</span>
    <span class="n">score_kwds</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">score_kwds</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">score_kwds</span>
    <span class="n">hess_kwds</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">hess_kwds</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">hess_kwds</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">alpha</span><span class="p">):</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">k_exog</span><span class="p">)</span>

    <span class="c1"># Define starting params</span>
    <span class="k">if</span> <span class="n">start_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">k_exog</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">start_params</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="n">btol</span> <span class="o">=</span> <span class="mf">1e-4</span>
    <span class="n">params_zero</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>

    <span class="n">init_args</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">_get_init_kwds</span><span class="p">()</span>
    <span class="c1"># we do not need a copy of init_args b/c get_init_kwds provides new dict</span>
    <span class="n">init_args</span><span class="p">[</span><span class="s1">'hasconst'</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">model_offset</span> <span class="o">=</span> <span class="n">init_args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">'offset'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="s1">'exposure'</span> <span class="ow">in</span> <span class="n">init_args</span> <span class="ow">and</span> <span class="n">init_args</span><span class="p">[</span><span class="s1">'exposure'</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">model_offset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_offset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">init_args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">'exposure'</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model_offset</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">init_args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">'exposure'</span><span class="p">))</span>

    <span class="n">fgh_list</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">_gen_npfuncs</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">L1_wt</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">loglike_kwds</span><span class="p">,</span> <span class="n">score_kwds</span><span class="p">,</span> <span class="n">hess_kwds</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k_exog</span><span class="p">)]</span>

    <span class="k">for</span> <span class="n">itr</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">maxiter</span><span class="p">):</span>

        <span class="c1"># Sweep through the parameters</span>
        <span class="n">params_save</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k_exog</span><span class="p">):</span>

            <span class="c1"># Under the active set method, if a parameter becomes</span>
            <span class="c1"># zero we do not try to change it again.</span>
            <span class="c1"># TODO : give the user the option to switch this off</span>
            <span class="k">if</span> <span class="n">params_zero</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span>
                <span class="k">continue</span>

            <span class="c1"># Set the offset to account for the variables that are</span>
            <span class="c1"># being held fixed in the current coordinate</span>
            <span class="c1"># optimization.</span>
            <span class="n">params0</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">params0</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">exog</span><span class="p">,</span> <span class="n">params0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">model_offset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">offset</span> <span class="o">+=</span> <span class="n">model_offset</span>

            <span class="c1"># Create a one-variable model for optimization.</span>
            <span class="n">model_1var</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span>
                <span class="n">model</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">exog</span><span class="p">[:,</span> <span class="n">k</span><span class="p">],</span> <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span> <span class="o">**</span><span class="n">init_args</span><span class="p">)</span>

            <span class="c1"># Do the one-dimensional optimization.</span>
            <span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">hess</span> <span class="o">=</span> <span class="n">fgh_list</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            <span class="n">params</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">_opt_1d</span><span class="p">(</span>
                <span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">hess</span><span class="p">,</span> <span class="n">model_1var</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">alpha</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">*</span><span class="n">L1_wt</span><span class="p">,</span>
                <span class="n">tol</span><span class="o">=</span><span class="n">btol</span><span class="p">,</span> <span class="n">check_step</span><span class="o">=</span><span class="n">check_step</span><span class="p">)</span>

            <span class="c1"># Update the active set</span>
            <span class="k">if</span> <span class="n">itr</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">zero_tol</span><span class="p">:</span>
                <span class="n">params_zero</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">params</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>

        <span class="c1"># Check for convergence</span>
        <span class="n">pchange</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">params</span> <span class="o">-</span> <span class="n">params_save</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">pchange</span> <span class="o">&lt;</span> <span class="n">cnvrg_tol</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="c1"># Set approximate zero coefficients to be exactly zero</span>
    <span class="n">params</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">params</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">zero_tol</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">refit</span><span class="p">:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">RegularizedResults</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">RegularizedResultsWrapper</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

    <span class="c1"># Fit the reduced model to get standard errors and other</span>
    <span class="c1"># post-estimation results.</span>
    <span class="n">ii</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">k_exog</span><span class="p">,</span> <span class="n">k_exog</span><span class="p">))</span>
    <span class="n">init_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">k</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">_init_keys</span><span class="p">])</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ii</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">model1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">exog</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">],</span> <span class="o">**</span><span class="n">init_args</span><span class="p">)</span>
        <span class="n">rslt</span> <span class="o">=</span> <span class="n">model1</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">params</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">rslt</span><span class="o">.</span><span class="n">params</span>
        <span class="n">cov</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">ii</span><span class="p">,</span> <span class="n">ii</span><span class="p">)]</span> <span class="o">=</span> <span class="n">rslt</span><span class="o">.</span><span class="n">normalized_cov_params</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Hack: no variables were selected but we need to run fit in</span>
        <span class="c1"># order to get the correct results class.  So just fit a model</span>
        <span class="c1"># with one variable.</span>
        <span class="n">model1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">exog</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="o">**</span><span class="n">init_args</span><span class="p">)</span>
        <span class="n">rslt</span> <span class="o">=</span> <span class="n">model1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">maxiter</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># fit may return a results or a results wrapper</span>
    <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">rslt</span><span class="o">.</span><span class="vm">__class__</span><span class="p">,</span> <span class="n">wrap</span><span class="o">.</span><span class="n">ResultsWrapper</span><span class="p">):</span>
        <span class="n">klass</span> <span class="o">=</span> <span class="n">rslt</span><span class="o">.</span><span class="n">_results</span><span class="o">.</span><span class="vm">__class__</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">klass</span> <span class="o">=</span> <span class="n">rslt</span><span class="o">.</span><span class="vm">__class__</span>

    <span class="c1"># Not all models have a scale</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">rslt</span><span class="p">,</span> <span class="s1">'scale'</span><span class="p">):</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">rslt</span><span class="o">.</span><span class="n">scale</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="c1"># The degrees of freedom should reflect the number of parameters</span>
    <span class="c1"># in the refit model, not including the zeros that are displayed</span>
    <span class="c1"># to indicate which variables were dropped.  See issue #1723 for</span>
    <span class="c1"># discussion about setting df parameters in model and results</span>
    <span class="c1"># classes.</span>
    <span class="n">p</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">df_model</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">df_resid</span>
    <span class="n">model</span><span class="o">.</span><span class="n">df_model</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ii</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">df_resid</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">nobs</span> <span class="o">-</span> <span class="n">model</span><span class="o">.</span><span class="n">df_model</span>

    <span class="c1"># Assuming a standard signature for creating results classes.</span>
    <span class="n">refit</span> <span class="o">=</span> <span class="n">klass</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
    <span class="n">refit</span><span class="o">.</span><span class="n">regularized</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">refit</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
    <span class="n">refit</span><span class="o">.</span><span class="n">fit_history</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'iteration'</span><span class="p">:</span> <span class="n">itr</span> <span class="o">+</span> <span class="mi">1</span><span class="p">}</span>

    <span class="c1"># Restore df in model class, see issue #1723 for discussion.</span>
    <span class="n">model</span><span class="o">.</span><span class="n">df_model</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">df_resid</span> <span class="o">=</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span>

    <span class="k">return</span> <span class="n">refit</span>


<span class="k">def</span> <span class="nf">_opt_1d</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">hess</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">L1_wt</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span>
            <span class="n">check_step</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    One-dimensional helper for elastic net.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    func : function</span>
<span class="sd">        A smooth function of a single variable to be optimized</span>
<span class="sd">        with L1 penaty.</span>
<span class="sd">    grad : function</span>
<span class="sd">        The gradient of `func`.</span>
<span class="sd">    hess : function</span>
<span class="sd">        The Hessian of `func`.</span>
<span class="sd">    model : statsmodels model</span>
<span class="sd">        The model being fit.</span>
<span class="sd">    start : real</span>
<span class="sd">        A starting value for the function argument</span>
<span class="sd">    L1_wt : non-negative real</span>
<span class="sd">        The weight for the L1 penalty function.</span>
<span class="sd">    tol : non-negative real</span>
<span class="sd">        A convergence threshold.</span>
<span class="sd">    check_step : bool</span>
<span class="sd">        If True, check that the first step is an improvement and</span>
<span class="sd">        use bisection if it is not.  If False, return after the</span>
<span class="sd">        first step regardless.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    ``func``, ``grad``, and ``hess`` have argument signature (x,</span>
<span class="sd">    model), where ``x`` is a point in the parameter space and</span>
<span class="sd">    ``model`` is the model being fit.</span>

<span class="sd">    If the log-likelihood for the model is exactly quadratic, the</span>
<span class="sd">    global minimum is returned in one step.  Otherwise numerical</span>
<span class="sd">    bisection is used.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    The argmin of the objective function.</span>
<span class="sd">    """</span>

    <span class="c1"># Overview:</span>
    <span class="c1"># We want to minimize L(x) + L1_wt*abs(x), where L() is a smooth</span>
    <span class="c1"># loss function that includes the log-likelihood and L2 penalty.</span>
    <span class="c1"># This is a 1-dimensional optimization.  If L(x) is exactly</span>
    <span class="c1"># quadratic we can solve for the argmin exactly.  Otherwise we</span>
    <span class="c1"># approximate L(x) with a quadratic function Q(x) and try to use</span>
    <span class="c1"># the minimizer of Q(x) + L1_wt*abs(x).  But if this yields an</span>
    <span class="c1"># uphill step for the actual target function L(x) + L1_wt*abs(x),</span>
    <span class="c1"># then we fall back to a expensive line search.  The line search</span>
    <span class="c1"># is never needed for OLS.</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">start</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">hess</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">b</span> <span class="o">-</span> <span class="n">c</span><span class="o">*</span><span class="n">x</span>

    <span class="c1"># The optimum is achieved by hard thresholding to zero</span>
    <span class="k">if</span> <span class="n">L1_wt</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">0.</span>

    <span class="c1"># x + h is the minimizer of the Q(x) + L1_wt*abs(x)</span>
    <span class="k">if</span> <span class="n">d</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="p">(</span><span class="n">L1_wt</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="n">c</span>
    <span class="k">elif</span> <span class="n">d</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">L1_wt</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="n">c</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

    <span class="c1"># If the new point is not uphill for the target function, take it</span>
    <span class="c1"># and return.  This check is a bit expensive and un-necessary for</span>
    <span class="c1"># OLS</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">check_step</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">h</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">h</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="o">+</span> <span class="n">L1_wt</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">h</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">f1</span> <span class="o">&lt;=</span> <span class="n">f</span> <span class="o">+</span> <span class="n">L1_wt</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">h</span>

    <span class="c1"># Fallback for models where the loss is not quadratic</span>
    <span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">brent</span>
    <span class="n">x_opt</span> <span class="o">=</span> <span class="n">brent</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">model</span><span class="p">,),</span> <span class="n">brack</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_opt</span>


<div class="viewcode-block" id="RegularizedResults"><a class="viewcode-back" href="../../../generated/statsmodels.base.elastic_net.RegularizedResults.html#statsmodels.base.elastic_net.RegularizedResults">[docs]</a><span class="k">class</span> <span class="nc">RegularizedResults</span><span class="p">(</span><span class="n">Results</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Results for models estimated using regularization</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : Model</span>
<span class="sd">        The model instance used to estimate the parameters.</span>
<span class="sd">    params : ndarray</span>
<span class="sd">        The estimated (regularized) parameters.</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RegularizedResults</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

    <span class="nd">@cache_readonly</span>
    <span class="k">def</span> <span class="nf">fittedvalues</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""</span>
<span class="sd">        The predicted values from the model at the estimated parameters.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span></div>


<span class="k">class</span> <span class="nc">RegularizedResultsWrapper</span><span class="p">(</span><span class="n">wrap</span><span class="o">.</span><span class="n">ResultsWrapper</span><span class="p">):</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'params'</span><span class="p">:</span> <span class="s1">'columns'</span><span class="p">,</span>
        <span class="s1">'resid'</span><span class="p">:</span> <span class="s1">'rows'</span><span class="p">,</span>
        <span class="s1">'fittedvalues'</span><span class="p">:</span> <span class="s1">'rows'</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">_wrap_attrs</span> <span class="o">=</span> <span class="n">_attrs</span>
<span class="n">wrap</span><span class="o">.</span><span class="n">populate_wrapper</span><span class="p">(</span><span class="n">RegularizedResultsWrapper</span><span class="p">,</span>  <span class="c1"># noqa:E305</span>
                      <span class="n">RegularizedResults</span><span class="p">)</span>
</pre></div>

          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2009-2019, Josef Perktold, Skipper Seabold, Jonathan Taylor, statsmodels-developers.
              
          </div>
            Last updated on
              Feb 21, 2020.
            <br/>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 2.4.2.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../../../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>