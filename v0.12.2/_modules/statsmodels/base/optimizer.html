

<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../../../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../../../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../../../_static/javascripts/modernizr.js"></script>
  
  
  
    <title>statsmodels.base.optimizer &#8212; statsmodels</title>
  <link rel="icon" type="image/png" sizes="32x32" href="../../../_static/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="../../../_static/icons/favicon-16x16.png">
  <link rel="manifest" href="../../../_static/icons/site.webmanifest">
  <link rel="mask-icon" href="../../../_static/icons/safari-pinned-tab.svg" color="#919191">
  <meta name="msapplication-TileColor" content="#2b5797">
  <meta name="msapplication-config" content="../../../_static/icons/browserconfig.xml">
  <link rel="stylesheet" href="../../../_static/stylesheets/examples.css">
  <link rel="stylesheet" href="../../../_static/stylesheets/deprecation.css">
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/material.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../../about.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=indigo data-md-color-accent=blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#_modules/statsmodels/base/optimizer" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../../index.html" title="statsmodels"
           class="md-header-nav__button md-logo">
          
              <img src="../../../_static/statsmodels-logo-v2-bw.svg" height="26"
                   alt="statsmodels logo">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">statsmodels v0.12.2</span>
          <span class="md-header-nav__topic"> statsmodels.base.optimizer </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../../../search.html" method="GET" name="search">
      <input type="text" class="md-search__input" name="q" placeholder="Search"
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/statsmodels/statsmodels" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    statsmodels
  </div>
</a>
          </div>
        </div>
      
      
  
  <script src="../../../_static/javascripts/version_dropdown.js"></script>
  <script>
    var json_loc = "../../../_static/versions.json",
        target_loc = "../../../../",
        text = "Versions";
    $( document ).ready( add_version_dropdown(json_loc, target_loc, text));
  </script>
  

    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
          <li class="md-tabs__item"><a href="../../index.html" class="md-tabs__link">Module code</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../../index.html" title="statsmodels" class="md-nav__button md-logo">
      
        <img src="../../../_static/statsmodels-logo-v2-bw.svg" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../../../index.html"
       title="statsmodels">statsmodels v0.12.2</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/statsmodels/statsmodels" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    statsmodels
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
    
      <a href="../../../install.html" class="md-nav__link">Installing statsmodels</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../gettingstarted.html" class="md-nav__link">Getting started</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../user-guide.html" class="md-nav__link">User Guide</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../examples/index.html" class="md-nav__link">Examples</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../api.html" class="md-nav__link">API Reference</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../about.html" class="md-nav__link">About statsmodels</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../dev/index.html" class="md-nav__link">Developer Page</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../release/index.html" class="md-nav__link">Release Notes</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
  <ul class="md-nav__list" data-md-scrollfix="">
    

<li id="searchbox" class="md-nav__item"></li>

  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <h1 id="modules-statsmodels-base-optimizer--page-root">Source code for statsmodels.base.optimizer</h1><div class="highlight"><pre>
<span></span><span class="sd">"""</span>
<span class="sd">Functions that are general enough to use for any model fitting. The idea is</span>
<span class="sd">to untie these from LikelihoodModel so that they may be re-used generally.</span>
<span class="sd">"""</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">optimize</span>


<span class="k">def</span> <span class="nf">_check_method</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">methods</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">:</span>
        <span class="n">message</span> <span class="o">=</span> <span class="s2">"Unknown fit method </span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span> <span class="n">method</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>


<div class="viewcode-block" id="Optimizer"><a class="viewcode-back" href="../../../generated/statsmodels.base.optimizer.Optimizer.html#statsmodels.base.optimizer.Optimizer">[docs]</a><span class="k">class</span> <span class="nc">Optimizer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">objective</span><span class="p">,</span> <span class="n">gradient</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">fargs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span>
             <span class="n">hessian</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">'newton'</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">full_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">disp</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retall</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">"""</span>
<span class="sd">        Fit function for any model with an objective function.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        objective : function</span>
<span class="sd">            Objective function to be minimized.</span>
<span class="sd">        gradient : function</span>
<span class="sd">            The gradient of the objective function.</span>
<span class="sd">        start_params : array_like, optional</span>
<span class="sd">            Initial guess of the solution for the loglikelihood maximization.</span>
<span class="sd">            The default is an array of zeros.</span>
<span class="sd">        fargs : tuple</span>
<span class="sd">            Extra arguments passed to the objective function, i.e.</span>
<span class="sd">            objective(x,*args)</span>
<span class="sd">        kwargs : tuple</span>
<span class="sd">            Extra keyworded arguments passed to the objective function, i.e.</span>
<span class="sd">            objective(x,**kwargs)</span>
<span class="sd">        hessian : str, optional</span>
<span class="sd">            Method for computing the Hessian matrix, if applicable.</span>
<span class="sd">        method : str {'newton','nm','bfgs','powell','cg','ncg','basinhopping',</span>
<span class="sd">            'minimize'}</span>
<span class="sd">            Method can be 'newton' for Newton-Raphson, 'nm' for Nelder-Mead,</span>
<span class="sd">            'bfgs' for Broyden-Fletcher-Goldfarb-Shanno, 'powell' for modified</span>
<span class="sd">            Powell's method, 'cg' for conjugate gradient, 'ncg' for Newton-</span>
<span class="sd">            conjugate gradient, 'basinhopping' for global basin-hopping</span>
<span class="sd">            solver, if available or a generic 'minimize' which is a wrapper for</span>
<span class="sd">            scipy.optimize.minimize. `method` determines which solver from</span>
<span class="sd">            scipy.optimize is used. The explicit arguments in `fit` are passed</span>
<span class="sd">            to the solver, with the exception of the basin-hopping solver. Each</span>
<span class="sd">            solver has several optional arguments that are not the same across</span>
<span class="sd">            solvers. See the notes section below (or scipy.optimize) for the</span>
<span class="sd">            available arguments and for the list of explicit arguments that the</span>
<span class="sd">            basin-hopping solver supports..</span>
<span class="sd">        maxiter : int</span>
<span class="sd">            The maximum number of iterations to perform.</span>
<span class="sd">        full_output : bool</span>
<span class="sd">            Set to True to have all available output in the Results object's</span>
<span class="sd">            mle_retvals attribute. The output is dependent on the solver.</span>
<span class="sd">            See LikelihoodModelResults notes section for more information.</span>
<span class="sd">        disp : bool</span>
<span class="sd">            Set to True to print convergence messages.</span>
<span class="sd">        callback : callable callback(xk)</span>
<span class="sd">            Called after each iteration, as callback(xk), where xk is the</span>
<span class="sd">            current parameter vector.</span>
<span class="sd">        retall : bool</span>
<span class="sd">            Set to True to return list of solutions at each iteration.</span>
<span class="sd">            Available in Results object's mle_retvals attribute.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        xopt : ndarray</span>
<span class="sd">            The solution to the objective function</span>
<span class="sd">        retvals : dict, None</span>
<span class="sd">            If `full_output` is True then this is a dictionary which holds</span>
<span class="sd">            information returned from the solver used. If it is False, this is</span>
<span class="sd">            None.</span>
<span class="sd">        optim_settings : dict</span>
<span class="sd">            A dictionary that contains the parameters passed to the solver.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The 'basinhopping' solver ignores `maxiter`, `retall`, `full_output`</span>
<span class="sd">        explicit arguments.</span>

<span class="sd">        Optional arguments for the solvers (available in Results.mle_settings)::</span>

<span class="sd">            'newton'</span>
<span class="sd">                tol : float</span>
<span class="sd">                    Relative error in params acceptable for convergence.</span>
<span class="sd">            'nm' -- Nelder Mead</span>
<span class="sd">                xtol : float</span>
<span class="sd">                    Relative error in params acceptable for convergence</span>
<span class="sd">                ftol : float</span>
<span class="sd">                    Relative error in loglike(params) acceptable for</span>
<span class="sd">                    convergence</span>
<span class="sd">                maxfun : int</span>
<span class="sd">                    Maximum number of function evaluations to make.</span>
<span class="sd">            'bfgs'</span>
<span class="sd">                gtol : float</span>
<span class="sd">                    Stop when norm of gradient is less than gtol.</span>
<span class="sd">                norm : float</span>
<span class="sd">                    Order of norm (np.Inf is max, -np.Inf is min)</span>
<span class="sd">                epsilon</span>
<span class="sd">                    If fprime is approximated, use this value for the step</span>
<span class="sd">                    size. Only relevant if LikelihoodModel.score is None.</span>
<span class="sd">            'lbfgs'</span>
<span class="sd">                m : int</span>
<span class="sd">                    The maximum number of variable metric corrections used to</span>
<span class="sd">                    define the limited memory matrix. (The limited memory BFGS</span>
<span class="sd">                    method does not store the full hessian but uses this many</span>
<span class="sd">                    terms in an approximation to it.)</span>
<span class="sd">                pgtol : float</span>
<span class="sd">                    The iteration will stop when</span>
<span class="sd">                    ``max{|proj g_i | i = 1, ..., n} &lt;= pgtol`` where pg_i is</span>
<span class="sd">                    the i-th component of the projected gradient.</span>
<span class="sd">                factr : float</span>
<span class="sd">                    The iteration stops when</span>
<span class="sd">                    ``(f^k - f^{k+1})/max{|f^k|,|f^{k+1}|,1} &lt;= factr * eps``,</span>
<span class="sd">                    where eps is the machine precision, which is automatically</span>
<span class="sd">                    generated by the code. Typical values for factr are: 1e12</span>
<span class="sd">                    for low accuracy; 1e7 for moderate accuracy; 10.0 for</span>
<span class="sd">                    extremely high accuracy. See Notes for relationship to</span>
<span class="sd">                    ftol, which is exposed (instead of factr) by the</span>
<span class="sd">                    scipy.optimize.minimize interface to L-BFGS-B.</span>
<span class="sd">                maxfun : int</span>
<span class="sd">                    Maximum number of iterations.</span>
<span class="sd">                epsilon : float</span>
<span class="sd">                    Step size used when approx_grad is True, for numerically</span>
<span class="sd">                    calculating the gradient</span>
<span class="sd">                approx_grad : bool</span>
<span class="sd">                    Whether to approximate the gradient numerically (in which</span>
<span class="sd">                    case func returns only the function value).</span>
<span class="sd">            'cg'</span>
<span class="sd">                gtol : float</span>
<span class="sd">                    Stop when norm of gradient is less than gtol.</span>
<span class="sd">                norm : float</span>
<span class="sd">                    Order of norm (np.Inf is max, -np.Inf is min)</span>
<span class="sd">                epsilon : float</span>
<span class="sd">                    If fprime is approximated, use this value for the step</span>
<span class="sd">                    size. Can be scalar or vector.  Only relevant if</span>
<span class="sd">                    Likelihoodmodel.score is None.</span>
<span class="sd">            'ncg'</span>
<span class="sd">                fhess_p : callable f'(x,*args)</span>
<span class="sd">                    Function which computes the Hessian of f times an arbitrary</span>
<span class="sd">                    vector, p.  Should only be supplied if</span>
<span class="sd">                    LikelihoodModel.hessian is None.</span>
<span class="sd">                avextol : float</span>
<span class="sd">                    Stop when the average relative error in the minimizer</span>
<span class="sd">                    falls below this amount.</span>
<span class="sd">                epsilon : float or ndarray</span>
<span class="sd">                    If fhess is approximated, use this value for the step size.</span>
<span class="sd">                    Only relevant if Likelihoodmodel.hessian is None.</span>
<span class="sd">            'powell'</span>
<span class="sd">                xtol : float</span>
<span class="sd">                    Line-search error tolerance</span>
<span class="sd">                ftol : float</span>
<span class="sd">                    Relative error in loglike(params) for acceptable for</span>
<span class="sd">                    convergence.</span>
<span class="sd">                maxfun : int</span>
<span class="sd">                    Maximum number of function evaluations to make.</span>
<span class="sd">                start_direc : ndarray</span>
<span class="sd">                    Initial direction set.</span>
<span class="sd">            'basinhopping'</span>
<span class="sd">                niter : int</span>
<span class="sd">                    The number of basin hopping iterations.</span>
<span class="sd">                niter_success : int</span>
<span class="sd">                    Stop the run if the global minimum candidate remains the</span>
<span class="sd">                    same for this number of iterations.</span>
<span class="sd">                T : float</span>
<span class="sd">                    The "temperature" parameter for the accept or reject</span>
<span class="sd">                    criterion. Higher "temperatures" mean that larger jumps</span>
<span class="sd">                    in function value will be accepted. For best results</span>
<span class="sd">                    `T` should be comparable to the separation (in function</span>
<span class="sd">                    value) between local minima.</span>
<span class="sd">                stepsize : float</span>
<span class="sd">                    Initial step size for use in the random displacement.</span>
<span class="sd">                interval : int</span>
<span class="sd">                    The interval for how often to update the `stepsize`.</span>
<span class="sd">                minimizer : dict</span>
<span class="sd">                    Extra keyword arguments to be passed to the minimizer</span>
<span class="sd">                    `scipy.optimize.minimize()`, for example 'method' - the</span>
<span class="sd">                    minimization method (e.g. 'L-BFGS-B'), or 'tol' - the</span>
<span class="sd">                    tolerance for termination. Other arguments are mapped from</span>
<span class="sd">                    explicit argument of `fit`:</span>
<span class="sd">                    - `args` &lt;- `fargs`</span>
<span class="sd">                    - `jac` &lt;- `score`</span>
<span class="sd">                    - `hess` &lt;- `hess`</span>
<span class="sd">            'minimize'</span>
<span class="sd">                min_method : str, optional</span>
<span class="sd">                    Name of minimization method to use.</span>
<span class="sd">                    Any method specific arguments can be passed directly.</span>
<span class="sd">                    For a list of methods and their arguments, see</span>
<span class="sd">                    documentation of `scipy.optimize.minimize`.</span>
<span class="sd">                    If no method is specified, then BFGS is used.</span>
<span class="sd">        """</span>
        <span class="c1">#TODO: generalize the regularization stuff</span>
        <span class="c1"># Extract kwargs specific to fit_regularized calling fit</span>
        <span class="n">extra_fit_funcs</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'extra_fit_funcs'</span><span class="p">,</span> <span class="nb">dict</span><span class="p">())</span>

        <span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'newton'</span><span class="p">,</span> <span class="s1">'nm'</span><span class="p">,</span> <span class="s1">'bfgs'</span><span class="p">,</span> <span class="s1">'lbfgs'</span><span class="p">,</span> <span class="s1">'powell'</span><span class="p">,</span> <span class="s1">'cg'</span><span class="p">,</span> <span class="s1">'ncg'</span><span class="p">,</span>
                <span class="s1">'basinhopping'</span><span class="p">,</span> <span class="s1">'minimize'</span><span class="p">]</span>
        <span class="n">methods</span> <span class="o">+=</span> <span class="n">extra_fit_funcs</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
        <span class="n">method</span> <span class="o">=</span> <span class="n">method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="n">_check_method</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">methods</span><span class="p">)</span>

        <span class="n">fit_funcs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">'newton'</span><span class="p">:</span> <span class="n">_fit_newton</span><span class="p">,</span>
            <span class="s1">'nm'</span><span class="p">:</span> <span class="n">_fit_nm</span><span class="p">,</span>  <span class="c1"># Nelder-Mead</span>
            <span class="s1">'bfgs'</span><span class="p">:</span> <span class="n">_fit_bfgs</span><span class="p">,</span>
            <span class="s1">'lbfgs'</span><span class="p">:</span> <span class="n">_fit_lbfgs</span><span class="p">,</span>
            <span class="s1">'cg'</span><span class="p">:</span> <span class="n">_fit_cg</span><span class="p">,</span>
            <span class="s1">'ncg'</span><span class="p">:</span> <span class="n">_fit_ncg</span><span class="p">,</span>
            <span class="s1">'powell'</span><span class="p">:</span> <span class="n">_fit_powell</span><span class="p">,</span>
            <span class="s1">'basinhopping'</span><span class="p">:</span> <span class="n">_fit_basinhopping</span><span class="p">,</span>
            <span class="s1">'minimize'</span><span class="p">:</span> <span class="n">_fit_minimize</span> <span class="c1"># wrapper for scipy.optimize.minimize</span>
        <span class="p">}</span>

        <span class="c1">#NOTE: fit_regularized checks the methods for these but it should be</span>
        <span class="c1">#      moved up probably</span>
        <span class="k">if</span> <span class="n">extra_fit_funcs</span><span class="p">:</span>
            <span class="n">fit_funcs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">extra_fit_funcs</span><span class="p">)</span>

        <span class="n">func</span> <span class="o">=</span> <span class="n">fit_funcs</span><span class="p">[</span><span class="n">method</span><span class="p">]</span>
        <span class="n">xopt</span><span class="p">,</span> <span class="n">retvals</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">gradient</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">fargs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span>
                            <span class="n">disp</span><span class="o">=</span><span class="n">disp</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">,</span>
                            <span class="n">retall</span><span class="o">=</span><span class="n">retall</span><span class="p">,</span> <span class="n">full_output</span><span class="o">=</span><span class="n">full_output</span><span class="p">,</span>
                            <span class="n">hess</span><span class="o">=</span><span class="n">hessian</span><span class="p">)</span>

        <span class="n">optim_settings</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'optimizer'</span><span class="p">:</span> <span class="n">method</span><span class="p">,</span> <span class="s1">'start_params'</span><span class="p">:</span> <span class="n">start_params</span><span class="p">,</span>
                        <span class="s1">'maxiter'</span><span class="p">:</span> <span class="n">maxiter</span><span class="p">,</span> <span class="s1">'full_output'</span><span class="p">:</span> <span class="n">full_output</span><span class="p">,</span>
                        <span class="s1">'disp'</span><span class="p">:</span> <span class="n">disp</span><span class="p">,</span> <span class="s1">'fargs'</span><span class="p">:</span> <span class="n">fargs</span><span class="p">,</span> <span class="s1">'callback'</span><span class="p">:</span> <span class="n">callback</span><span class="p">,</span>
                        <span class="s1">'retall'</span><span class="p">:</span> <span class="n">retall</span><span class="p">}</span>
        <span class="n">optim_settings</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># set as attributes or return?</span>
        <span class="k">return</span> <span class="n">xopt</span><span class="p">,</span> <span class="n">retvals</span><span class="p">,</span> <span class="n">optim_settings</span>

    <span class="k">def</span> <span class="nf">_fit_constrained</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="sd">"""</span>
<span class="sd">        TODO: how to add constraints?</span>

<span class="sd">        Something like</span>
<span class="sd">        sm.add_constraint(Model, func)</span>

<span class="sd">        or</span>

<span class="sd">        model_instance.add_constraint(func)</span>
<span class="sd">        model_instance.add_constraint("x1 + x2 = 2")</span>
<span class="sd">        result = model_instance.fit()</span>
<span class="sd">        """</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">_fit_regularized</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="c1"># TODO: code will not necessarily be general here. 3 options.</span>
        <span class="c1"># 1) setup for scipy.optimize.fmin_sqlsqp</span>
        <span class="c1"># 2) setup for cvxopt</span>
        <span class="c1"># 3) setup for openopt</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>


<span class="c1">########################################</span>
<span class="c1"># Helper functions to fit</span>


<span class="k">def</span> <span class="nf">_fit_minimize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">fargs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                  <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retall</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                  <span class="n">full_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hess</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Fit using scipy minimize, where kwarg `min_method` defines the algorithm.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    f : function</span>
<span class="sd">        Returns negative log likelihood given parameters.</span>
<span class="sd">    score : function</span>
<span class="sd">        Returns gradient of negative log likelihood with respect to params.</span>
<span class="sd">    start_params : array_like, optional</span>
<span class="sd">        Initial guess of the solution for the loglikelihood maximization.</span>
<span class="sd">        The default is an array of zeros.</span>
<span class="sd">    fargs : tuple</span>
<span class="sd">        Extra arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,*args)</span>
<span class="sd">    kwargs : tuple</span>
<span class="sd">        Extra keyworded arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,**kwargs)</span>
<span class="sd">    disp : bool</span>
<span class="sd">        Set to True to print convergence messages.</span>
<span class="sd">    maxiter : int</span>
<span class="sd">        The maximum number of iterations to perform.</span>
<span class="sd">    callback : callable callback(xk)</span>
<span class="sd">        Called after each iteration, as callback(xk), where xk is the</span>
<span class="sd">        current parameter vector.</span>
<span class="sd">    retall : bool</span>
<span class="sd">        Set to True to return list of solutions at each iteration.</span>
<span class="sd">        Available in Results object's mle_retvals attribute.</span>
<span class="sd">    full_output : bool</span>
<span class="sd">        Set to True to have all available output in the Results object's</span>
<span class="sd">        mle_retvals attribute. The output is dependent on the solver.</span>
<span class="sd">        See LikelihoodModelResults notes section for more information.</span>
<span class="sd">    hess : str, optional</span>
<span class="sd">        Method for computing the Hessian matrix, if applicable.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    xopt : ndarray</span>
<span class="sd">        The solution to the objective function</span>
<span class="sd">    retvals : dict, None</span>
<span class="sd">        If `full_output` is True then this is a dictionary which holds</span>
<span class="sd">        information returned from the solver used. If it is False, this is</span>
<span class="sd">        None.</span>
<span class="sd">    """</span>
    <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'min_method'</span><span class="p">,</span> <span class="s1">'BFGS'</span><span class="p">)</span>

    <span class="c1"># prepare options dict for minimize</span>
    <span class="n">filter_opts</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'extra_fit_funcs'</span><span class="p">,</span> <span class="s1">'niter'</span><span class="p">,</span> <span class="s1">'min_method'</span><span class="p">,</span> <span class="s1">'tol'</span><span class="p">,</span> <span class="s1">'bounds'</span><span class="p">,</span> <span class="s1">'constraints'</span><span class="p">]</span>
    <span class="n">options</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">k</span><span class="p">,</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">filter_opts</span><span class="p">)</span>
    <span class="n">options</span><span class="p">[</span><span class="s1">'disp'</span><span class="p">]</span>    <span class="o">=</span> <span class="n">disp</span>
    <span class="n">options</span><span class="p">[</span><span class="s1">'maxiter'</span><span class="p">]</span> <span class="o">=</span> <span class="n">maxiter</span>

    <span class="c1"># Use Hessian/Jacobian only if they're required by the method</span>
    <span class="n">no_hess</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Nelder-Mead'</span><span class="p">,</span> <span class="s1">'Powell'</span><span class="p">,</span> <span class="s1">'CG'</span><span class="p">,</span> <span class="s1">'BFGS'</span><span class="p">,</span> <span class="s1">'COBYLA'</span><span class="p">,</span> <span class="s1">'SLSQP'</span><span class="p">]</span>
    <span class="n">no_jac</span>  <span class="o">=</span> <span class="p">[</span><span class="s1">'Nelder-Mead'</span><span class="p">,</span> <span class="s1">'Powell'</span><span class="p">,</span> <span class="s1">'COBYLA'</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">'min_method'</span><span class="p">]</span> <span class="ow">in</span> <span class="n">no_hess</span><span class="p">:</span>
        <span class="n">hess</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">'min_method'</span><span class="p">]</span> <span class="ow">in</span> <span class="n">no_jac</span><span class="p">:</span>
        <span class="n">score</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Use bounds/constraints only if they're allowed by the method</span>
    <span class="n">has_bounds</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'L-BFGS-B'</span><span class="p">,</span> <span class="s1">'TNC'</span><span class="p">,</span> <span class="s1">'SLSQP'</span><span class="p">,</span> <span class="s1">'trust-constr'</span><span class="p">]</span>
    <span class="n">has_constraints</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'COBYLA'</span><span class="p">,</span> <span class="s1">'SLSQP'</span> <span class="p">,</span> <span class="s1">'trust-constr'</span><span class="p">]</span>

    <span class="k">if</span> <span class="s1">'bounds'</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">'min_method'</span><span class="p">]</span> <span class="ow">in</span> <span class="n">has_bounds</span><span class="p">:</span>
        <span class="n">bounds</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">'bounds'</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">bounds</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="s1">'constraints'</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">'min_method'</span><span class="p">]</span> <span class="ow">in</span> <span class="n">has_constraints</span><span class="p">:</span>
        <span class="n">constraints</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">'constraints'</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">constraints</span> <span class="o">=</span> <span class="p">()</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">fargs</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">'min_method'</span><span class="p">],</span>
                            <span class="n">jac</span><span class="o">=</span><span class="n">score</span><span class="p">,</span> <span class="n">hess</span><span class="o">=</span><span class="n">hess</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span> <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
                            <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">)</span>

    <span class="n">xopt</span>    <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span>
    <span class="n">retvals</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">full_output</span><span class="p">:</span>
        <span class="n">nit</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="s1">'nit'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span> <span class="c1"># scipy 0.14 compat</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'fopt'</span><span class="p">:</span> <span class="n">res</span><span class="o">.</span><span class="n">fun</span><span class="p">,</span> <span class="s1">'iterations'</span><span class="p">:</span> <span class="n">nit</span><span class="p">,</span>
                   <span class="s1">'fcalls'</span><span class="p">:</span> <span class="n">res</span><span class="o">.</span><span class="n">nfev</span><span class="p">,</span> <span class="s1">'warnflag'</span><span class="p">:</span> <span class="n">res</span><span class="o">.</span><span class="n">status</span><span class="p">,</span>
                   <span class="s1">'converged'</span><span class="p">:</span> <span class="n">res</span><span class="o">.</span><span class="n">success</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">retall</span><span class="p">:</span>
            <span class="n">retvals</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">'allvecs'</span><span class="p">:</span> <span class="n">res</span><span class="o">.</span><span class="n">values</span><span class="p">()})</span>

    <span class="k">return</span> <span class="n">xopt</span><span class="p">,</span> <span class="n">retvals</span>


<div class="viewcode-block" id="_fit_newton"><a class="viewcode-back" href="../../../generated/statsmodels.base.optimizer._fit_newton.html#statsmodels.base.optimizer._fit_newton">[docs]</a><span class="k">def</span> <span class="nf">_fit_newton</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">fargs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retall</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">full_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hess</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ridge_factor</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Fit using Newton-Raphson algorithm.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    f : function</span>
<span class="sd">        Returns negative log likelihood given parameters.</span>
<span class="sd">    score : function</span>
<span class="sd">        Returns gradient of negative log likelihood with respect to params.</span>
<span class="sd">    start_params : array_like, optional</span>
<span class="sd">        Initial guess of the solution for the loglikelihood maximization.</span>
<span class="sd">        The default is an array of zeros.</span>
<span class="sd">    fargs : tuple</span>
<span class="sd">        Extra arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,*args)</span>
<span class="sd">    kwargs : tuple</span>
<span class="sd">        Extra keyworded arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,**kwargs)</span>
<span class="sd">    disp : bool</span>
<span class="sd">        Set to True to print convergence messages.</span>
<span class="sd">    maxiter : int</span>
<span class="sd">        The maximum number of iterations to perform.</span>
<span class="sd">    callback : callable callback(xk)</span>
<span class="sd">        Called after each iteration, as callback(xk), where xk is the</span>
<span class="sd">        current parameter vector.</span>
<span class="sd">    retall : bool</span>
<span class="sd">        Set to True to return list of solutions at each iteration.</span>
<span class="sd">        Available in Results object's mle_retvals attribute.</span>
<span class="sd">    full_output : bool</span>
<span class="sd">        Set to True to have all available output in the Results object's</span>
<span class="sd">        mle_retvals attribute. The output is dependent on the solver.</span>
<span class="sd">        See LikelihoodModelResults notes section for more information.</span>
<span class="sd">    hess : str, optional</span>
<span class="sd">        Method for computing the Hessian matrix, if applicable.</span>
<span class="sd">    ridge_factor : float</span>
<span class="sd">        Regularization factor for Hessian matrix.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    xopt : ndarray</span>
<span class="sd">        The solution to the objective function</span>
<span class="sd">    retvals : dict, None</span>
<span class="sd">        If `full_output` is True then this is a dictionary which holds</span>
<span class="sd">        information returned from the solver used. If it is False, this is</span>
<span class="sd">        None.</span>
<span class="sd">    """</span>
    <span class="n">tol</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'tol'</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">)</span>
    <span class="n">iterations</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">oldparams</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="n">newparams</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">start_params</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">retall</span><span class="p">:</span>
        <span class="n">history</span> <span class="o">=</span> <span class="p">[</span><span class="n">oldparams</span><span class="p">,</span> <span class="n">newparams</span><span class="p">]</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">iterations</span> <span class="o">&lt;</span> <span class="n">maxiter</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">newparams</span> <span class="o">-</span>
            <span class="n">oldparams</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">tol</span><span class="p">)):</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">hess</span><span class="p">(</span><span class="n">newparams</span><span class="p">))</span>
        <span class="c1"># regularize Hessian, not clear what ridge factor should be</span>
        <span class="c1"># keyword option with absolute default 1e-10, see #1847</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">ridge_factor</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">H</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">diag_indices</span><span class="p">(</span><span class="n">H</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">+=</span> <span class="n">ridge_factor</span>
        <span class="n">oldparams</span> <span class="o">=</span> <span class="n">newparams</span>
        <span class="n">newparams</span> <span class="o">=</span> <span class="n">oldparams</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">H</span><span class="p">),</span>
                <span class="n">score</span><span class="p">(</span><span class="n">oldparams</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">retall</span><span class="p">:</span>
            <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">newparams</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">callback</span><span class="p">(</span><span class="n">newparams</span><span class="p">)</span>
        <span class="n">iterations</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">fval</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">newparams</span><span class="p">,</span> <span class="o">*</span><span class="n">fargs</span><span class="p">)</span>  <span class="c1"># this is the negative likelihood</span>
    <span class="k">if</span> <span class="n">iterations</span> <span class="o">==</span> <span class="n">maxiter</span><span class="p">:</span>
        <span class="n">warnflag</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">disp</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Warning: Maximum number of iterations has been "</span>
                   <span class="s2">"exceeded."</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"         Current function value: </span><span class="si">%f</span><span class="s2">"</span> <span class="o">%</span> <span class="n">fval</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"         Iterations: </span><span class="si">%d</span><span class="s2">"</span> <span class="o">%</span> <span class="n">iterations</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">warnflag</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">disp</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Optimization terminated successfully."</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"         Current function value: </span><span class="si">%f</span><span class="s2">"</span> <span class="o">%</span> <span class="n">fval</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"         Iterations </span><span class="si">%d</span><span class="s2">"</span> <span class="o">%</span> <span class="n">iterations</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">full_output</span><span class="p">:</span>
        <span class="p">(</span><span class="n">xopt</span><span class="p">,</span> <span class="n">fopt</span><span class="p">,</span> <span class="n">niter</span><span class="p">,</span>
         <span class="n">gopt</span><span class="p">,</span> <span class="n">hopt</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">newparams</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">newparams</span><span class="p">,</span> <span class="o">*</span><span class="n">fargs</span><span class="p">),</span>
                        <span class="n">iterations</span><span class="p">,</span> <span class="n">score</span><span class="p">(</span><span class="n">newparams</span><span class="p">),</span>
                        <span class="n">hess</span><span class="p">(</span><span class="n">newparams</span><span class="p">))</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">warnflag</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'fopt'</span><span class="p">:</span> <span class="n">fopt</span><span class="p">,</span> <span class="s1">'iterations'</span><span class="p">:</span> <span class="n">niter</span><span class="p">,</span> <span class="s1">'score'</span><span class="p">:</span> <span class="n">gopt</span><span class="p">,</span>
                   <span class="s1">'Hessian'</span><span class="p">:</span> <span class="n">hopt</span><span class="p">,</span> <span class="s1">'warnflag'</span><span class="p">:</span> <span class="n">warnflag</span><span class="p">,</span>
                   <span class="s1">'converged'</span><span class="p">:</span> <span class="n">converged</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">retall</span><span class="p">:</span>
            <span class="n">retvals</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">'allvecs'</span><span class="p">:</span> <span class="n">history</span><span class="p">})</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">xopt</span> <span class="o">=</span> <span class="n">newparams</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="n">xopt</span><span class="p">,</span> <span class="n">retvals</span></div>


<div class="viewcode-block" id="_fit_bfgs"><a class="viewcode-back" href="../../../generated/statsmodels.base.optimizer._fit_bfgs.html#statsmodels.base.optimizer._fit_bfgs">[docs]</a><span class="k">def</span> <span class="nf">_fit_bfgs</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">fargs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
              <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retall</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
              <span class="n">full_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hess</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Fit using Broyden-Fletcher-Goldfarb-Shannon algorithm.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    f : function</span>
<span class="sd">        Returns negative log likelihood given parameters.</span>
<span class="sd">    score : function</span>
<span class="sd">        Returns gradient of negative log likelihood with respect to params.</span>
<span class="sd">    start_params : array_like, optional</span>
<span class="sd">        Initial guess of the solution for the loglikelihood maximization.</span>
<span class="sd">        The default is an array of zeros.</span>
<span class="sd">    fargs : tuple</span>
<span class="sd">        Extra arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,*args)</span>
<span class="sd">    kwargs : tuple</span>
<span class="sd">        Extra keyworded arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,**kwargs)</span>
<span class="sd">    disp : bool</span>
<span class="sd">        Set to True to print convergence messages.</span>
<span class="sd">    maxiter : int</span>
<span class="sd">        The maximum number of iterations to perform.</span>
<span class="sd">    callback : callable callback(xk)</span>
<span class="sd">        Called after each iteration, as callback(xk), where xk is the</span>
<span class="sd">        current parameter vector.</span>
<span class="sd">    retall : bool</span>
<span class="sd">        Set to True to return list of solutions at each iteration.</span>
<span class="sd">        Available in Results object's mle_retvals attribute.</span>
<span class="sd">    full_output : bool</span>
<span class="sd">        Set to True to have all available output in the Results object's</span>
<span class="sd">        mle_retvals attribute. The output is dependent on the solver.</span>
<span class="sd">        See LikelihoodModelResults notes section for more information.</span>
<span class="sd">    hess : str, optional</span>
<span class="sd">        Method for computing the Hessian matrix, if applicable.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    xopt : ndarray</span>
<span class="sd">        The solution to the objective function</span>
<span class="sd">    retvals : dict, None</span>
<span class="sd">        If `full_output` is True then this is a dictionary which holds</span>
<span class="sd">        information returned from the solver used. If it is False, this is</span>
<span class="sd">        None.</span>
<span class="sd">    """</span>
    <span class="n">gtol</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'gtol'</span><span class="p">,</span> <span class="mf">1.0000000000000001e-05</span><span class="p">)</span>
    <span class="n">norm</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'norm'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span><span class="p">)</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'epsilon'</span><span class="p">,</span> <span class="mf">1.4901161193847656e-08</span><span class="p">)</span>
    <span class="n">retvals</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">fmin_bfgs</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">fargs</span><span class="p">,</span>
                                 <span class="n">gtol</span><span class="o">=</span><span class="n">gtol</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="n">epsilon</span><span class="p">,</span>
                                 <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span> <span class="n">full_output</span><span class="o">=</span><span class="n">full_output</span><span class="p">,</span>
                                 <span class="n">disp</span><span class="o">=</span><span class="n">disp</span><span class="p">,</span> <span class="n">retall</span><span class="o">=</span><span class="n">retall</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">full_output</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">retall</span><span class="p">:</span>
            <span class="n">xopt</span><span class="p">,</span> <span class="n">fopt</span><span class="p">,</span> <span class="n">gopt</span><span class="p">,</span> <span class="n">Hinv</span><span class="p">,</span> <span class="n">fcalls</span><span class="p">,</span> <span class="n">gcalls</span><span class="p">,</span> <span class="n">warnflag</span> <span class="o">=</span> <span class="n">retvals</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="p">(</span><span class="n">xopt</span><span class="p">,</span> <span class="n">fopt</span><span class="p">,</span> <span class="n">gopt</span><span class="p">,</span> <span class="n">Hinv</span><span class="p">,</span> <span class="n">fcalls</span><span class="p">,</span>
             <span class="n">gcalls</span><span class="p">,</span> <span class="n">warnflag</span><span class="p">,</span> <span class="n">allvecs</span><span class="p">)</span> <span class="o">=</span> <span class="n">retvals</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">warnflag</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'fopt'</span><span class="p">:</span> <span class="n">fopt</span><span class="p">,</span> <span class="s1">'gopt'</span><span class="p">:</span> <span class="n">gopt</span><span class="p">,</span> <span class="s1">'Hinv'</span><span class="p">:</span> <span class="n">Hinv</span><span class="p">,</span>
                <span class="s1">'fcalls'</span><span class="p">:</span> <span class="n">fcalls</span><span class="p">,</span> <span class="s1">'gcalls'</span><span class="p">:</span> <span class="n">gcalls</span><span class="p">,</span> <span class="s1">'warnflag'</span><span class="p">:</span>
                <span class="n">warnflag</span><span class="p">,</span> <span class="s1">'converged'</span><span class="p">:</span> <span class="n">converged</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">retall</span><span class="p">:</span>
            <span class="n">retvals</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">'allvecs'</span><span class="p">:</span> <span class="n">allvecs</span><span class="p">})</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">xopt</span> <span class="o">=</span> <span class="n">retvals</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="n">xopt</span><span class="p">,</span> <span class="n">retvals</span></div>


<div class="viewcode-block" id="_fit_lbfgs"><a class="viewcode-back" href="../../../generated/statsmodels.base.optimizer._fit_lbfgs.html#statsmodels.base.optimizer._fit_lbfgs">[docs]</a><span class="k">def</span> <span class="nf">_fit_lbfgs</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">fargs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
               <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retall</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">full_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hess</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Fit using Limited-memory Broyden-Fletcher-Goldfarb-Shannon algorithm.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    f : function</span>
<span class="sd">        Returns negative log likelihood given parameters.</span>
<span class="sd">    score : function</span>
<span class="sd">        Returns gradient of negative log likelihood with respect to params.</span>
<span class="sd">    start_params : array_like, optional</span>
<span class="sd">        Initial guess of the solution for the loglikelihood maximization.</span>
<span class="sd">        The default is an array of zeros.</span>
<span class="sd">    fargs : tuple</span>
<span class="sd">        Extra arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,*args)</span>
<span class="sd">    kwargs : tuple</span>
<span class="sd">        Extra keyworded arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,**kwargs)</span>
<span class="sd">    disp : bool</span>
<span class="sd">        Set to True to print convergence messages.</span>
<span class="sd">    maxiter : int</span>
<span class="sd">        The maximum number of iterations to perform.</span>
<span class="sd">    callback : callable callback(xk)</span>
<span class="sd">        Called after each iteration, as callback(xk), where xk is the</span>
<span class="sd">        current parameter vector.</span>
<span class="sd">    retall : bool</span>
<span class="sd">        Set to True to return list of solutions at each iteration.</span>
<span class="sd">        Available in Results object's mle_retvals attribute.</span>
<span class="sd">    full_output : bool</span>
<span class="sd">        Set to True to have all available output in the Results object's</span>
<span class="sd">        mle_retvals attribute. The output is dependent on the solver.</span>
<span class="sd">        See LikelihoodModelResults notes section for more information.</span>
<span class="sd">    hess : str, optional</span>
<span class="sd">        Method for computing the Hessian matrix, if applicable.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    xopt : ndarray</span>
<span class="sd">        The solution to the objective function</span>
<span class="sd">    retvals : dict, None</span>
<span class="sd">        If `full_output` is True then this is a dictionary which holds</span>
<span class="sd">        information returned from the solver used. If it is False, this is</span>
<span class="sd">        None.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Within the mle part of statsmodels, the log likelihood function and</span>
<span class="sd">    its gradient with respect to the parameters do not have notationally</span>
<span class="sd">    consistent sign.</span>
<span class="sd">    """</span>

    <span class="c1"># Use unconstrained optimization by default.</span>
    <span class="n">bounds</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'bounds'</span><span class="p">,</span> <span class="p">[(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">start_params</span><span class="p">))</span>
    <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'iprint'</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Pass the following keyword argument names through to fmin_l_bfgs_b</span>
    <span class="c1"># if they are present in kwargs, otherwise use the fmin_l_bfgs_b</span>
    <span class="c1"># default values.</span>
    <span class="n">names</span> <span class="o">=</span> <span class="p">(</span><span class="s1">'m'</span><span class="p">,</span> <span class="s1">'pgtol'</span><span class="p">,</span> <span class="s1">'factr'</span><span class="p">,</span> <span class="s1">'maxfun'</span><span class="p">,</span> <span class="s1">'epsilon'</span><span class="p">,</span> <span class="s1">'approx_grad'</span><span class="p">)</span>
    <span class="n">extra_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">x</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">names</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># Extract values for the options related to the gradient.</span>
    <span class="n">approx_grad</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'approx_grad'</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">loglike_and_score</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'loglike_and_score'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'epsilon'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="c1"># The approx_grad flag has superpowers nullifying the score function arg.</span>
    <span class="k">if</span> <span class="n">approx_grad</span><span class="p">:</span>
        <span class="n">score</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Choose among three options for dealing with the gradient (the gradient</span>
    <span class="c1"># of a log likelihood function with respect to its parameters</span>
    <span class="c1"># is more specifically called the score in statistics terminology).</span>
    <span class="c1"># The first option is to use the finite-differences</span>
    <span class="c1"># approximation that is built into the fmin_l_bfgs_b optimizer.</span>
    <span class="c1"># The second option is to use the provided score function.</span>
    <span class="c1"># The third option is to use the score component of a provided</span>
    <span class="c1"># function that simultaneously evaluates the log likelihood and score.</span>
    <span class="k">if</span> <span class="n">epsilon</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">approx_grad</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'a finite-differences epsilon was provided '</span>
                         <span class="s1">'even though we are not using approx_grad'</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">approx_grad</span> <span class="ow">and</span> <span class="n">loglike_and_score</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'gradient approximation was requested '</span>
                         <span class="s1">'even though an analytic loglike_and_score function '</span>
                         <span class="s1">'was given'</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">loglike_and_score</span><span class="p">:</span>
        <span class="n">func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">p</span><span class="p">,</span> <span class="o">*</span><span class="n">a</span> <span class="p">:</span> <span class="nb">tuple</span><span class="p">(</span><span class="o">-</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">loglike_and_score</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="o">*</span><span class="n">a</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">score</span><span class="p">:</span>
        <span class="n">func</span> <span class="o">=</span> <span class="n">f</span>
        <span class="n">extra_kwargs</span><span class="p">[</span><span class="s1">'fprime'</span><span class="p">]</span> <span class="o">=</span> <span class="n">score</span>
    <span class="k">elif</span> <span class="n">approx_grad</span><span class="p">:</span>
        <span class="n">func</span> <span class="o">=</span> <span class="n">f</span>

    <span class="n">retvals</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">fmin_l_bfgs_b</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span>
                                     <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">fargs</span><span class="p">,</span>
                                     <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="n">disp</span><span class="p">,</span>
                                     <span class="o">**</span><span class="n">extra_kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">full_output</span><span class="p">:</span>
        <span class="n">xopt</span><span class="p">,</span> <span class="n">fopt</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">retvals</span>
        <span class="c1"># The warnflag is</span>
        <span class="c1"># 0 if converged</span>
        <span class="c1"># 1 if too many function evaluations or too many iterations</span>
        <span class="c1"># 2 if stopped for another reason, given in d['task']</span>
        <span class="n">warnflag</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s1">'warnflag'</span><span class="p">]</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="p">(</span><span class="n">warnflag</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">gopt</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s1">'grad'</span><span class="p">]</span>
        <span class="n">fcalls</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s1">'funcalls'</span><span class="p">]</span>
        <span class="n">iterations</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s1">'nit'</span><span class="p">]</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'fopt'</span><span class="p">:</span> <span class="n">fopt</span><span class="p">,</span> <span class="s1">'gopt'</span><span class="p">:</span> <span class="n">gopt</span><span class="p">,</span> <span class="s1">'fcalls'</span><span class="p">:</span> <span class="n">fcalls</span><span class="p">,</span>
                   <span class="s1">'warnflag'</span><span class="p">:</span> <span class="n">warnflag</span><span class="p">,</span> <span class="s1">'converged'</span><span class="p">:</span> <span class="n">converged</span><span class="p">,</span>
                   <span class="s1">'iterations'</span><span class="p">:</span> <span class="n">iterations</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">xopt</span> <span class="o">=</span> <span class="n">retvals</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="n">xopt</span><span class="p">,</span> <span class="n">retvals</span></div>


<div class="viewcode-block" id="_fit_nm"><a class="viewcode-back" href="../../../generated/statsmodels.base.optimizer._fit_nm.html#statsmodels.base.optimizer._fit_nm">[docs]</a><span class="k">def</span> <span class="nf">_fit_nm</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">fargs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retall</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">full_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hess</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Fit using Nelder-Mead algorithm.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    f : function</span>
<span class="sd">        Returns negative log likelihood given parameters.</span>
<span class="sd">    score : function</span>
<span class="sd">        Returns gradient of negative log likelihood with respect to params.</span>
<span class="sd">    start_params : array_like, optional</span>
<span class="sd">        Initial guess of the solution for the loglikelihood maximization.</span>
<span class="sd">        The default is an array of zeros.</span>
<span class="sd">    fargs : tuple</span>
<span class="sd">        Extra arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,*args)</span>
<span class="sd">    kwargs : tuple</span>
<span class="sd">        Extra keyworded arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,**kwargs)</span>
<span class="sd">    disp : bool</span>
<span class="sd">        Set to True to print convergence messages.</span>
<span class="sd">    maxiter : int</span>
<span class="sd">        The maximum number of iterations to perform.</span>
<span class="sd">    callback : callable callback(xk)</span>
<span class="sd">        Called after each iteration, as callback(xk), where xk is the</span>
<span class="sd">        current parameter vector.</span>
<span class="sd">    retall : bool</span>
<span class="sd">        Set to True to return list of solutions at each iteration.</span>
<span class="sd">        Available in Results object's mle_retvals attribute.</span>
<span class="sd">    full_output : bool</span>
<span class="sd">        Set to True to have all available output in the Results object's</span>
<span class="sd">        mle_retvals attribute. The output is dependent on the solver.</span>
<span class="sd">        See LikelihoodModelResults notes section for more information.</span>
<span class="sd">    hess : str, optional</span>
<span class="sd">        Method for computing the Hessian matrix, if applicable.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    xopt : ndarray</span>
<span class="sd">        The solution to the objective function</span>
<span class="sd">    retvals : dict, None</span>
<span class="sd">        If `full_output` is True then this is a dictionary which holds</span>
<span class="sd">        information returned from the solver used. If it is False, this is</span>
<span class="sd">        None.</span>
<span class="sd">    """</span>
    <span class="n">xtol</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'xtol'</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">ftol</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'ftol'</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">maxfun</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'maxfun'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">retvals</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">fmin</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">fargs</span><span class="p">,</span> <span class="n">xtol</span><span class="o">=</span><span class="n">xtol</span><span class="p">,</span>
                            <span class="n">ftol</span><span class="o">=</span><span class="n">ftol</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span> <span class="n">maxfun</span><span class="o">=</span><span class="n">maxfun</span><span class="p">,</span>
                            <span class="n">full_output</span><span class="o">=</span><span class="n">full_output</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="n">disp</span><span class="p">,</span> <span class="n">retall</span><span class="o">=</span><span class="n">retall</span><span class="p">,</span>
                            <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">full_output</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">retall</span><span class="p">:</span>
            <span class="n">xopt</span><span class="p">,</span> <span class="n">fopt</span><span class="p">,</span> <span class="n">niter</span><span class="p">,</span> <span class="n">fcalls</span><span class="p">,</span> <span class="n">warnflag</span> <span class="o">=</span> <span class="n">retvals</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">xopt</span><span class="p">,</span> <span class="n">fopt</span><span class="p">,</span> <span class="n">niter</span><span class="p">,</span> <span class="n">fcalls</span><span class="p">,</span> <span class="n">warnflag</span><span class="p">,</span> <span class="n">allvecs</span> <span class="o">=</span> <span class="n">retvals</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">warnflag</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'fopt'</span><span class="p">:</span> <span class="n">fopt</span><span class="p">,</span> <span class="s1">'iterations'</span><span class="p">:</span> <span class="n">niter</span><span class="p">,</span>
                   <span class="s1">'fcalls'</span><span class="p">:</span> <span class="n">fcalls</span><span class="p">,</span> <span class="s1">'warnflag'</span><span class="p">:</span> <span class="n">warnflag</span><span class="p">,</span>
                   <span class="s1">'converged'</span><span class="p">:</span> <span class="n">converged</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">retall</span><span class="p">:</span>
            <span class="n">retvals</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">'allvecs'</span><span class="p">:</span> <span class="n">allvecs</span><span class="p">})</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">xopt</span> <span class="o">=</span> <span class="n">retvals</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="n">xopt</span><span class="p">,</span> <span class="n">retvals</span></div>


<div class="viewcode-block" id="_fit_cg"><a class="viewcode-back" href="../../../generated/statsmodels.base.optimizer._fit_cg.html#statsmodels.base.optimizer._fit_cg">[docs]</a><span class="k">def</span> <span class="nf">_fit_cg</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">fargs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retall</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">full_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hess</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Fit using Conjugate Gradient algorithm.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    f : function</span>
<span class="sd">        Returns negative log likelihood given parameters.</span>
<span class="sd">    score : function</span>
<span class="sd">        Returns gradient of negative log likelihood with respect to params.</span>
<span class="sd">    start_params : array_like, optional</span>
<span class="sd">        Initial guess of the solution for the loglikelihood maximization.</span>
<span class="sd">        The default is an array of zeros.</span>
<span class="sd">    fargs : tuple</span>
<span class="sd">        Extra arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,*args)</span>
<span class="sd">    kwargs : tuple</span>
<span class="sd">        Extra keyworded arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,**kwargs)</span>
<span class="sd">    disp : bool</span>
<span class="sd">        Set to True to print convergence messages.</span>
<span class="sd">    maxiter : int</span>
<span class="sd">        The maximum number of iterations to perform.</span>
<span class="sd">    callback : callable callback(xk)</span>
<span class="sd">        Called after each iteration, as callback(xk), where xk is the</span>
<span class="sd">        current parameter vector.</span>
<span class="sd">    retall : bool</span>
<span class="sd">        Set to True to return list of solutions at each iteration.</span>
<span class="sd">        Available in Results object's mle_retvals attribute.</span>
<span class="sd">    full_output : bool</span>
<span class="sd">        Set to True to have all available output in the Results object's</span>
<span class="sd">        mle_retvals attribute. The output is dependent on the solver.</span>
<span class="sd">        See LikelihoodModelResults notes section for more information.</span>
<span class="sd">    hess : str, optional</span>
<span class="sd">        Method for computing the Hessian matrix, if applicable.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    xopt : ndarray</span>
<span class="sd">        The solution to the objective function</span>
<span class="sd">    retvals : dict, None</span>
<span class="sd">        If `full_output` is True then this is a dictionary which holds</span>
<span class="sd">        information returned from the solver used. If it is False, this is</span>
<span class="sd">        None.</span>
<span class="sd">    """</span>
    <span class="n">gtol</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'gtol'</span><span class="p">,</span> <span class="mf">1.0000000000000001e-05</span><span class="p">)</span>
    <span class="n">norm</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'norm'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span><span class="p">)</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'epsilon'</span><span class="p">,</span> <span class="mf">1.4901161193847656e-08</span><span class="p">)</span>
    <span class="n">retvals</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">fmin_cg</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">gtol</span><span class="o">=</span><span class="n">gtol</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span>
                               <span class="n">epsilon</span><span class="o">=</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span>
                               <span class="n">full_output</span><span class="o">=</span><span class="n">full_output</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="n">disp</span><span class="p">,</span>
                               <span class="n">retall</span><span class="o">=</span><span class="n">retall</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">full_output</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">retall</span><span class="p">:</span>
            <span class="n">xopt</span><span class="p">,</span> <span class="n">fopt</span><span class="p">,</span> <span class="n">fcalls</span><span class="p">,</span> <span class="n">gcalls</span><span class="p">,</span> <span class="n">warnflag</span> <span class="o">=</span> <span class="n">retvals</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">xopt</span><span class="p">,</span> <span class="n">fopt</span><span class="p">,</span> <span class="n">fcalls</span><span class="p">,</span> <span class="n">gcalls</span><span class="p">,</span> <span class="n">warnflag</span><span class="p">,</span> <span class="n">allvecs</span> <span class="o">=</span> <span class="n">retvals</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">warnflag</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'fopt'</span><span class="p">:</span> <span class="n">fopt</span><span class="p">,</span> <span class="s1">'fcalls'</span><span class="p">:</span> <span class="n">fcalls</span><span class="p">,</span> <span class="s1">'gcalls'</span><span class="p">:</span> <span class="n">gcalls</span><span class="p">,</span>
                   <span class="s1">'warnflag'</span><span class="p">:</span> <span class="n">warnflag</span><span class="p">,</span> <span class="s1">'converged'</span><span class="p">:</span> <span class="n">converged</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">retall</span><span class="p">:</span>
            <span class="n">retvals</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">'allvecs'</span><span class="p">:</span> <span class="n">allvecs</span><span class="p">})</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">xopt</span> <span class="o">=</span> <span class="n">retvals</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="n">xopt</span><span class="p">,</span> <span class="n">retvals</span></div>


<div class="viewcode-block" id="_fit_ncg"><a class="viewcode-back" href="../../../generated/statsmodels.base.optimizer._fit_ncg.html#statsmodels.base.optimizer._fit_ncg">[docs]</a><span class="k">def</span> <span class="nf">_fit_ncg</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">fargs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retall</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">full_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hess</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Fit using Newton Conjugate Gradient algorithm.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    f : function</span>
<span class="sd">        Returns negative log likelihood given parameters.</span>
<span class="sd">    score : function</span>
<span class="sd">        Returns gradient of negative log likelihood with respect to params.</span>
<span class="sd">    start_params : array_like, optional</span>
<span class="sd">        Initial guess of the solution for the loglikelihood maximization.</span>
<span class="sd">        The default is an array of zeros.</span>
<span class="sd">    fargs : tuple</span>
<span class="sd">        Extra arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,*args)</span>
<span class="sd">    kwargs : tuple</span>
<span class="sd">        Extra keyworded arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,**kwargs)</span>
<span class="sd">    disp : bool</span>
<span class="sd">        Set to True to print convergence messages.</span>
<span class="sd">    maxiter : int</span>
<span class="sd">        The maximum number of iterations to perform.</span>
<span class="sd">    callback : callable callback(xk)</span>
<span class="sd">        Called after each iteration, as callback(xk), where xk is the</span>
<span class="sd">        current parameter vector.</span>
<span class="sd">    retall : bool</span>
<span class="sd">        Set to True to return list of solutions at each iteration.</span>
<span class="sd">        Available in Results object's mle_retvals attribute.</span>
<span class="sd">    full_output : bool</span>
<span class="sd">        Set to True to have all available output in the Results object's</span>
<span class="sd">        mle_retvals attribute. The output is dependent on the solver.</span>
<span class="sd">        See LikelihoodModelResults notes section for more information.</span>
<span class="sd">    hess : str, optional</span>
<span class="sd">        Method for computing the Hessian matrix, if applicable.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    xopt : ndarray</span>
<span class="sd">        The solution to the objective function</span>
<span class="sd">    retvals : dict, None</span>
<span class="sd">        If `full_output` is True then this is a dictionary which holds</span>
<span class="sd">        information returned from the solver used. If it is False, this is</span>
<span class="sd">        None.</span>
<span class="sd">    """</span>
    <span class="n">fhess_p</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'fhess_p'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">avextol</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'avextol'</span><span class="p">,</span> <span class="mf">1.0000000000000001e-05</span><span class="p">)</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'epsilon'</span><span class="p">,</span> <span class="mf">1.4901161193847656e-08</span><span class="p">)</span>
    <span class="n">retvals</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">fmin_ncg</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">fhess_p</span><span class="o">=</span><span class="n">fhess_p</span><span class="p">,</span>
                                <span class="n">fhess</span><span class="o">=</span><span class="n">hess</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">fargs</span><span class="p">,</span> <span class="n">avextol</span><span class="o">=</span><span class="n">avextol</span><span class="p">,</span>
                                <span class="n">epsilon</span><span class="o">=</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span>
                                <span class="n">full_output</span><span class="o">=</span><span class="n">full_output</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="n">disp</span><span class="p">,</span>
                                <span class="n">retall</span><span class="o">=</span><span class="n">retall</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">full_output</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">retall</span><span class="p">:</span>
            <span class="n">xopt</span><span class="p">,</span> <span class="n">fopt</span><span class="p">,</span> <span class="n">fcalls</span><span class="p">,</span> <span class="n">gcalls</span><span class="p">,</span> <span class="n">hcalls</span><span class="p">,</span> <span class="n">warnflag</span> <span class="o">=</span> <span class="n">retvals</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">xopt</span><span class="p">,</span> <span class="n">fopt</span><span class="p">,</span> <span class="n">fcalls</span><span class="p">,</span> <span class="n">gcalls</span><span class="p">,</span> <span class="n">hcalls</span><span class="p">,</span> <span class="n">warnflag</span><span class="p">,</span> <span class="n">allvecs</span> <span class="o">=</span>\
                <span class="n">retvals</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">warnflag</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'fopt'</span><span class="p">:</span> <span class="n">fopt</span><span class="p">,</span> <span class="s1">'fcalls'</span><span class="p">:</span> <span class="n">fcalls</span><span class="p">,</span> <span class="s1">'gcalls'</span><span class="p">:</span> <span class="n">gcalls</span><span class="p">,</span>
                   <span class="s1">'hcalls'</span><span class="p">:</span> <span class="n">hcalls</span><span class="p">,</span> <span class="s1">'warnflag'</span><span class="p">:</span> <span class="n">warnflag</span><span class="p">,</span>
                   <span class="s1">'converged'</span><span class="p">:</span> <span class="n">converged</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">retall</span><span class="p">:</span>
            <span class="n">retvals</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">'allvecs'</span><span class="p">:</span> <span class="n">allvecs</span><span class="p">})</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">xopt</span> <span class="o">=</span> <span class="n">retvals</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="n">xopt</span><span class="p">,</span> <span class="n">retvals</span></div>


<div class="viewcode-block" id="_fit_powell"><a class="viewcode-back" href="../../../generated/statsmodels.base.optimizer._fit_powell.html#statsmodels.base.optimizer._fit_powell">[docs]</a><span class="k">def</span> <span class="nf">_fit_powell</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">fargs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retall</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">full_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hess</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Fit using Powell's conjugate direction algorithm.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    f : function</span>
<span class="sd">        Returns negative log likelihood given parameters.</span>
<span class="sd">    score : function</span>
<span class="sd">        Returns gradient of negative log likelihood with respect to params.</span>
<span class="sd">    start_params : array_like, optional</span>
<span class="sd">        Initial guess of the solution for the loglikelihood maximization.</span>
<span class="sd">        The default is an array of zeros.</span>
<span class="sd">    fargs : tuple</span>
<span class="sd">        Extra arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,*args)</span>
<span class="sd">    kwargs : tuple</span>
<span class="sd">        Extra keyworded arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,**kwargs)</span>
<span class="sd">    disp : bool</span>
<span class="sd">        Set to True to print convergence messages.</span>
<span class="sd">    maxiter : int</span>
<span class="sd">        The maximum number of iterations to perform.</span>
<span class="sd">    callback : callable callback(xk)</span>
<span class="sd">        Called after each iteration, as callback(xk), where xk is the</span>
<span class="sd">        current parameter vector.</span>
<span class="sd">    retall : bool</span>
<span class="sd">        Set to True to return list of solutions at each iteration.</span>
<span class="sd">        Available in Results object's mle_retvals attribute.</span>
<span class="sd">    full_output : bool</span>
<span class="sd">        Set to True to have all available output in the Results object's</span>
<span class="sd">        mle_retvals attribute. The output is dependent on the solver.</span>
<span class="sd">        See LikelihoodModelResults notes section for more information.</span>
<span class="sd">    hess : str, optional</span>
<span class="sd">        Method for computing the Hessian matrix, if applicable.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    xopt : ndarray</span>
<span class="sd">        The solution to the objective function</span>
<span class="sd">    retvals : dict, None</span>
<span class="sd">        If `full_output` is True then this is a dictionary which holds</span>
<span class="sd">        information returned from the solver used. If it is False, this is</span>
<span class="sd">        None.</span>
<span class="sd">    """</span>
    <span class="n">xtol</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'xtol'</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">ftol</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'ftol'</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">maxfun</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'maxfun'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">start_direc</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'start_direc'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">retvals</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">fmin_powell</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">fargs</span><span class="p">,</span> <span class="n">xtol</span><span class="o">=</span><span class="n">xtol</span><span class="p">,</span>
                                   <span class="n">ftol</span><span class="o">=</span><span class="n">ftol</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span> <span class="n">maxfun</span><span class="o">=</span><span class="n">maxfun</span><span class="p">,</span>
                                   <span class="n">full_output</span><span class="o">=</span><span class="n">full_output</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="n">disp</span><span class="p">,</span>
                                   <span class="n">retall</span><span class="o">=</span><span class="n">retall</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">,</span>
                                   <span class="n">direc</span><span class="o">=</span><span class="n">start_direc</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">full_output</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">retall</span><span class="p">:</span>
            <span class="n">xopt</span><span class="p">,</span> <span class="n">fopt</span><span class="p">,</span> <span class="n">direc</span><span class="p">,</span> <span class="n">niter</span><span class="p">,</span> <span class="n">fcalls</span><span class="p">,</span> <span class="n">warnflag</span> <span class="o">=</span> <span class="n">retvals</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">xopt</span><span class="p">,</span> <span class="n">fopt</span><span class="p">,</span> <span class="n">direc</span><span class="p">,</span> <span class="n">niter</span><span class="p">,</span> <span class="n">fcalls</span><span class="p">,</span> <span class="n">warnflag</span><span class="p">,</span> <span class="n">allvecs</span> <span class="o">=</span>\
                <span class="n">retvals</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">warnflag</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'fopt'</span><span class="p">:</span> <span class="n">fopt</span><span class="p">,</span> <span class="s1">'direc'</span><span class="p">:</span> <span class="n">direc</span><span class="p">,</span> <span class="s1">'iterations'</span><span class="p">:</span> <span class="n">niter</span><span class="p">,</span>
                   <span class="s1">'fcalls'</span><span class="p">:</span> <span class="n">fcalls</span><span class="p">,</span> <span class="s1">'warnflag'</span><span class="p">:</span> <span class="n">warnflag</span><span class="p">,</span>
                   <span class="s1">'converged'</span><span class="p">:</span> <span class="n">converged</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">retall</span><span class="p">:</span>
            <span class="n">retvals</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">'allvecs'</span><span class="p">:</span> <span class="n">allvecs</span><span class="p">})</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">xopt</span> <span class="o">=</span> <span class="n">retvals</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="n">xopt</span><span class="p">,</span> <span class="n">retvals</span></div>


<div class="viewcode-block" id="_fit_basinhopping"><a class="viewcode-back" href="../../../generated/statsmodels.base.optimizer._fit_basinhopping.html#statsmodels.base.optimizer._fit_basinhopping">[docs]</a><span class="k">def</span> <span class="nf">_fit_basinhopping</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span> <span class="n">fargs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                      <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retall</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                      <span class="n">full_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hess</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Fit using Basin-hopping algorithm.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    f : function</span>
<span class="sd">        Returns negative log likelihood given parameters.</span>
<span class="sd">    score : function</span>
<span class="sd">        Returns gradient of negative log likelihood with respect to params.</span>
<span class="sd">    start_params : array_like, optional</span>
<span class="sd">        Initial guess of the solution for the loglikelihood maximization.</span>
<span class="sd">        The default is an array of zeros.</span>
<span class="sd">    fargs : tuple</span>
<span class="sd">        Extra arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,*args)</span>
<span class="sd">    kwargs : tuple</span>
<span class="sd">        Extra keyworded arguments passed to the objective function, i.e.</span>
<span class="sd">        objective(x,**kwargs)</span>
<span class="sd">    disp : bool</span>
<span class="sd">        Set to True to print convergence messages.</span>
<span class="sd">    maxiter : int</span>
<span class="sd">        The maximum number of iterations to perform.</span>
<span class="sd">    callback : callable callback(xk)</span>
<span class="sd">        Called after each iteration, as callback(xk), where xk is the</span>
<span class="sd">        current parameter vector.</span>
<span class="sd">    retall : bool</span>
<span class="sd">        Set to True to return list of solutions at each iteration.</span>
<span class="sd">        Available in Results object's mle_retvals attribute.</span>
<span class="sd">    full_output : bool</span>
<span class="sd">        Set to True to have all available output in the Results object's</span>
<span class="sd">        mle_retvals attribute. The output is dependent on the solver.</span>
<span class="sd">        See LikelihoodModelResults notes section for more information.</span>
<span class="sd">    hess : str, optional</span>
<span class="sd">        Method for computing the Hessian matrix, if applicable.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    xopt : ndarray</span>
<span class="sd">        The solution to the objective function</span>
<span class="sd">    retvals : dict, None</span>
<span class="sd">        If `full_output` is True then this is a dictionary which holds</span>
<span class="sd">        information returned from the solver used. If it is False, this is</span>
<span class="sd">        None.</span>
<span class="sd">    """</span>
    <span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">copy</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">niter</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'niter'</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">niter_success</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'niter_success'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'T'</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">stepsize</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'stepsize'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">interval</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">'interval'</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
    <span class="n">minimizer_kwargs</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'minimizer'</span><span class="p">,</span> <span class="p">{})</span>
    <span class="n">minimizer_kwargs</span><span class="p">[</span><span class="s1">'args'</span><span class="p">]</span> <span class="o">=</span> <span class="n">fargs</span>
    <span class="n">minimizer_kwargs</span><span class="p">[</span><span class="s1">'jac'</span><span class="p">]</span> <span class="o">=</span> <span class="n">score</span>
    <span class="n">method</span> <span class="o">=</span> <span class="n">minimizer_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'method'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">method</span> <span class="ow">and</span> <span class="n">method</span> <span class="o">!=</span> <span class="s1">'L-BFGS-B'</span><span class="p">:</span> <span class="c1"># l_bfgs_b does not take a hessian</span>
        <span class="n">minimizer_kwargs</span><span class="p">[</span><span class="s1">'hess'</span><span class="p">]</span> <span class="o">=</span> <span class="n">hess</span>

    <span class="n">retvals</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">basinhopping</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">start_params</span><span class="p">,</span>
                                    <span class="n">minimizer_kwargs</span><span class="o">=</span><span class="n">minimizer_kwargs</span><span class="p">,</span>
                                    <span class="n">niter</span><span class="o">=</span><span class="n">niter</span><span class="p">,</span> <span class="n">niter_success</span><span class="o">=</span><span class="n">niter_success</span><span class="p">,</span>
                                    <span class="n">T</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">stepsize</span><span class="o">=</span><span class="n">stepsize</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="n">disp</span><span class="p">,</span>
                                    <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="n">interval</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">full_output</span><span class="p">:</span>
        <span class="n">xopt</span><span class="p">,</span> <span class="n">fopt</span><span class="p">,</span> <span class="n">niter</span><span class="p">,</span> <span class="n">fcalls</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">retvals</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span>
                                        <span class="p">[</span><span class="s1">'x'</span><span class="p">,</span> <span class="s1">'fun'</span><span class="p">,</span> <span class="s1">'nit'</span><span class="p">,</span> <span class="s1">'nfev'</span><span class="p">])</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="s1">'completed successfully'</span> <span class="ow">in</span> <span class="n">retvals</span><span class="o">.</span><span class="n">message</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'fopt'</span><span class="p">:</span> <span class="n">fopt</span><span class="p">,</span> <span class="s1">'iterations'</span><span class="p">:</span> <span class="n">niter</span><span class="p">,</span>
                   <span class="s1">'fcalls'</span><span class="p">:</span> <span class="n">fcalls</span><span class="p">,</span> <span class="s1">'converged'</span><span class="p">:</span> <span class="n">converged</span><span class="p">}</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">xopt</span> <span class="o">=</span> <span class="n">retvals</span><span class="o">.</span><span class="n">x</span>
        <span class="n">retvals</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="n">xopt</span><span class="p">,</span> <span class="n">retvals</span></div>
</pre></div>

          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2009-2019, Josef Perktold, Skipper Seabold, Jonathan Taylor, statsmodels-developers.
              
          </div>
            Last updated on
              Feb 02, 2021.
            <br/>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 3.4.3.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../../../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>