

<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../../../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../../../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../../../_static/javascripts/modernizr.js"></script>
  
  
  
    <title>Fast Bayesian estimation of SARIMAX models &#8212; statsmodels</title>
  <link rel="icon" type="image/png" sizes="32x32" href="../../../_static/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="../../../_static/icons/favicon-16x16.png">
  <link rel="manifest" href="../../../_static/icons/site.webmanifest">
  <link rel="mask-icon" href="../../../_static/icons/safari-pinned-tab.svg" color="#919191">
  <meta name="msapplication-TileColor" content="#2b5797">
  <meta name="msapplication-config" content="../../../_static/icons/browserconfig.xml">
  <link rel="stylesheet" href="../../../_static/stylesheets/examples.css">
  <link rel="stylesheet" href="../../../_static/stylesheets/deprecation.css">
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/material.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../../about.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Forecasting, updating datasets, and the “news”" href="statespace_news.html" />
    <link rel="prev" title="TVP-VAR, MCMC, and sparse simulation smoothing" href="statespace_tvpvar_mcmc_cfa.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=indigo data-md-color-accent=blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#examples/notebooks/generated/statespace_sarimax_pymc3" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../../index.html" title="statsmodels"
           class="md-header-nav__button md-logo">
          
              <img src="../../../_static/statsmodels-logo-v2-bw.svg" height="26"
                   alt="statsmodels logo">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">statsmodels v0.12.2</span>
          <span class="md-header-nav__topic"> Fast Bayesian estimation of SARIMAX models </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../../../search.html" method="GET" name="search">
      <input type="text" class="md-search__input" name="q" placeholder="Search"
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/statsmodels/statsmodels" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    statsmodels
  </div>
</a>
          </div>
        </div>
      
      
  
  <script src="../../../_static/javascripts/version_dropdown.js"></script>
  <script>
    var json_loc = "../../../_static/versions.json",
        target_loc = "../../../../",
        text = "Versions";
    $( document ).ready( add_version_dropdown(json_loc, target_loc, text));
  </script>
  

    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
          <li class="md-tabs__item"><a href="../../index.html" class="md-tabs__link">Examples</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../../index.html" title="statsmodels" class="md-nav__button md-logo">
      
        <img src="../../../_static/statsmodels-logo-v2-bw.svg" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../../../index.html"
       title="statsmodels">statsmodels v0.12.2</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/statsmodels/statsmodels" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    statsmodels
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
    
      <a href="../../../install.html" class="md-nav__link">Installing statsmodels</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../gettingstarted.html" class="md-nav__link">Getting started</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../user-guide.html" class="md-nav__link">User Guide</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../index.html" class="md-nav__link">Examples</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="../../index.html#linear-regression-models" class="md-nav__link">Linear Regression Models</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../index.html#plotting" class="md-nav__link">Plotting</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../index.html#discrete-choice-models" class="md-nav__link">Discrete Choice Models</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../index.html#nonparametric-statistics" class="md-nav__link">Nonparametric Statistics</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../index.html#generalized-linear-models" class="md-nav__link">Generalized Linear Models</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../index.html#robust-regression" class="md-nav__link">Robust Regression</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../index.html#generalized-estimating-equations" class="md-nav__link">Generalized Estimating Equations</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../index.html#statistics" class="md-nav__link">Statistics</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../index.html#time-series-analysis" class="md-nav__link">Time Series Analysis</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../index.html#state-space-models" class="md-nav__link">State space models</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="statespace_sarimax_stata.html" class="md-nav__link">SARIMAX: Introduction</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="statespace_sarimax_internet.html" class="md-nav__link">SARIMAX: Model selection, missing data</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="statespace_varmax.html" class="md-nav__link">VARMAX models</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="statespace_dfm_coincident.html" class="md-nav__link">Dynamic factors and coincident indices</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="statespace_structural_harvey_jaeger.html" class="md-nav__link">Detrending, Stylized Facts and the Business Cycle</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="statespace_cycles.html" class="md-nav__link">Trends and cycles in unemployment</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="statespace_local_linear_trend.html" class="md-nav__link">State space modeling: Local Linear Trends</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="statespace_arma_0.html" class="md-nav__link">Autoregressive Moving Average (ARMA): Sunspots data</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="statespace_seasonal.html" class="md-nav__link">Seasonality in time series data</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="statespace_fixed_params.html" class="md-nav__link">Estimating or specifying parameters in state space models</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="statespace_tvpvar_mcmc_cfa.html" class="md-nav__link">TVP-VAR, MCMC, and sparse simulation smoothing</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    <label class="md-nav__link md-nav__link--active" for="__toc"> Fast Bayesian estimation of SARIMAX models </label>
    
      <a href="#" class="md-nav__link md-nav__link--active">Fast Bayesian estimation of SARIMAX models</a>
      
        
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">Contents</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#examples-notebooks-generated-statespace-sarimax-pymc3--page-root" class="md-nav__link">Fast Bayesian estimation of SARIMAX models</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Introduction" class="md-nav__link">Introduction</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#1.-Import-external-dependencies" class="md-nav__link">1. Import external dependencies</a>
        </li>
        <li class="md-nav__item"><a href="#2.-Download-and-plot-the-data-on-US-CPI" class="md-nav__link">2. Download and plot the data on US CPI</a>
        </li>
        <li class="md-nav__item"><a href="#3.-Fit-the-model-with-maximum-likelihood" class="md-nav__link">3. Fit the model with maximum likelihood</a>
        </li>
        <li class="md-nav__item"><a href="#4.-Helper-functions-to-provide-tensors-to-the-library-doing-Bayesian-estimation" class="md-nav__link">4. Helper functions to provide tensors to the library doing Bayesian estimation</a>
        </li>
        <li class="md-nav__item"><a href="#Technical-Details" class="md-nav__link">Technical Details</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Defining-helper-functions-to-translate-models-into-a-PyMC3-friendly-form" class="md-nav__link">Defining helper functions to translate models into a PyMC3 friendly form</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#5.-Bayesian-estimation-with-NUTS" class="md-nav__link">5. Bayesian estimation with NUTS</a>
        </li>
        <li class="md-nav__item"><a href="#6.-Application-of-Bayesian-estimates-of-parameters" class="md-nav__link">6. Application of Bayesian estimates of parameters</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Appendix-A.-Application-to-UnobservedComponents-models" class="md-nav__link">Appendix A. Application to <code class="docutils literal notranslate"><span class="pre">UnobservedComponents</span></code> models</a>
        </li></ul>
            </nav>
        </li>
    
<li class="md-nav__item"><a class="md-nav__extra_link" href="../../../_sources/examples/notebooks/generated/statespace_sarimax_pymc3.ipynb.txt">Show Source</a> </li>

  </ul>
</nav>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="statespace_news.html" class="md-nav__link">Forecasting, updating datasets, and the “news”</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="statespace_custom_models.html" class="md-nav__link">Custom statespace models</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="ets.html" class="md-nav__link">ETS models</a>
      
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../index.html#state-space-models-technical-notes" class="md-nav__link">State space models - Technical notes</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../index.html#forecasting" class="md-nav__link">Forecasting</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../index.html#multivariate-methods" class="md-nav__link">Multivariate Methods</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../index.html#user-notes" class="md-nav__link">User Notes</a>
      
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../api.html" class="md-nav__link">API Reference</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../about.html" class="md-nav__link">About statsmodels</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../dev/index.html" class="md-nav__link">Developer Page</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../release/index.html" class="md-nav__link">Release Notes</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">Contents</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#examples-notebooks-generated-statespace-sarimax-pymc3--page-root" class="md-nav__link">Fast Bayesian estimation of SARIMAX models</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Introduction" class="md-nav__link">Introduction</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#1.-Import-external-dependencies" class="md-nav__link">1. Import external dependencies</a>
        </li>
        <li class="md-nav__item"><a href="#2.-Download-and-plot-the-data-on-US-CPI" class="md-nav__link">2. Download and plot the data on US CPI</a>
        </li>
        <li class="md-nav__item"><a href="#3.-Fit-the-model-with-maximum-likelihood" class="md-nav__link">3. Fit the model with maximum likelihood</a>
        </li>
        <li class="md-nav__item"><a href="#4.-Helper-functions-to-provide-tensors-to-the-library-doing-Bayesian-estimation" class="md-nav__link">4. Helper functions to provide tensors to the library doing Bayesian estimation</a>
        </li>
        <li class="md-nav__item"><a href="#Technical-Details" class="md-nav__link">Technical Details</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Defining-helper-functions-to-translate-models-into-a-PyMC3-friendly-form" class="md-nav__link">Defining helper functions to translate models into a PyMC3 friendly form</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#5.-Bayesian-estimation-with-NUTS" class="md-nav__link">5. Bayesian estimation with NUTS</a>
        </li>
        <li class="md-nav__item"><a href="#6.-Application-of-Bayesian-estimates-of-parameters" class="md-nav__link">6. Application of Bayesian estimates of parameters</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Appendix-A.-Application-to-UnobservedComponents-models" class="md-nav__link">Appendix A. Application to <code class="docutils literal notranslate"><span class="pre">UnobservedComponents</span></code> models</a>
        </li></ul>
            </nav>
        </li>
    
<li class="md-nav__item"><a class="md-nav__extra_link" href="../../../_sources/examples/notebooks/generated/statespace_sarimax_pymc3.ipynb.txt">Show Source</a> </li>

<li id="searchbox" class="md-nav__item"></li>

  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>

<h1 id="examples-notebooks-generated-statespace-sarimax-pymc3--page-root">Fast Bayesian estimation of SARIMAX models<a class="headerlink" href="#examples-notebooks-generated-statespace-sarimax-pymc3--page-root" title="Permalink to this headline">¶</a></h1>

<h2 id="Introduction">Introduction<a class="headerlink" href="#Introduction" title="Permalink to this headline">¶</a></h2>
<p>This notebook will show how to use fast Bayesian methods to estimate SARIMAX (Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors) models. These methods can also be parallelized across multiple cores.</p>
<p>Here, fast methods means a version of Hamiltonian Monte Carlo called the No-U-Turn Sampler (NUTS) developed by Hoffmann and Gelman: see <a class="reference external" href="https://arxiv.org/abs/1111.4246">Hoffman, M. D., &amp; Gelman, A. (2014). The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1), 1593-1623.</a>. As they say, “the cost of HMC per independent sample from a target distribution of dimension <span class="math notranslate nohighlight">\(D\)</span> is roughly <span class="math notranslate nohighlight">\(\mathcal{O}(D^{5/4})\)</span>, which
stands in sharp contrast with the <span class="math notranslate nohighlight">\(\mathcal{O}(D^{2})\)</span> cost of random-walk Metropolis”. So for problems of larger dimension, the time-saving with HMC is significant. However it does require the gradient, or Jacobian, of the model to be provided.</p>
<p>This notebook will combine the Python libraries <a class="reference external" href="https://www.statsmodels.org/stable/index.html">statsmodels</a>, which does econometrics, and <a class="reference external" href="https://docs.pymc.io/">PyMC3</a>, which is for Bayesian estimation, to perform fast Bayesian estimation of a simple SARIMAX model, in this case an ARMA(1, 1) model for US CPI.</p>
<p>Note that, for simple models like AR(p), base PyMC3 is a quicker way to fit a model; there’s an <a class="reference external" href="https://docs.pymc.io/notebooks/AR.html">example here</a>. The advantage of using statsmodels is that it gives access to methods that can solve a vast range of statespace models.</p>
<p>The model we’ll solve is given by</p>
<div class="math notranslate nohighlight">
\[y_t = \phi y_{t-1} + \varepsilon_t + \theta_1 \varepsilon_{t-1}, \qquad \varepsilon_t \sim N(0, \sigma^2)\]</div>
<p>with 1 auto-regressive term and 1 moving average term. In statespace form it is written as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
y_t &amp; = \underbrace{\begin{bmatrix} 1 &amp; \theta_1 \end{bmatrix}}_{Z} \underbrace{\begin{bmatrix} \alpha_{1,t} \\ \alpha_{2,t} \end{bmatrix}}_{\alpha_t} \\
    \begin{bmatrix} \alpha_{1,t+1} \\ \alpha_{2,t+1} \end{bmatrix} &amp; = \underbrace{\begin{bmatrix}
        \phi &amp; 0 \\
        1      &amp; 0     \\
    \end{bmatrix}}_{T} \begin{bmatrix} \alpha_{1,t} \\ \alpha_{2,t} \end{bmatrix} +
    \underbrace{\begin{bmatrix} 1 \\ 0 \end{bmatrix}}_{R} \underbrace{\varepsilon_{t+1}}_{\eta_t} \\
\end{align}\end{split}\]</div>
<p>The code will follow these steps: 1. Import external dependencies 2. Download and plot the data on US CPI 3. Simple maximum likelihood estimation (MLE) as an example 4. Definitions of helper functions to provide tensors to the library doing Bayesian estimation 5. Bayesian estimation via NUTS 6. Application to US CPI series</p>
<p>Finally, Appendix A shows how to re-use the helper functions from step (4) to estimate a different state space model, <code class="docutils literal notranslate"><span class="pre">UnobservedComponents</span></code>, using the same Bayesian methods.</p>

<h3 id="1.-Import-external-dependencies">1. Import external dependencies<a class="headerlink" href="#1.-Import-external-dependencies" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">theano</span>
<span class="kn">import</span> <span class="nn">theano.tensor</span> <span class="k">as</span> <span class="nn">tt</span>
<span class="kn">import</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">pandas_datareader.data</span> <span class="kn">import</span> <span class="n">DataReader</span>
<span class="kn">from</span> <span class="nn">pandas.plotting</span> <span class="kn">import</span> <span class="n">register_matplotlib_converters</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">'seaborn'</span><span class="p">)</span>
<span class="n">register_matplotlib_converters</span><span class="p">()</span>
</pre></div>
</div>
</div>


<h3 id="2.-Download-and-plot-the-data-on-US-CPI">2. Download and plot the data on US CPI<a class="headerlink" href="#2.-Download-and-plot-the-data-on-US-CPI" title="Permalink to this headline">¶</a></h3>
<p>We’ll get the data from FRED:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">cpi</span> <span class="o">=</span> <span class="n">DataReader</span><span class="p">(</span><span class="s1">'CPIAUCNS'</span><span class="p">,</span> <span class="s1">'fred'</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="s1">'1971-01'</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">'2018-12'</span><span class="p">)</span>
<span class="n">cpi</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DatetimeIndex</span><span class="p">(</span><span class="n">cpi</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">'MS'</span><span class="p">)</span>

<span class="c1"># Define the inflation series that we'll use in analysis</span>
<span class="n">inf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">cpi</span><span class="p">)</span><span class="o">.</span><span class="n">resample</span><span class="p">(</span><span class="s1">'QS'</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">diff</span><span class="p">()[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">*</span> <span class="mi">400</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inf</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
            CPIAUCNS
DATE
1971-04-01  4.316424
1971-07-01  4.279518
1971-10-01  1.956799
1972-01-01  2.917767
1972-04-01  3.219096
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Plot the series</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">inf</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">inf</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">'$\Delta \log CPI$'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower left'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../_images/examples_notebooks_generated_statespace_sarimax_pymc3_6_0.png" src="../../../_images/examples_notebooks_generated_statespace_sarimax_pymc3_6_0.png"/>
</div>
</div>


<h3 id="3.-Fit-the-model-with-maximum-likelihood">3. Fit the model with maximum likelihood<a class="headerlink" href="#3.-Fit-the-model-with-maximum-likelihood" title="Permalink to this headline">¶</a></h3>
<p>Statsmodels does all of the hard work of this for us - creating and fitting the model takes just two lines of code. The model order parameters correspond to auto-regressive, difference, and moving average orders respectively.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Create an SARIMAX model instance - here we use it to estimate</span>
<span class="c1"># the parameters via MLE using the `fit` method, but we can</span>
<span class="c1"># also re-use it below for the Bayesian estimation</span>
<span class="n">mod</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">tsa</span><span class="o">.</span><span class="n">statespace</span><span class="o">.</span><span class="n">SARIMAX</span><span class="p">(</span><span class="n">inf</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">res_mle</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">disp</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res_mle</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
                               SARIMAX Results
==============================================================================
Dep. Variable:               CPIAUCNS   No. Observations:                  191
Model:               SARIMAX(1, 0, 1)   Log Likelihood                -448.685
Date:                Tue, 02 Feb 2021   AIC                            903.370
Time:                        06:55:38   BIC                            913.127
Sample:                    04-01-1971   HQIC                           907.322
                         - 10-01-2018
Covariance Type:                  opg
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
ar.L1          0.9785      0.015     64.545      0.000       0.949       1.008
ma.L1         -0.6342      0.057    -11.073      0.000      -0.747      -0.522
sigma2         6.3682      0.323     19.695      0.000       5.734       7.002
===================================================================================
Ljung-Box (L1) (Q):                   4.77   Jarque-Bera (JB):               699.70
Prob(Q):                              0.03   Prob(JB):                         0.00
Heteroskedasticity (H):               1.72   Skew:                            -1.48
Prob(H) (two-sided):                  0.03   Kurtosis:                        11.90
===================================================================================

Warnings:
[1] Covariance matrix calculated using the outer product of gradients (complex-step).
</pre></div></div>
</div>
<p>It’s a good fit. We can also get the series of one-step ahead predictions and plot it next to the actual data, along with a confidence band.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">predict_mle</span> <span class="o">=</span> <span class="n">res_mle</span><span class="o">.</span><span class="n">get_prediction</span><span class="p">()</span>
<span class="n">predict_mle_ci</span> <span class="o">=</span> <span class="n">predict_mle</span><span class="o">.</span><span class="n">conf_int</span><span class="p">()</span>
<span class="n">lower</span> <span class="o">=</span> <span class="n">predict_mle_ci</span><span class="p">[</span><span class="s1">'lower CPIAUCNS'</span><span class="p">]</span>
<span class="n">upper</span> <span class="o">=</span> <span class="n">predict_mle_ci</span><span class="p">[</span><span class="s1">'upper CPIAUCNS'</span><span class="p">]</span>

<span class="c1"># Graph</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

<span class="c1"># Plot data points</span>
<span class="n">inf</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s1">'-'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Observed'</span><span class="p">)</span>

<span class="c1"># Plot predictions</span>
<span class="n">predict_mle</span><span class="o">.</span><span class="n">predicted_mean</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s1">'r.'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'One-step-ahead forecast'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">predict_mle_ci</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'r'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower left'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../_images/examples_notebooks_generated_statespace_sarimax_pymc3_10_0.png" src="../../../_images/examples_notebooks_generated_statespace_sarimax_pymc3_10_0.png"/>
</div>
</div>


<h3 id="4.-Helper-functions-to-provide-tensors-to-the-library-doing-Bayesian-estimation">4. Helper functions to provide tensors to the library doing Bayesian estimation<a class="headerlink" href="#4.-Helper-functions-to-provide-tensors-to-the-library-doing-Bayesian-estimation" title="Permalink to this headline">¶</a></h3>
<p>We’re almost on to the magic but there are a few preliminaries. Feel free to skip this section if you’re not interested in the technical details.</p>


<h3 id="Technical-Details">Technical Details<a class="headerlink" href="#Technical-Details" title="Permalink to this headline">¶</a></h3>
<p>PyMC3 is a Bayesian estimation library (“Probabilistic Programming in Python: Bayesian Modeling and Probabilistic Machine Learning with Theano”) that is a) fast and b) optimized for Bayesian machine learning, for instance <a class="reference external" href="https://docs.pymc.io/notebooks/bayesian_neural_network_advi.html">Bayesian neural networks</a>. To do all of this, it is built on top of a Theano, a library that aims to evaluate tensors very efficiently and provide symbolic differentiation (necessary for any kind of deep
learning). It is the symbolic differentiation that means PyMC3 can use NUTS on any problem formulated within PyMC3.</p>
<p>We are not formulating a problem directly in PyMC3; we’re using statsmodels to specify the statespace model and solve it with the Kalman filter. So we need to put the plumbing of statsmodels and PyMC3 together, which means wrapping the statsmodels SARIMAX model object in a Theano-flavored wrapper before passing information to PyMC3 for estimation.</p>
<p>Because of this, we can’t use the Theano auto-differentiation directly. Happily, statsmodels SARIMAX objects have a method to return the Jacobian evaluated at the parameter values. We’ll be making use of this to provide gradients so that we can use NUTS.</p>

<h4 id="Defining-helper-functions-to-translate-models-into-a-PyMC3-friendly-form">Defining helper functions to translate models into a PyMC3 friendly form<a class="headerlink" href="#Defining-helper-functions-to-translate-models-into-a-PyMC3-friendly-form" title="Permalink to this headline">¶</a></h4>
<p>First, we’ll create the Theano wrappers. They will be in the form of ‘Ops’, operation objects, that ‘perform’ particular tasks. They are initialized with a statsmodels <code class="docutils literal notranslate"><span class="pre">model</span></code> instance.</p>
<p>Although this code may look somewhat opaque, it is generic for any state space model in statsmodels.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">Loglike</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">Op</span><span class="p">):</span>

    <span class="n">itypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">tt</span><span class="o">.</span><span class="n">dvector</span><span class="p">]</span> <span class="c1"># expects a vector of parameter values when called</span>
    <span class="n">otypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">tt</span><span class="o">.</span><span class="n">dscalar</span><span class="p">]</span> <span class="c1"># outputs a single scalar value (the log likelihood)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="n">Score</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">perform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="n">theta</span><span class="p">,</span> <span class="o">=</span> <span class="n">inputs</span>  <span class="c1"># contains the vector of parameters</span>
        <span class="n">llf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">loglike</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">llf</span><span class="p">)</span> <span class="c1"># output the log-likelihood</span>

    <span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="c1"># the method that calculates the gradients - it actually returns the</span>
        <span class="c1"># vector-Jacobian product - g[0] is a vector of parameter values</span>
        <span class="n">theta</span><span class="p">,</span> <span class="o">=</span> <span class="n">inputs</span>  <span class="c1"># our parameters</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">[</span><span class="n">g</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">theta</span><span class="p">)]</span>
        <span class="k">return</span> <span class="n">out</span>


<span class="k">class</span> <span class="nc">Score</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">Op</span><span class="p">):</span>
    <span class="n">itypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">tt</span><span class="o">.</span><span class="n">dvector</span><span class="p">]</span>
    <span class="n">otypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">tt</span><span class="o">.</span><span class="n">dvector</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">def</span> <span class="nf">perform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="n">theta</span><span class="p">,</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
</pre></div>
</div>
</div>



<h3 id="5.-Bayesian-estimation-with-NUTS">5. Bayesian estimation with NUTS<a class="headerlink" href="#5.-Bayesian-estimation-with-NUTS" title="Permalink to this headline">¶</a></h3>
<p>The next step is to set the parameters for the Bayesian estimation, specify our priors, and run it.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Set sampling params</span>
<span class="n">ndraws</span> <span class="o">=</span> <span class="mi">3000</span>  <span class="c1"># number of draws from the distribution</span>
<span class="n">nburn</span> <span class="o">=</span> <span class="mi">600</span>   <span class="c1"># number of "burn-in points" (which will be discarded)</span>
</pre></div>
</div>
</div>
<p>Now for the fun part! There are three parameters to estimate: <span class="math notranslate nohighlight">\(\phi\)</span>, <span class="math notranslate nohighlight">\(\theta_1\)</span>, and <span class="math notranslate nohighlight">\(\sigma\)</span>. We’ll use uninformative uniform priors for the first two, and an inverse gamma for the last one. Then we’ll run the inference optionally using as many computer cores as I have.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Construct an instance of the Theano wrapper defined above, which</span>
<span class="c1"># will allow PyMC3 to compute the likelihood and Jacobian in a way</span>
<span class="c1"># that it can make use of. Here we are using the same model instance</span>
<span class="c1"># created earlier for MLE analysis (we could also create a new model</span>
<span class="c1"># instance if we preferred)</span>
<span class="n">loglike</span> <span class="o">=</span> <span class="n">Loglike</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">():</span>
    <span class="c1"># Priors</span>
    <span class="n">arL1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s1">'ar.L1'</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.99</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">)</span>
    <span class="n">maL1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s1">'ma.L1'</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.99</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">)</span>
    <span class="n">sigma2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">InverseGamma</span><span class="p">(</span><span class="s1">'sigma2'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

    <span class="c1"># convert variables to tensor vectors</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">as_tensor_variable</span><span class="p">([</span><span class="n">arL1</span><span class="p">,</span> <span class="n">maL1</span><span class="p">,</span> <span class="n">sigma2</span><span class="p">])</span>

    <span class="c1"># use a DensityDist (use a lamdba function to "call" the Op)</span>
    <span class="n">pm</span><span class="o">.</span><span class="n">DensityDist</span><span class="p">(</span><span class="s1">'likelihood'</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">loglike</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">observed</span><span class="o">=</span><span class="p">{</span><span class="s1">'v'</span><span class="p">:</span> <span class="n">theta</span><span class="p">})</span>

    <span class="c1"># Draw samples</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">ndraws</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="n">nburn</span><span class="p">,</span> <span class="n">discard_tuned_samples</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cores</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [sigma2, ma.L1, ar.L1]
Sampling 4 chains, 1 divergences: 100%|██████████| 14400/14400 [04:47&lt;00:00, 50.13draws/s]
There was 1 divergence after tuning. Increase `target_accept` or reparameterize.
The acceptance probability does not match the target. It is 0.8895639164406598, but should be close to 0.8. Try to increase the number of tuning steps.
</pre></div></div>
</div>
<p>Note that the NUTS sampler is auto-assigned because we provided gradients. PyMC3 will use Metropolis or Slicing samplers if it does not find that gradients are available. There are an impressive number of draws per second for a “block box” style computation! However, note that if the model can be represented directly by PyMC3 (like the AR(p) models mentioned above), then computation can be substantially faster.</p>
<p>Inference is complete, but are the results any good? There are a number of ways to check. The first is to look at the posterior distributions (with lines showing the MLE values):</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="c1"># Note: the syntax here for the lines argument is required for</span>
<span class="c1"># PyMC3 versions &gt;= 3.7</span>
<span class="c1"># For version &lt;= 3.6 you can use lines=dict(res_mle.params) instead</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">traceplot</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span>
                 <span class="n">lines</span><span class="o">=</span><span class="p">[(</span><span class="n">k</span><span class="p">,</span> <span class="p">{},</span> <span class="p">[</span><span class="n">v</span><span class="p">])</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">dict</span><span class="p">(</span><span class="n">res_mle</span><span class="o">.</span><span class="n">params</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()],</span>
                 <span class="n">combined</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/travis/miniconda/envs/statsmodels-test/lib/python3.7/site-packages/arviz/plots/backends/matplotlib/distplot.py:38: UserWarning: Argument backend_kwargs has not effect in matplotlib.plot_distSupplied value won't be used
  "Argument backend_kwargs has not effect in matplotlib.plot_dist"
/home/travis/miniconda/envs/statsmodels-test/lib/python3.7/site-packages/arviz/plots/backends/matplotlib/distplot.py:38: UserWarning: Argument backend_kwargs has not effect in matplotlib.plot_distSupplied value won't be used
  "Argument backend_kwargs has not effect in matplotlib.plot_dist"
/home/travis/miniconda/envs/statsmodels-test/lib/python3.7/site-packages/arviz/plots/backends/matplotlib/distplot.py:38: UserWarning: Argument backend_kwargs has not effect in matplotlib.plot_distSupplied value won't be used
  "Argument backend_kwargs has not effect in matplotlib.plot_dist"
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;Figure size 576x396 with 0 Axes&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../_images/examples_notebooks_generated_statespace_sarimax_pymc3_20_2.png" src="../../../_images/examples_notebooks_generated_statespace_sarimax_pymc3_20_2.png"/>
</div>
</div>
<p>The estimated posteriors clearly peak close to the parameters found by MLE. We can also see a summary of the estimated values:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pm</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>mean</th>
<th>sd</th>
<th>hpd_3%</th>
<th>hpd_97%</th>
<th>mcse_mean</th>
<th>mcse_sd</th>
<th>ess_mean</th>
<th>ess_sd</th>
<th>ess_bulk</th>
<th>ess_tail</th>
<th>r_hat</th>
</tr>
</thead>
<tbody>
<tr>
<th>ar.L1</th>
<td>0.969</td>
<td>0.015</td>
<td>0.943</td>
<td>0.990</td>
<td>0.000</td>
<td>0.000</td>
<td>4750.0</td>
<td>4743.0</td>
<td>4111.0</td>
<td>3382.0</td>
<td>1.0</td>
</tr>
<tr>
<th>ma.L1</th>
<td>-0.597</td>
<td>0.075</td>
<td>-0.730</td>
<td>-0.459</td>
<td>0.001</td>
<td>0.001</td>
<td>5669.0</td>
<td>5669.0</td>
<td>6048.0</td>
<td>5139.0</td>
<td>1.0</td>
</tr>
<tr>
<th>sigma2</th>
<td>6.402</td>
<td>0.658</td>
<td>5.279</td>
<td>7.721</td>
<td>0.008</td>
<td>0.006</td>
<td>6328.0</td>
<td>6238.0</td>
<td>6426.0</td>
<td>6404.0</td>
<td>1.0</td>
</tr>
</tbody>
</table>
</div></div>
</div>
<p>Here <span class="math notranslate nohighlight">\(\hat{R}\)</span> is the Gelman-Rubin statistic. It tests for lack of convergence by comparing the variance between multiple chains to the variance within each chain. If convergence has been achieved, the between-chain and within-chain variances should be identical. If <span class="math notranslate nohighlight">\(\hat{R}&lt;1.2\)</span> for all model parameters, we can have some confidence that convergence has been reached.</p>
<p>Additionally, the highest posterior density interval (the gap between the two values of HPD in the table) is small for each of the variables.</p>


<h3 id="6.-Application-of-Bayesian-estimates-of-parameters">6. Application of Bayesian estimates of parameters<a class="headerlink" href="#6.-Application-of-Bayesian-estimates-of-parameters" title="Permalink to this headline">¶</a></h3>
<p>We’ll now re-instigate a version of the model but using the parameters from the Bayesian estimation, and again plot the one-step-ahead forecasts.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Retrieve the posterior means</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace</span><span class="p">)[</span><span class="s1">'mean'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Construct results using these posterior means as parameter values</span>
<span class="n">res_bayes</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">smooth</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

<span class="n">predict_bayes</span> <span class="o">=</span> <span class="n">res_bayes</span><span class="o">.</span><span class="n">get_prediction</span><span class="p">()</span>
<span class="n">predict_bayes_ci</span> <span class="o">=</span> <span class="n">predict_bayes</span><span class="o">.</span><span class="n">conf_int</span><span class="p">()</span>
<span class="n">lower</span> <span class="o">=</span> <span class="n">predict_bayes_ci</span><span class="p">[</span><span class="s1">'lower CPIAUCNS'</span><span class="p">]</span>
<span class="n">upper</span> <span class="o">=</span> <span class="n">predict_bayes_ci</span><span class="p">[</span><span class="s1">'upper CPIAUCNS'</span><span class="p">]</span>

<span class="c1"># Graph</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

<span class="c1"># Plot data points</span>
<span class="n">inf</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s1">'-'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Observed'</span><span class="p">)</span>

<span class="c1"># Plot predictions</span>
<span class="n">predict_bayes</span><span class="o">.</span><span class="n">predicted_mean</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s1">'r.'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'One-step-ahead forecast'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">predict_bayes_ci</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'r'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower left'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../_images/examples_notebooks_generated_statespace_sarimax_pymc3_24_0.png" src="../../../_images/examples_notebooks_generated_statespace_sarimax_pymc3_24_0.png"/>
</div>
</div>



<h2 id="Appendix-A.-Application-to-UnobservedComponents-models">Appendix A. Application to <code class="docutils literal notranslate"><span class="pre">UnobservedComponents</span></code> models<a class="headerlink" href="#Appendix-A.-Application-to-UnobservedComponents-models" title="Permalink to this headline">¶</a></h2>
<p>We can reuse the <code class="docutils literal notranslate"><span class="pre">Loglike</span></code> and <code class="docutils literal notranslate"><span class="pre">Score</span></code> wrappers defined above to consider a different state space model. For example, we might want to model inflation as the combination of a random walk trend and autoregressive error term:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
y_t &amp; = \mu_t + \varepsilon_t \\
\mu_t &amp; = \mu_{t-1} + \eta_t \\
\varepsilon_t &amp;= \phi \varepsilon_t + \zeta_t
\end{aligned}\end{split}\]</div>
<p>This model can be constructed in Statsmodels with the <code class="docutils literal notranslate"><span class="pre">UnobservedComponents</span></code> class using the <code class="docutils literal notranslate"><span class="pre">rwalk</span></code> and <code class="docutils literal notranslate"><span class="pre">autoregressive</span></code> specifications. As before, we can fit the model using maximum likelihood via the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Construct the model instance</span>
<span class="n">mod_uc</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">tsa</span><span class="o">.</span><span class="n">UnobservedComponents</span><span class="p">(</span><span class="n">inf</span><span class="p">,</span> <span class="s1">'rwalk'</span><span class="p">,</span> <span class="n">autoregressive</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Fit the model via maximum likelihood</span>
<span class="n">res_uc_mle</span> <span class="o">=</span> <span class="n">mod_uc</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res_uc_mle</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
                        Unobserved Components Results
==============================================================================
Dep. Variable:               CPIAUCNS   No. Observations:                  191
Model:                    random walk   Log Likelihood                -440.855
                              + AR(1)   AIC                            887.709
Date:                Tue, 02 Feb 2021   BIC                            897.450
Time:                        07:01:53   HQIC                           891.655
Sample:                    04-01-1971
                         - 10-01-2018
Covariance Type:                  opg
================================================================================
                   coef    std err          z      P&gt;|z|      [0.025      0.975]
--------------------------------------------------------------------------------
sigma2.level     0.2037      0.156      1.310      0.190      -0.101       0.508
sigma2.ar        5.2920      0.338     15.665      0.000       4.630       5.954
ar.L1            0.4005      0.096      4.161      0.000       0.212       0.589
===================================================================================
Ljung-Box (L1) (Q):                   1.46   Jarque-Bera (JB):               521.69
Prob(Q):                              0.23   Prob(JB):                         0.00
Heteroskedasticity (H):               1.59   Skew:                            -1.30
Prob(H) (two-sided):                  0.07   Kurtosis:                        10.69
===================================================================================

Warnings:
[1] Covariance matrix calculated using the outer product of gradients (complex-step).
</pre></div></div>
</div>
<p>As noted earlier, the Theano wrappers (<code class="docutils literal notranslate"><span class="pre">Loglike</span></code> and <code class="docutils literal notranslate"><span class="pre">Score</span></code>) that we created above are generic, so we can re-use essentially the same code to explore the model with Bayesian methods.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Set sampling params</span>
<span class="n">ndraws</span> <span class="o">=</span> <span class="mi">3000</span>  <span class="c1"># number of draws from the distribution</span>
<span class="n">nburn</span> <span class="o">=</span> <span class="mi">600</span>   <span class="c1"># number of "burn-in points" (which will be discarded)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Here we follow the same procedure as above, but now we instantiate the</span>
<span class="c1"># Theano wrapper `Loglike` with the UC model instance instead of the</span>
<span class="c1"># SARIMAX model instance</span>
<span class="n">loglike_uc</span> <span class="o">=</span> <span class="n">Loglike</span><span class="p">(</span><span class="n">mod_uc</span><span class="p">)</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">():</span>
    <span class="c1"># Priors</span>
    <span class="n">sigma2level</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">InverseGamma</span><span class="p">(</span><span class="s1">'sigma2.level'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">sigma2ar</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">InverseGamma</span><span class="p">(</span><span class="s1">'sigma2.ar'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">arL1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s1">'ar.L1'</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.99</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">)</span>

    <span class="c1"># convert variables to tensor vectors</span>
    <span class="n">theta_uc</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">as_tensor_variable</span><span class="p">([</span><span class="n">sigma2level</span><span class="p">,</span> <span class="n">sigma2ar</span><span class="p">,</span> <span class="n">arL1</span><span class="p">])</span>

    <span class="c1"># use a DensityDist (use a lamdba function to "call" the Op)</span>
    <span class="n">pm</span><span class="o">.</span><span class="n">DensityDist</span><span class="p">(</span><span class="s1">'likelihood'</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">loglike_uc</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">observed</span><span class="o">=</span><span class="p">{</span><span class="s1">'v'</span><span class="p">:</span> <span class="n">theta_uc</span><span class="p">})</span>

    <span class="c1"># Draw samples</span>
    <span class="n">trace_uc</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">ndraws</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="n">nburn</span><span class="p">,</span> <span class="n">discard_tuned_samples</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cores</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [ar.L1, sigma2.ar, sigma2.level]
Sampling 4 chains, 0 divergences: 100%|██████████| 14400/14400 [03:36&lt;00:00, 66.46draws/s]
</pre></div></div>
</div>
<p>And as before we can plot the marginal posteriors. In contrast to the SARIMAX example, here the posterior modes are somewhat different from the MLE estimates.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="c1"># Note: the syntax here for the lines argument is required for</span>
<span class="c1"># PyMC3 versions &gt;= 3.7</span>
<span class="c1"># For version &lt;= 3.6 you can use lines=dict(res_mle.params) instead</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">traceplot</span><span class="p">(</span><span class="n">trace_uc</span><span class="p">,</span>
                 <span class="n">lines</span><span class="o">=</span><span class="p">[(</span><span class="n">k</span><span class="p">,</span> <span class="p">{},</span> <span class="p">[</span><span class="n">v</span><span class="p">])</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">dict</span><span class="p">(</span><span class="n">res_uc_mle</span><span class="o">.</span><span class="n">params</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()],</span>
                 <span class="n">combined</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/travis/miniconda/envs/statsmodels-test/lib/python3.7/site-packages/arviz/plots/backends/matplotlib/distplot.py:38: UserWarning: Argument backend_kwargs has not effect in matplotlib.plot_distSupplied value won't be used
  "Argument backend_kwargs has not effect in matplotlib.plot_dist"
/home/travis/miniconda/envs/statsmodels-test/lib/python3.7/site-packages/arviz/plots/backends/matplotlib/distplot.py:38: UserWarning: Argument backend_kwargs has not effect in matplotlib.plot_distSupplied value won't be used
  "Argument backend_kwargs has not effect in matplotlib.plot_dist"
/home/travis/miniconda/envs/statsmodels-test/lib/python3.7/site-packages/arviz/plots/backends/matplotlib/distplot.py:38: UserWarning: Argument backend_kwargs has not effect in matplotlib.plot_distSupplied value won't be used
  "Argument backend_kwargs has not effect in matplotlib.plot_dist"
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;Figure size 576x396 with 0 Axes&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../_images/examples_notebooks_generated_statespace_sarimax_pymc3_32_2.png" src="../../../_images/examples_notebooks_generated_statespace_sarimax_pymc3_32_2.png"/>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pm</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace_uc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>mean</th>
<th>sd</th>
<th>hpd_3%</th>
<th>hpd_97%</th>
<th>mcse_mean</th>
<th>mcse_sd</th>
<th>ess_mean</th>
<th>ess_sd</th>
<th>ess_bulk</th>
<th>ess_tail</th>
<th>r_hat</th>
</tr>
</thead>
<tbody>
<tr>
<th>sigma2.level</th>
<td>0.538</td>
<td>0.255</td>
<td>0.155</td>
<td>1.001</td>
<td>0.003</td>
<td>0.002</td>
<td>7713.0</td>
<td>7704.0</td>
<td>7737.0</td>
<td>8234.0</td>
<td>1.0</td>
</tr>
<tr>
<th>sigma2.ar</th>
<td>4.840</td>
<td>0.666</td>
<td>3.600</td>
<td>6.071</td>
<td>0.008</td>
<td>0.006</td>
<td>7253.0</td>
<td>7253.0</td>
<td>7199.0</td>
<td>7191.0</td>
<td>1.0</td>
</tr>
<tr>
<th>ar.L1</th>
<td>0.329</td>
<td>0.102</td>
<td>0.141</td>
<td>0.522</td>
<td>0.001</td>
<td>0.001</td>
<td>8441.0</td>
<td>8363.0</td>
<td>8444.0</td>
<td>8854.0</td>
<td>1.0</td>
</tr>
</tbody>
</table>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Retrieve the posterior means</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace_uc</span><span class="p">)[</span><span class="s1">'mean'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Construct results using these posterior means as parameter values</span>
<span class="n">res_uc_bayes</span> <span class="o">=</span> <span class="n">mod_uc</span><span class="o">.</span><span class="n">smooth</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>One benefit of this model is that it gives us an estimate of the underling “level” of inflation, using the smoothed estimate of <span class="math notranslate nohighlight">\(\mu_t\)</span>, which we can access as the “level” column in the results objects’ <code class="docutils literal notranslate"><span class="pre">states.smoothed</span></code> attribute. In this case, because the Bayesian posterior mean of the level’s variance is larger than the MLE estimate, its estimated level is a little more volatile.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Graph</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

<span class="c1"># Plot data points</span>
<span class="n">inf</span><span class="p">[</span><span class="s1">'CPIAUCNS'</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s1">'-'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Observed data'</span><span class="p">)</span>

<span class="c1"># Plot estimate of the level term</span>
<span class="n">res_uc_mle</span><span class="o">.</span><span class="n">states</span><span class="o">.</span><span class="n">smoothed</span><span class="p">[</span><span class="s1">'level'</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Smoothed level (MLE)'</span><span class="p">)</span>
<span class="n">res_uc_bayes</span><span class="o">.</span><span class="n">states</span><span class="o">.</span><span class="n">smoothed</span><span class="p">[</span><span class="s1">'level'</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Smoothed level (Bayesian)'</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower left'</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.legend.Legend at 0x7fa82ea6a790&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../_images/examples_notebooks_generated_statespace_sarimax_pymc3_36_1.png" src="../../../_images/examples_notebooks_generated_statespace_sarimax_pymc3_36_1.png"/>
</div>
</div>




          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
            <a href="statespace_tvpvar_mcmc_cfa.html" title="TVP-VAR, MCMC, and sparse simulation smoothing"
               class="md-flex md-footer-nav__link md-footer-nav__link--prev"
               rel="prev">
              <div class="md-flex__cell md-flex__cell--shrink">
                <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
              </div>
              <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
                <span class="md-flex__ellipsis">
                  <span
                      class="md-footer-nav__direction"> Previous </span> TVP-VAR, MCMC, and sparse simulation smoothing </span>
              </div>
            </a>
          
          
            <a href="statespace_news.html" title="Forecasting, updating datasets, and the “news”"
               class="md-flex md-footer-nav__link md-footer-nav__link--next"
               rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span
                class="md-flex__ellipsis"> <span
                class="md-footer-nav__direction"> Next </span> Forecasting, updating datasets, and the “news” </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink"><i
                class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2009-2019, Josef Perktold, Skipper Seabold, Jonathan Taylor, statsmodels-developers.
              
          </div>
            Last updated on
              Feb 02, 2021.
            <br/>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 3.4.3.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../../../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>