
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>vbench &mdash; statsmodels 0.6.1 documentation</title>
    
    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.6.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../_static/statsmodels_hybi_favico.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="top" title="statsmodels 0.6.1 documentation" href="../index.html" />
<link rel="stylesheet" href="../../_static/facebox.css" type="text/css" />
<link rel="stylesheet" href="../_static/examples.css" type="text/css" />
<script type="text/javascript" src="../_static/scripts.js">
</script>
<script type="text/javascript" src="../_static/facebox.js">
</script>

  </head>
  <body role="document">
<div class="headerwrap">
    <div class = "header">
        
        <a href = "../index.html">
<img src="../_static/statsmodels_hybi_banner.png" alt="Logo"
    style="padding-left: 15px"/></a>
        
    </div>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
<li><a href ="../install.html">Install</a></li> &nbsp;|&nbsp;
<li><a href="https://groups.google.com/group/pystatsmodels?hl=en">Support</a></li> &nbsp;|&nbsp;
<li><a href="https://github.com/statsmodels/statsmodels/issues">Bugs</a></li> &nbsp;|&nbsp;
<li><a href="index.html">Develop</a></li> &nbsp;|&nbsp;
<li><a href="../examples/index.html">Examples</a></li> &nbsp;|&nbsp;
<li><a href="../faq.html">FAQ</a></li> &nbsp;|&nbsp;
 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            




  <div class="section" id="vbench">
<span id="vbenchdoc"></span><h1>vbench<a class="headerlink" href="#vbench" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://github.com/pydata/vbench">vbench</a> is a tool for benchmarking your code through time, for showing performance improvement or regressions.</p>
<p>WARNING: <code class="docutils literal"><span class="pre">vbench</span></code> is not yet compatible with python3.</p>
<div class="section" id="new-dependencies">
<h2>New Dependencies<a class="headerlink" href="#new-dependencies" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><a class="reference external" href="https://github.com/pydata/vbench">vbench</a> (from github only)</li>
<li><a class="reference external" href="https://pypi.python.org/pypi/SQLAlchemy">sqlalchemy</a></li>
<li><a class="reference external" href="https://pypi.python.org/pypi/GitPython/">gitpython</a></li>
<li><a class="reference external" href="https://pypi.python.org/pypi/psutil">psutil</a></li>
<li><a class="reference external" href="https://pypi.python.org/pypi/affinity">affinity</a> (As a fallback to psutil)</li>
</ul>
<p>Also note that you need to have sqlite3 working with python.</p>
</div>
<div class="section" id="writing-a-good-vbench">
<h2>Writing a good vbench<a class="headerlink" href="#writing-a-good-vbench" title="Permalink to this headline">¶</a></h2>
<p>A set of related benchmarks go together in a module (a <code class="docutils literal"><span class="pre">.py</span></code> file).
See <code class="docutils literal"><span class="pre">vb_suite/discrete.py</span></code> for an example.</p>
<p>There&#8217;s typically some boilerplate common to all the tests, which can
be placed in a string <code class="docutils literal"><span class="pre">common_setup</span></code>.</p>
<p>Now we can write our specific benchmark.</p>
<p>There are up to three items in a single benchmark:</p>
<ul class="simple">
<li>setup specific to that benchmark (typically a string concatenated to <code class="docutils literal"><span class="pre">common_setup</span></code>)</li>
<li>a statement to be executed, which is the first argument to the <code class="docutils literal"><span class="pre">vbench.BenchmarkRunner</span></code> class</li>
<li>instantiation the <code class="docutils literal"><span class="pre">vbench.Benchmark</span></code> class</li>
</ul>
<p>It&#8217;s important to separate the setup from the statement we&#8217;re interested in profiling.
The statement ought to be concise and should profile only one thing.
If you mix setup in with the statement to be profiled, then changes affecting the performance of the setup (which might even take place outside your library) will pollute the test.</p>
<p>Each module must be listed in the <code class="docutils literal"><span class="pre">suite.py</span></code> file in the modules list.</p>
<p>Not all tests can be run against the entire history of the project.
For newer features, each <code class="docutils literal"><span class="pre">Benchmark</span></code> object takes an optional <code class="docutils literal"><span class="pre">start_date</span></code> parameter.
For example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">start_date</span><span class="o">=</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2012</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>If a <code class="docutils literal"><span class="pre">start_date</span></code> is not applied for a specific benchmark, the global setting from <code class="docutils literal"><span class="pre">vb_suite.py</span></code> is used.</p>
<p>Another reason that a benchmark can&#8217;t be run against the entire project&#8217;s history is that API&#8217;s sometimes have to change in ways that are not backwards compatible.
For these cases, the easiest way to compare performance pre- to post-API change is probably the try-except idiom:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">try</span><span class="p">:</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">date_range</span><span class="p">(</span><span class="s">&#39;1/1/2000&#39;</span><span class="p">,</span> <span class="n">periods</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s">&#39;min&#39;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">DateRange</span><span class="p">(</span><span class="s">&#39;1/1/2000&#39;</span><span class="p">,</span> <span class="n">periods</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="n">datetools</span><span class="o">.</span><span class="n">Minute</span><span class="p">())</span>
    <span class="n">date_range</span> <span class="o">=</span> <span class="n">DateRange</span>
</pre></div>
</div>
</div>
<div class="section" id="pre-pr">
<h2>Pre-PR<a class="headerlink" href="#pre-pr" title="Permalink to this headline">¶</a></h2>
<p>Most contributors don&#8217;t need to worry about writing a vbench or running the full suite against the project&#8217;s entire history.
Use <code class="docutils literal"><span class="pre">test_perf.py</span></code> to see how the performance of your PR compares against a known-to-be-good benchmark.</p>
</div>
</div>
<div class="section" id="implementation">
<h1>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">¶</a></h1>
<p>There are two main uses for <code class="docutils literal"><span class="pre">vbench.</span></code>
The first is most useful for someone submitting a pull request that might affect the performance of the library.
In this case, the submitter should run <code class="docutils literal"><span class="pre">python</span> <span class="pre">vb_suite/test_perf.py</span> <span class="pre">-b</span> <span class="pre">base_commit</span> <span class="pre">-H</span></code>, where <code class="docutils literal"><span class="pre">base_commit</span></code> is the baseline commit hash you want to compare to.
The <code class="docutils literal"><span class="pre">-H</span></code> argument says to compare the HEAD of your branch against the baseline commit.</p>
<p>The second use-case is for measuring the long-term performance of the project.
For this case the file of interest is <code class="docutils literal"><span class="pre">run_suite.py</span></code>.
Using the parameters specified in that file, the suite of benchmarks is run against the history of the project.
The results are stored in a sqlite database.</p>
<div class="section" id="suite-py">
<h2>suite.py<a class="headerlink" href="#suite-py" title="Permalink to this headline">¶</a></h2>
<p>This is the main configuration file.
It pulls in the benchmarks from the various modules in <code class="docutils literal"><span class="pre">vb_suite</span></code>, reads in the user configuration, and handles the setup and tear-down of the performance tests.</p>
</div>
<div class="section" id="run-suite-py">
<h2>run_suite.py<a class="headerlink" href="#run-suite-py" title="Permalink to this headline">¶</a></h2>
<p>Useful for the maintainers of the project to track performance over time.
Runs with no arguments from the command line.
Persists the results in a database so that the the full suite needn&#8217;t be rerun each time.</p>
</div>
<div class="section" id="user-config-file">
<h2>User config file<a class="headerlink" href="#user-config-file" title="Permalink to this headline">¶</a></h2>
<p>Only necessary if you&#8217;re running <code class="docutils literal"><span class="pre">run_suite.py</span></code>.
Should look something like:</p>
<p>repo_path: /Home/Envs/statsmodels/lib/python2.7/site~packages/statsmodels/
repo_url: <a class="reference external" href="https://github.com/statsmodels/statsmodels.git">https://github.com/statsmodels/statsmodels.git</a>
db_path: /Homevbench/statsmodels/vb_suite/benchmarks.db
tmp_dir: /Home/tmp</p>
</div>
<div class="section" id="test-perf-py">
<h2>test_perf.py<a class="headerlink" href="#test-perf-py" title="Permalink to this headline">¶</a></h2>
<p>Use before commit to check for performance regressions.
CLT, use <code class="docutils literal"><span class="pre">python</span> <span class="pre">test_perf.py</span> <span class="pre">-h</span></code> for help.</p>
<p>Most of the time you&#8217;ll be giving it one or two arguments:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">-b</span> <span class="pre">BASE_COMMIT</span></code>: the commit you&#8217;re comparing your commit against</li>
<li><code class="docutils literal"><span class="pre">-t</span> <span class="pre">TARGET_COMMIT</span></code>: or use -H to set the target to the <code class="docutils literal"><span class="pre">HEAD</span></code> of your branch.</li>
</ul>
</div>
<div class="section" id="generate-rst-files-py">
<h2>generate_rst_files.py<a class="headerlink" href="#generate-rst-files-py" title="Permalink to this headline">¶</a></h2>
<p>Once you&#8217;ve run <cite>run_suite.py</cite> and generated a benchmark database, you can use <code class="docutils literal"><span class="pre">generate_rst_files.py</span></code> to graph performance over time.</p>
</div>
<div class="section" id="references">
<h2>References:<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="http://wesmckinney.com/blog/?p=373">http://wesmckinney.com/blog/?p=373</a></p>
<p><a class="reference external" href="https://github.com/pydata/vbench">https://github.com/pydata/vbench</a></p>
<p><a class="reference external" href="https://github.com/pydata/pandas/tree/master/vb_suite">https://github.com/pydata/pandas/tree/master/vb_suite</a></p>
<p><a class="reference external" href="https://github.com/yarikoptic/numpy-vbench">https://github.com/yarikoptic/numpy-vbench</a></p>
</div>
</div>





          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">vbench</a><ul>
<li><a class="reference internal" href="#new-dependencies">New Dependencies</a></li>
<li><a class="reference internal" href="#writing-a-good-vbench">Writing a good vbench</a></li>
<li><a class="reference internal" href="#pre-pr">Pre-PR</a></li>
</ul>
</li>
<li><a class="reference internal" href="#implementation">Implementation</a><ul>
<li><a class="reference internal" href="#suite-py">suite.py</a></li>
<li><a class="reference internal" href="#run-suite-py">run_suite.py</a></li>
<li><a class="reference internal" href="#user-config-file">User config file</a></li>
<li><a class="reference internal" href="#test-perf-py">test_perf.py</a></li>
<li><a class="reference internal" href="#generate-rst-files-py">generate_rst_files.py</a></li>
<li><a class="reference internal" href="#references">References:</a></li>
</ul>
</li>
</ul>

  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/dev/vbench.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer" role="contentinfo">
        &copy; Copyright 2009-2013, Josef Perktold, Skipper Seabold, Jonathan Taylor, statsmodels-developers.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.1.
    </div>
  </body>
</html>